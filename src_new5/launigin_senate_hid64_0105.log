args
 Namespace(samples=4, concat=10, runs=3, latent_size=10, dataset='senate', seed=42, epochs=1000, lr=0.001, weight_decay=0.0005, hidden=64, dropout=0.5, batch_size=128, tem=0.5, lam=1.0, pretrain_epochs=8, pretrain_lr=0.001, conditional=True, update_epochs=20, num_models=100, warmup=200, cuda=False)
Hypergraph(num_v=294, num_e=21721)
X dim: torch.Size([294, 294])
labels: 2
Run Train:   0%|          | 0/3 [00:00<?, ?it/s]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Run Train:  33%|███▎      | 1/3 [24:36<49:12, 1476.26s/it]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Run:01 Epoch: 0001 loss_train: 1371.6334 loss_val: 6844.8701
Run:01 Epoch: 0011 loss_train: 1001.1132 loss_val: 1260.8259
Run:01 Epoch: 0021 loss_train: 555.8516 loss_val: 618.6276
Run:01 Epoch: 0031 loss_train: 452.0337 loss_val: 45.0023
Run:01 Epoch: 0041 loss_train: 501.3857 loss_val: 243.4440
Run:01 Epoch: 0051 loss_train: 627.4811 loss_val: 301.1122
Run:01 Epoch: 0061 loss_train: 485.0730 loss_val: 153.6920
Run:01 Epoch: 0071 loss_train: 452.4095 loss_val: 124.2308
Run:01 Epoch: 0081 loss_train: 195.5080 loss_val: 136.8243
Run:01 Epoch: 0091 loss_train: 270.0463 loss_val: 201.3473
Run:01 Epoch: 0101 loss_train: 206.3420 loss_val: 112.3943
Run:01 Epoch: 0111 loss_train: 192.7739 loss_val: 102.2264
Run:01 Epoch: 0121 loss_train: 195.6949 loss_val: 314.0937
Run:01 Epoch: 0131 loss_train: 148.0515 loss_val: 180.1304
Run:01 Epoch: 0141 loss_train: 201.3972 loss_val: 136.3428
Run:01 Epoch: 0151 loss_train: 200.9477 loss_val: 96.5865
Run:01 Epoch: 0161 loss_train: 181.7975 loss_val: 83.0859
Run:01 Epoch: 0171 loss_train: 201.4030 loss_val: 80.5807
Run:01 Epoch: 0181 loss_train: 138.5294 loss_val: 77.9065
Run:01 Epoch: 0191 loss_train: 128.3852 loss_val: 73.9237
Run:01 Epoch: 0201 loss_train: 103.8801 loss_val: 72.8592
Run:01 Epoch: 0211 loss_train: 258.6474 loss_val: 108.9199
Run:01 Epoch: 0221 loss_train: 99.9252 loss_val: 68.7599
Run:01 Epoch: 0231 loss_train: 82.5603 loss_val: 91.4112
Run:01 Epoch: 0241 loss_train: 67.8581 loss_val: 100.6886
Run:01 Epoch: 0251 loss_train: 77.9690 loss_val: 137.2919
Run:01 Epoch: 0261 loss_train: 74.5329 loss_val: 84.2802
Run:01 Epoch: 0271 loss_train: 73.5721 loss_val: 50.7256
Run:01 Epoch: 0281 loss_train: 74.5057 loss_val: 81.5083
Run:01 Epoch: 0291 loss_train: 128.0478 loss_val: 85.9969
Run:01 Epoch: 0301 loss_train: 39.5966 loss_val: 49.7564
Run:01 Epoch: 0311 loss_train: 50.1858 loss_val: 107.1898
Run:01 Epoch: 0321 loss_train: 73.1385 loss_val: 51.2165
Run:01 Epoch: 0331 loss_train: 88.0380 loss_val: 71.8798
Run:01 Epoch: 0341 loss_train: 35.1359 loss_val: 44.3683
Run:01 Epoch: 0351 loss_train: 75.4332 loss_val: 45.6241
Run:01 Epoch: 0361 loss_train: 43.3103 loss_val: 49.5677
Run:01 Epoch: 0371 loss_train: 22.1448 loss_val: 66.9905
Run:01 Epoch: 0381 loss_train: 55.0078 loss_val: 39.4840
Run:01 Epoch: 0391 loss_train: 16.7868 loss_val: 29.3638
Run:01 Epoch: 0401 loss_train: 77.0436 loss_val: 22.7306
Run:01 Epoch: 0411 loss_train: 22.7152 loss_val: 22.9099
Run:01 Epoch: 0421 loss_train: 24.3192 loss_val: 16.7382
Run:01 Epoch: 0431 loss_train: 32.2657 loss_val: 19.1744
Run:01 Epoch: 0441 loss_train: 17.1143 loss_val: 23.2825
Run:01 Epoch: 0451 loss_train: 15.1597 loss_val: 29.7574
Run:01 Epoch: 0461 loss_train: 18.6402 loss_val: 13.4210
Run:01 Epoch: 0471 loss_train: 12.1126 loss_val: 17.2753
Run:01 Epoch: 0481 loss_train: 92.9115 loss_val: 19.0787
Run:01 Epoch: 0491 loss_train: 87.1603 loss_val: 21.5513
Run:01 Epoch: 0501 loss_train: 47.5839 loss_val: 25.2437
Run:01 Epoch: 0511 loss_train: 46.2844 loss_val: 27.8450
Run:01 Epoch: 0521 loss_train: 50.8265 loss_val: 21.0706
Run:01 Epoch: 0531 loss_train: 11.6752 loss_val: 21.1091
Run:01 Epoch: 0541 loss_train: 23.8782 loss_val: 47.7138
Run:01 Epoch: 0551 loss_train: 9.6436 loss_val: 26.2683
Run:01 Epoch: 0561 loss_train: 14.3291 loss_val: 11.6089
Run:01 Epoch: 0571 loss_train: 12.4519 loss_val: 18.5746
Run:01 Epoch: 0581 loss_train: 10.6797 loss_val: 18.4589
Run:01 Epoch: 0591 loss_train: 15.6685 loss_val: 19.7384
Run:01 Epoch: 0601 loss_train: 24.5779 loss_val: 16.6571
Run:01 Epoch: 0611 loss_train: 9.7309 loss_val: 7.0595
Run:01 Epoch: 0621 loss_train: 7.7797 loss_val: 10.7494
Run:01 Epoch: 0631 loss_train: 10.1125 loss_val: 6.3839
Run:01 Epoch: 0641 loss_train: 13.6363 loss_val: 8.9048
Run:01 Epoch: 0651 loss_train: 10.5488 loss_val: 6.3202
Run:01 Epoch: 0661 loss_train: 8.0339 loss_val: 8.0780
Run:01 Epoch: 0671 loss_train: 5.4708 loss_val: 9.7773
Run:01 Epoch: 0681 loss_train: 5.9029 loss_val: 15.5682
Run:01 Epoch: 0691 loss_train: 41.1024 loss_val: 9.5718
Run:01 Epoch: 0701 loss_train: 18.1071 loss_val: 45.5078
Run:01 Epoch: 0711 loss_train: 18.8663 loss_val: 59.2764
Run:01 Epoch: 0721 loss_train: 6.7968 loss_val: 11.5945
Run:01 Epoch: 0731 loss_train: 5.8469 loss_val: 6.1860
Run:01 Epoch: 0741 loss_train: 5.9999 loss_val: 5.6123
Run:01 Epoch: 0751 loss_train: 12.5314 loss_val: 6.5594
Run:01 Epoch: 0761 loss_train: 9.6570 loss_val: 4.9225
Run:01 Epoch: 0771 loss_train: 10.5359 loss_val: 8.5636
Run:01 Epoch: 0781 loss_train: 9.4450 loss_val: 5.6824
Run:01 Epoch: 0791 loss_train: 4.8036 loss_val: 4.6994
Run:01 Epoch: 0801 loss_train: 6.1844 loss_val: 6.8003
Run:01 Epoch: 0811 loss_train: 4.6364 loss_val: 5.0174
Run:01 Epoch: 0821 loss_train: 4.6179 loss_val: 8.8212
Run:01 Epoch: 0831 loss_train: 8.0349 loss_val: 14.4387
Run:01 Epoch: 0841 loss_train: 2.6982 loss_val: 3.6137
Run:01 Epoch: 0851 loss_train: 5.4989 loss_val: 7.7848
Run:01 Epoch: 0861 loss_train: 3.7444 loss_val: 4.5862
Run:01 Epoch: 0871 loss_train: 2.4395 loss_val: 4.6378
Run:01 Epoch: 0881 loss_train: 5.1168 loss_val: 6.9819
Run:01 Epoch: 0891 loss_train: 61.6289 loss_val: 52.6912
Run:01 Epoch: 0901 loss_train: 11.0034 loss_val: 35.0505
Run:01 Epoch: 0911 loss_train: 8.7332 loss_val: 25.4469
Run:01 Epoch: 0921 loss_train: 4.0862 loss_val: 4.3222
Run:01 Epoch: 0931 loss_train: 3.7239 loss_val: 4.3713
Run:01 Epoch: 0941 loss_train: 3.5416 loss_val: 6.0430
Run:01 Epoch: 0951 loss_train: 4.6008 loss_val: 4.1233
Run:01 Epoch: 0961 loss_train: 2.0083 loss_val: 4.2980
Run:01 Epoch: 0971 loss_train: 3.3666 loss_val: 2.9209
Run:01 Epoch: 0981 loss_train: 2.0734 loss_val: 5.1834
Run:01 Epoch: 0991 loss_train: 1.3695 loss_val: 3.1415
Run:02 Epoch: 0001 loss_train: 9736.4834 loss_val: 3044.9094
Run:02 Epoch: 0011 loss_train: 1517.0160 loss_val: 80.3944
Run:02 Epoch: 0021 loss_train: 2783.7190 loss_val: 977.7237
Run:02 Epoch: 0031 loss_train: 1755.9668 loss_val: 2624.1851
Run:02 Epoch: 0041 loss_train: 873.6964 loss_val: 182.8702
Run:02 Epoch: 0051 loss_train: 426.0420 loss_val: 740.8380
Run:02 Epoch: 0061 loss_train: 610.9069 loss_val: 192.0013
Run:02 Epoch: 0071 loss_train: 567.2797 loss_val: 113.7543
Run:02 Epoch: 0081 loss_train: 453.9298 loss_val: 199.6591
Run:02 Epoch: 0091 loss_train: 704.8553 loss_val: 405.4433
Run:02 Epoch: 0101 loss_train: 232.4474 loss_val: 630.1852
Run:02 Epoch: 0111 loss_train: 254.5934 loss_val: 185.7057
Run:02 Epoch: 0121 loss_train: 571.8661 loss_val: 131.8015
Run:02 Epoch: 0131 loss_train: 141.0218 loss_val: 338.2411
Run:02 Epoch: 0141 loss_train: 198.9532 loss_val: 306.1289
Run:02 Epoch: 0151 loss_train: 352.4045 loss_val: 165.8400
Run:02 Epoch: 0161 loss_train: 161.0077 loss_val: 106.1697
Run:02 Epoch: 0171 loss_train: 178.2040 loss_val: 100.9183
Run:02 Epoch: 0181 loss_train: 123.4775 loss_val: 119.6665
Run:02 Epoch: 0191 loss_train: 210.1692 loss_val: 99.6824
Run:02 Epoch: 0201 loss_train: 176.5838 loss_val: 187.2614
Run:02 Epoch: 0211 loss_train: 96.0503 loss_val: 128.3411
Run:02 Epoch: 0221 loss_train: 115.8377 loss_val: 241.3903
Run:02 Epoch: 0231 loss_train: 196.0041 loss_val: 118.1142
Run:02 Epoch: 0241 loss_train: 200.6849 loss_val: 79.2908
Run:02 Epoch: 0251 loss_train: 154.0356 loss_val: 75.7273
Run:02 Epoch: 0261 loss_train: 162.2033 loss_val: 83.7715
Run:02 Epoch: 0271 loss_train: 111.1735 loss_val: 86.3302
Run:02 Epoch: 0281 loss_train: 103.8336 loss_val: 98.2940
Run:02 Epoch: 0291 loss_train: 134.5358 loss_val: 109.5742
Run:02 Epoch: 0301 loss_train: 108.1088 loss_val: 107.2021
Run:02 Epoch: 0311 loss_train: 79.5066 loss_val: 79.6884
Run:02 Epoch: 0321 loss_train: 126.5274 loss_val: 58.2619
Run:02 Epoch: 0331 loss_train: 110.6223 loss_val: 77.7939
Run:02 Epoch: 0341 loss_train: 95.9304 loss_val: 144.3576
Run:02 Epoch: 0351 loss_train: 69.2206 loss_val: 121.4700
Run:02 Epoch: 0361 loss_train: 77.2646 loss_val: 67.6749
Run:02 Epoch: 0371 loss_train: 92.2216 loss_val: 44.3038
Run:02 Epoch: 0381 loss_train: 62.9032 loss_val: 50.1468
Run:02 Epoch: 0391 loss_train: 67.5161 loss_val: 53.1288
Run:02 Epoch: 0401 loss_train: 61.3296 loss_val: 74.1098
Run:02 Epoch: 0411 loss_train: 56.4160 loss_val: 56.7171
Run:02 Epoch: 0421 loss_train: 42.9228 Run Train:  67%|██████▋   | 2/3 [49:10<24:34, 1474.82s/it]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_val: 96.5382
Run:02 Epoch: 0431 loss_train: 42.5488 loss_val: 59.2131
Run:02 Epoch: 0441 loss_train: 58.9748 loss_val: 73.3013
Run:02 Epoch: 0451 loss_train: 59.6847 loss_val: 56.5261
Run:02 Epoch: 0461 loss_train: 24.4263 loss_val: 49.5016
Run:02 Epoch: 0471 loss_train: 123.2060 loss_val: 32.1884
Run:02 Epoch: 0481 loss_train: 27.4428 loss_val: 36.0733
Run:02 Epoch: 0491 loss_train: 46.8713 loss_val: 86.0355
Run:02 Epoch: 0501 loss_train: 54.3619 loss_val: 43.0941
Run:02 Epoch: 0511 loss_train: 30.5134 loss_val: 66.6008
Run:02 Epoch: 0521 loss_train: 58.2073 loss_val: 54.7404
Run:02 Epoch: 0531 loss_train: 14.1756 loss_val: 47.4763
Run:02 Epoch: 0541 loss_train: 29.8925 loss_val: 27.4092
Run:02 Epoch: 0551 loss_train: 16.6091 loss_val: 37.3765
Run:02 Epoch: 0561 loss_train: 50.5128 loss_val: 17.5486
Run:02 Epoch: 0571 loss_train: 23.9726 loss_val: 17.8589
Run:02 Epoch: 0581 loss_train: 21.1627 loss_val: 13.2202
Run:02 Epoch: 0591 loss_train: 43.8939 loss_val: 16.6806
Run:02 Epoch: 0601 loss_train: 36.1242 loss_val: 16.5818
Run:02 Epoch: 0611 loss_train: 24.0801 loss_val: 31.3408
Run:02 Epoch: 0621 loss_train: 36.4127 loss_val: 20.5359
Run:02 Epoch: 0631 loss_train: 11.4701 loss_val: 23.1782
Run:02 Epoch: 0641 loss_train: 27.1393 loss_val: 17.9749
Run:02 Epoch: 0651 loss_train: 20.5727 loss_val: 12.7974
Run:02 Epoch: 0661 loss_train: 22.7893 loss_val: 11.8958
Run:02 Epoch: 0671 loss_train: 33.0056 loss_val: 15.7181
Run:02 Epoch: 0681 loss_train: 33.8979 loss_val: 11.6660
Run:02 Epoch: 0691 loss_train: 12.5736 loss_val: 15.5604
Run:02 Epoch: 0701 loss_train: 14.7018 loss_val: 11.3000
Run:02 Epoch: 0711 loss_train: 9.6175 loss_val: 12.6840
Run:02 Epoch: 0721 loss_train: 18.8716 loss_val: 15.0300
Run:02 Epoch: 0731 loss_train: 13.6941 loss_val: 9.5573
Run:02 Epoch: 0741 loss_train: 12.0602 loss_val: 11.3138
Run:02 Epoch: 0751 loss_train: 18.7485 loss_val: 15.1223
Run:02 Epoch: 0761 loss_train: 10.5858 loss_val: 8.7402
Run:02 Epoch: 0771 loss_train: 19.9369 loss_val: 17.2719
Run:02 Epoch: 0781 loss_train: 12.4268 loss_val: 14.8221
Run:02 Epoch: 0791 loss_train: 10.5033 loss_val: 9.0660
Run:02 Epoch: 0801 loss_train: 25.1197 loss_val: 14.1190
Run:02 Epoch: 0811 loss_train: 9.7686 loss_val: 13.5848
Run:02 Epoch: 0821 loss_train: 9.1828 loss_val: 9.2486
Run:02 Epoch: 0831 loss_train: 8.1877 loss_val: 9.0217
Run:02 Epoch: 0841 loss_train: 6.5383 loss_val: 13.5870
Run:02 Epoch: 0851 loss_train: 12.7314 loss_val: 10.1520
Run:02 Epoch: 0861 loss_train: 22.2981 loss_val: 12.2376
Run:02 Epoch: 0871 loss_train: 10.4482 loss_val: 9.8575
Run:02 Epoch: 0881 loss_train: 14.1258 loss_val: 12.2461
Run:02 Epoch: 0891 loss_train: 10.7401 loss_val: 9.5684
Run:02 Epoch: 0901 loss_train: 12.3979 loss_val: 6.7915
Run:02 Epoch: 0911 loss_train: 7.5503 loss_val: 6.8955
Run:02 Epoch: 0921 loss_train: 6.9058 loss_val: 7.1968
Run:02 Epoch: 0931 loss_train: 6.5568 loss_val: 7.3536
Run:02 Epoch: 0941 loss_train: 3.3671 loss_val: 6.0924
Run:02 Epoch: 0951 loss_train: 8.7724 loss_val: 6.2389
Run:02 Epoch: 0961 loss_train: 6.6460 loss_val: 6.5168
Run:02 Epoch: 0971 loss_train: 14.8438 loss_val: 6.9186
Run:02 Epoch: 0981 loss_train: 4.5864 loss_val: 6.8904
Run:02 Epoch: 0991 loss_train: 10.2752 loss_val: 6.6867
Run:03 Epoch: 0001 loss_train: 4035.1631 loss_val: 11028.7002
Run:03 Epoch: 0011 loss_train: 5710.4966 loss_val: 7989.4683
Run:03 Epoch: 0021 loss_train: 2799.0107 loss_val: 3924.5732
Run:03 Epoch: 0031 loss_train: 1030.2307 loss_val: 46.8207
Run:03 Epoch: 0041 loss_train: 696.4682 loss_val: 946.3048
Run:03 Epoch: 0051 loss_train: 880.2207 loss_val: 398.1378
Run:03 Epoch: 0061 loss_train: 382.0355 loss_val: 351.0391
Run:03 Epoch: 0071 loss_train: 1087.3206 loss_val: 66.0734
Run:03 Epoch: 0081 loss_train: 818.3690 loss_val: 1740.2870
Run:03 Epoch: 0091 loss_train: 320.8264 loss_val: 524.9120
Run:03 Epoch: 0101 loss_train: 438.7580 loss_val: 106.2190
Run:03 Epoch: 0111 loss_train: 511.8261 loss_val: 57.0922
Run:03 Epoch: 0121 loss_train: 384.5458 loss_val: 53.2675
Run:03 Epoch: 0131 loss_train: 257.1557 loss_val: 53.8495
Run:03 Epoch: 0141 loss_train: 228.8860 loss_val: 102.9841
Run:03 Epoch: 0151 loss_train: 191.1046 loss_val: 68.8375
Run:03 Epoch: 0161 loss_train: 405.4020 loss_val: 159.1399
Run:03 Epoch: 0171 loss_train: 189.0464 loss_val: 121.4965
Run:03 Epoch: 0181 loss_train: 128.1526 loss_val: 94.8571
Run:03 Epoch: 0191 loss_train: 427.8416 loss_val: 72.6588
Run:03 Epoch: 0201 loss_train: 359.8592 loss_val: 176.4720
Run:03 Epoch: 0211 loss_train: 409.9534 loss_val: 193.8620
Run:03 Epoch: 0221 loss_train: 274.5564 loss_val: 115.0365
Run:03 Epoch: 0231 loss_train: 170.4358 loss_val: 86.8080
Run:03 Epoch: 0241 loss_train: 110.3363 loss_val: 95.4342
Run:03 Epoch: 0251 loss_train: 123.3038 loss_val: 73.3118
Run:03 Epoch: 0261 loss_train: 130.6978 loss_val: 68.7529
Run:03 Epoch: 0271 loss_train: 107.4658 loss_val: 70.1970
Run:03 Epoch: 0281 loss_train: 134.3056 loss_val: 61.7952
Run:03 Epoch: 0291 loss_train: 61.5532 loss_val: 59.8157
Run:03 Epoch: 0301 loss_train: 161.2598 loss_val: 61.8649
Run:03 Epoch: 0311 loss_train: 85.3772 loss_val: 58.7514
Run:03 Epoch: 0321 loss_train: 52.6246 loss_val: 58.1755
Run:03 Epoch: 0331 loss_train: 224.0985 loss_val: 110.1574
Run:03 Epoch: 0341 loss_train: 64.3350 loss_val: 92.9070
Run:03 Epoch: 0351 loss_train: 98.5501 loss_val: 165.2150
Run:03 Epoch: 0361 loss_train: 67.6560 loss_val: 133.3289
Run:03 Epoch: 0371 loss_train: 64.6463 loss_val: 85.1494
Run:03 Epoch: 0381 loss_train: 84.5750 loss_val: 69.7628
Run:03 Epoch: 0391 loss_train: 86.2923 loss_val: 53.9139
Run:03 Epoch: 0401 loss_train: 58.7548 loss_val: 43.9238
Run:03 Epoch: 0411 loss_train: 69.9466 loss_val: 47.5323
Run:03 Epoch: 0421 loss_train: 34.4580 loss_val: 40.4961
Run:03 Epoch: 0431 loss_train: 37.3724 loss_val: 41.4418
Run:03 Epoch: 0441 loss_train: 59.1372 loss_val: 36.9709
Run:03 Epoch: 0451 loss_train: 43.6897 loss_val: 47.7046
Run:03 Epoch: 0461 loss_train: 36.9314 loss_val: 64.8839
Run:03 Epoch: 0471 loss_train: 34.3841 loss_val: 48.8417
Run:03 Epoch: 0481 loss_train: 25.6312 loss_val: 31.0695
Run:03 Epoch: 0491 loss_train: 83.8197 loss_val: 58.0752
Run:03 Epoch: 0501 loss_train: 43.1657 loss_val: 51.4704
Run:03 Epoch: 0511 loss_train: 30.0658 loss_val: 34.8835
Run:03 Epoch: 0521 loss_train: 34.8456 loss_val: 35.9327
Run:03 Epoch: 0531 loss_train: 37.9347 loss_val: 26.3494
Run:03 Epoch: 0541 loss_train: 44.1346 loss_val: 38.2544
Run:03 Epoch: 0551 loss_train: 19.5747 loss_val: 58.1615
Run:03 Epoch: 0561 loss_train: 33.8884 loss_val: 60.4157
Run:03 Epoch: 0571 loss_train: 34.8294 loss_val: 59.6684
Run:03 Epoch: 0581 loss_train: 28.2307 loss_val: 35.3951
Run:03 Epoch: 0591 loss_train: 13.5696 loss_val: 26.2083
Run:03 Epoch: 0601 loss_train: 22.5217 loss_val: 17.6747
Run:03 Epoch: 0611 loss_train: 18.3364 loss_val: 16.0166
Run:03 Epoch: 0621 loss_train: 48.3380 loss_val: 15.5872
Run:03 Epoch: 0631 loss_train: 27.0495 loss_val: 28.5578
Run:03 Epoch: 0641 loss_train: 13.9112 loss_val: 27.1524
Run:03 Epoch: 0651 loss_train: 20.7438 loss_val: 22.9895
Run:03 Epoch: 0661 loss_train: 18.2234 loss_val: 24.1659
Run:03 Epoch: 0671 loss_train: 11.3336 loss_val: 15.6714
Run:03 Epoch: 0681 loss_train: 17.3221 loss_val: 23.0714
Run:03 Epoch: 0691 loss_train: 16.0040 loss_val: 15.8221
Run:03 Epoch: 0701 loss_train: 31.9404 loss_val: 23.6366
Run:03 Epoch: 0711 loss_train: 23.6121 loss_val: 37.0511
Run:03 Epoch: 0721 loss_train: 20.3512 loss_val: 10.9119
Run:03 Epoch: 0731 loss_train: 8.0915 loss_val: 8.7555
Run:03 Epoch: 0741 loss_train: 19.1070 loss_val: 9.3074
Run:03 Epoch: 0751 loss_train: 31.4357 loss_val: 8.3141
Run:03 Epoch: 0761 loss_train: 20.3499 loss_val: 9.4184
Run:03 Epoch: 0771 loss_train: 7.5628 loss_val: 7.1778
Run:03 Epoch: 0781 loss_train: 10.6871 loss_val: 8.1928
Run:03 Epoch: 0791 loss_train: 12.3302 loss_val: 9.1384
Run:03 Epoch: 0801 loss_train: 7.3510 loss_val: 15.7287
Run:03 Epoch: 0811 loss_train: 6.2482 loss_val: 6.4584
Run:03 Epoch: 0821 loss_train: 5.3678 loss_val: 7.6178
Run:03 Epoch: 0831 loss_train: 7.9008 loss_val: 7.9809
Run:03 Epoch: 0841 loss_train: 6.6410 loss_val: 5.8028
Run:03 Epoch: 0851 loss_train: 15.2951 loss_val: 6.8177
Run:03 Run Train: 100%|██████████| 3/3 [1:13:36<00:00, 1470.79s/it]Run Train: 100%|██████████| 3/3 [1:13:36<00:00, 1472.02s/it]
Epoch: 0861 loss_train: 6.4593 loss_val: 5.2500
Run:03 Epoch: 0871 loss_train: 7.3278 loss_val: 4.9813
Run:03 Epoch: 0881 loss_train: 5.7149 loss_val: 4.9453
Run:03 Epoch: 0891 loss_train: 9.6864 loss_val: 4.7899
Run:03 Epoch: 0901 loss_train: 5.3162 loss_val: 4.4658
Run:03 Epoch: 0911 loss_train: 4.2165 loss_val: 4.3447
Run:03 Epoch: 0921 loss_train: 3.0856 loss_val: 4.6272
Run:03 Epoch: 0931 loss_train: 7.2318 loss_val: 7.7118
Run:03 Epoch: 0941 loss_train: 8.0502 loss_val: 4.4955
Run:03 Epoch: 0951 loss_train: 6.1472 loss_val: 4.1072
Run:03 Epoch: 0961 loss_train: 11.4136 loss_val: 6.1514
Run:03 Epoch: 0971 loss_train: 6.6047 loss_val: 9.0484
Run:03 Epoch: 0981 loss_train: 6.5147 loss_val: 3.9478
Run:03 Epoch: 0991 loss_train: 7.4484 loss_val: 4.1001
test acc: 0.9774774774774775 test acc std 0.012740662724081964


test micro f1: 0.9774774774774775 test macro f1 0.9774733637747337
