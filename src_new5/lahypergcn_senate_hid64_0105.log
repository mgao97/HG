args
 Namespace(samples=4, concat=10, runs=3, latent_size=10, dataset='senate', seed=42, epochs=1000, lr=0.001, weight_decay=0.0005, hidden=64, dropout=0.5, batch_size=128, tem=0.5, lam=1.0, pretrain_epochs=8, pretrain_lr=0.001, conditional=True, update_epochs=20, num_models=100, warmup=200, use_mediator=False, cuda=False)
Hypergraph(num_v=294, num_e=21721)
X dim: torch.Size([294, 294])
labels: 2
Run Train:   0%|          | 0/3 [00:00<?, ?it/s]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Run Train:  33%|███▎      | 1/3 [12:08:24<24:16:48, 43704.07s/it]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Run:01 Epoch: 0001 loss_train: 0.6939 loss_val: 0.6910
Run:01 Epoch: 0011 loss_train: 0.6950 loss_val: 0.6904
Run:01 Epoch: 0021 loss_train: 0.6947 loss_val: 0.6912
Run:01 Epoch: 0031 loss_train: 0.6938 loss_val: 0.6894
Run:01 Epoch: 0041 loss_train: 0.6926 loss_val: 0.6901
Run:01 Epoch: 0051 loss_train: 0.6915 loss_val: 0.6897
Run:01 Epoch: 0061 loss_train: 0.6907 loss_val: 0.6874
Run:01 Epoch: 0071 loss_train: 0.6881 loss_val: 0.6891
Run:01 Epoch: 0081 loss_train: 0.6888 loss_val: 0.6929
Run:01 Epoch: 0091 loss_train: 0.6905 loss_val: 0.6907
Run:01 Epoch: 0101 loss_train: 0.6946 loss_val: 0.6894
Run:01 Epoch: 0111 loss_train: 0.6962 loss_val: 0.6944
Run:01 Epoch: 0121 loss_train: 0.6938 loss_val: 0.6938
Run:01 Epoch: 0131 loss_train: 0.7094 loss_val: 0.7070
Run:01 Epoch: 0141 loss_train: 0.7043 loss_val: 0.7003
Run:01 Epoch: 0151 loss_train: 0.7073 loss_val: 0.7207
Run:01 Epoch: 0161 loss_train: 0.7011 loss_val: 0.7035
Run:01 Epoch: 0171 loss_train: 0.7058 loss_val: 0.6857
Run:01 Epoch: 0181 loss_train: 0.7042 loss_val: 0.7037
Run:01 Epoch: 0191 loss_train: 0.7052 loss_val: 0.7140
Run:01 Epoch: 0201 loss_train: 0.7132 loss_val: 0.7165
Run:01 Epoch: 0211 loss_train: 0.7073 loss_val: 0.7056
Run:01 Epoch: 0221 loss_train: 0.7055 loss_val: 0.6957
Run:01 Epoch: 0231 loss_train: 0.7035 loss_val: 0.7083
Run:01 Epoch: 0241 loss_train: 0.6969 loss_val: 0.7059
Run:01 Epoch: 0251 loss_train: 0.7080 loss_val: 0.7163
Run:01 Epoch: 0261 loss_train: 0.7003 loss_val: 0.7240
Run:01 Epoch: 0271 loss_train: 0.6986 loss_val: 0.7067
Run:01 Epoch: 0281 loss_train: 0.7021 loss_val: 0.7084
Run:01 Epoch: 0291 loss_train: 0.7055 loss_val: 0.7114
Run:01 Epoch: 0301 loss_train: 0.7047 loss_val: 0.7190
Run:01 Epoch: 0311 loss_train: 0.6971 loss_val: 0.6988
Run:01 Epoch: 0321 loss_train: 0.7055 loss_val: 0.6976
Run:01 Epoch: 0331 loss_train: 0.7036 loss_val: 0.7226
Run:01 Epoch: 0341 loss_train: 0.6998 loss_val: 0.7091
Run:01 Epoch: 0351 loss_train: 0.7038 loss_val: 0.7127
Run:01 Epoch: 0361 loss_train: 0.6987 loss_val: 0.7180
Run:01 Epoch: 0371 loss_train: 0.7100 loss_val: 0.7032
Run:01 Epoch: 0381 loss_train: 0.6966 loss_val: 0.7293
Run:01 Epoch: 0391 loss_train: 0.7040 loss_val: 0.7247
Run:01 Epoch: 0401 loss_train: 0.6984 loss_val: 0.7091
Run:01 Epoch: 0411 loss_train: 0.6921 loss_val: 0.7097
Run:01 Epoch: 0421 loss_train: 0.6989 loss_val: 0.7271
Run:01 Epoch: 0431 loss_train: 0.6951 loss_val: 0.7129
Run:01 Epoch: 0441 loss_train: 0.7001 loss_val: 0.6785
Run:01 Epoch: 0451 loss_train: 0.7081 loss_val: 0.7366
Run:01 Epoch: 0461 loss_train: 0.7005 loss_val: 0.7143
Run:01 Epoch: 0471 loss_train: 0.7084 loss_val: 0.7133
Run:01 Epoch: 0481 loss_train: 0.7039 loss_val: 0.7308
Run:01 Epoch: 0491 loss_train: 0.6998 loss_val: 0.7059
Run:01 Epoch: 0501 loss_train: 0.7000 loss_val: 0.7116
Run:01 Epoch: 0511 loss_train: 0.6986 loss_val: 0.7222
Run:01 Epoch: 0521 loss_train: 0.6909 loss_val: 0.7215
Run:01 Epoch: 0531 loss_train: 0.6974 loss_val: 0.7048
Run:01 Epoch: 0541 loss_train: 0.6986 loss_val: 0.7540
Run:01 Epoch: 0551 loss_train: 0.6997 loss_val: 0.7367
Run:01 Epoch: 0561 loss_train: 0.6982 loss_val: 0.7199
Run:01 Epoch: 0571 loss_train: 0.6992 loss_val: 0.7048
Run:01 Epoch: 0581 loss_train: 0.6959 loss_val: 0.6982
Run:01 Epoch: 0591 loss_train: 0.6869 loss_val: 0.7130
Run:01 Epoch: 0601 loss_train: 0.6952 loss_val: 0.7450
Run:01 Epoch: 0611 loss_train: 0.6906 loss_val: 0.7247
Run:01 Epoch: 0621 loss_train: 0.6959 loss_val: 0.7060
Run:01 Epoch: 0631 loss_train: 0.6954 loss_val: 0.7240
Run:01 Epoch: 0641 loss_train: 0.6929 loss_val: 0.7145
Run:01 Epoch: 0651 loss_train: 0.6885 loss_val: 0.7573
Run:01 Epoch: 0661 loss_train: 0.6860 loss_val: 0.7510
Run:01 Epoch: 0671 loss_train: 0.7018 loss_val: 0.7037
Run:01 Epoch: 0681 loss_train: 0.6944 loss_val: 0.7131
Run:01 Epoch: 0691 loss_train: 0.6872 loss_val: 0.7158
Run:01 Epoch: 0701 loss_train: 0.6893 loss_val: 0.7339
Run:01 Epoch: 0711 loss_train: 0.7034 loss_val: 0.7441
Run:01 Epoch: 0721 loss_train: 0.7013 loss_val: 0.7439
Run:01 Epoch: 0731 loss_train: 0.7066 loss_val: 0.7238
Run:01 Epoch: 0741 loss_train: 0.6990 loss_val: 0.7512
Run:01 Epoch: 0751 loss_train: 0.6958 loss_val: 0.7461
Run:01 Epoch: 0761 loss_train: 0.7049 loss_val: 0.7211
Run:01 Epoch: 0771 loss_train: 0.7057 loss_val: 0.7282
Run:01 Epoch: 0781 loss_train: 0.6992 loss_val: 0.7245
Run:01 Epoch: 0791 loss_train: 0.7041 loss_val: 0.7281
Run:01 Epoch: 0801 loss_train: 0.6946 loss_val: 0.7260
Run:01 Epoch: 0811 loss_train: 0.6899 loss_val: 0.7248
Run:01 Epoch: 0821 loss_train: 0.6944 loss_val: 0.7071
Run:01 Epoch: 0831 loss_train: 0.6997 loss_val: 0.7163
Run:01 Epoch: 0841 loss_train: 0.7049 loss_val: 0.7150
Run:01 Epoch: 0851 loss_train: 0.6800 loss_val: 0.7101
Run:01 Epoch: 0861 loss_train: 0.6996 loss_val: 0.7240
Run:01 Epoch: 0871 loss_train: 0.6894 loss_val: 0.7215
Run:01 Epoch: 0881 loss_train: 0.7020 loss_val: 0.7208
Run:01 Epoch: 0891 loss_train: 0.6968 loss_val: 0.7093
Run:01 Epoch: 0901 loss_train: 0.6978 loss_val: 0.7158
Run:01 Epoch: 0911 loss_train: 0.6971 loss_val: 0.7148
Run:01 Epoch: 0921 loss_train: 0.6848 loss_val: 0.7166
Run:01 Epoch: 0931 loss_train: 0.6926 loss_val: 0.7215
Run:01 Epoch: 0941 loss_train: 0.6944 loss_val: 0.7185
Run:01 Epoch: 0951 loss_train: 0.7023 loss_val: 0.7063
Run:01 Epoch: 0961 loss_train: 0.6926 loss_val: 0.7147
Run:01 Epoch: 0971 loss_train: 0.6990 loss_val: 0.7199
Run:01 Epoch: 0981 loss_train: 0.6961 loss_val: 0.7016
Run:01 Epoch: 0991 loss_train: 0.6937 loss_val: 0.7149
Run:02 Epoch: 0001 loss_train: 0.6933 loss_val: 0.6924
Run:02 Epoch: 0011 loss_train: 0.6938 loss_val: 0.6911
Run:02 Epoch: 0021 loss_train: 0.6926 loss_val: 0.6912
Run:02 Epoch: 0031 loss_train: 0.6912 loss_val: 0.6914
Run:02 Epoch: 0041 loss_train: 0.6907 loss_val: 0.6888
Run:02 Epoch: 0051 loss_train: 0.6900 loss_val: 0.6926
Run:02 Epoch: 0061 loss_train: 0.6889 loss_val: 0.6942
Run:02 Epoch: 0071 loss_train: 0.6864 loss_val: 0.6895
Run:02 Epoch: 0081 loss_train: 0.6859 loss_val: 0.6886
Run:02 Epoch: 0091 loss_train: 0.6876 loss_val: 0.6899
Run:02 Epoch: 0101 loss_train: 0.6869 loss_val: 0.6898
Run:02 Epoch: 0111 loss_train: 0.6922 loss_val: 0.6993
Run:02 Epoch: 0121 loss_train: 0.6980 loss_val: 0.7010
Run:02 Epoch: 0131 loss_train: 0.6914 loss_val: 0.6968
Run:02 Epoch: 0141 loss_train: 0.6945 loss_val: 0.7018
Run:02 Epoch: 0151 loss_train: 0.6946 loss_val: 0.7098
Run:02 Epoch: 0161 loss_train: 0.6937 loss_val: 0.7034
Run:02 Epoch: 0171 loss_train: 0.6938 loss_val: 0.7135
Run:02 Epoch: 0181 loss_train: 0.7038 loss_val: 0.7164
Run:02 Epoch: 0191 loss_train: 0.6963 loss_val: 0.7017
Run:02 Epoch: 0201 loss_train: 0.6845 loss_val: 0.7072
Run:02 Epoch: 0211 loss_train: 0.6753 loss_val: 0.6783
Run:02 Epoch: 0221 loss_train: 0.6923 loss_val: 0.6961
Run:02 Epoch: 0231 loss_train: 0.6876 loss_val: 0.6982
Run:02 Epoch: 0241 loss_train: 0.6913 loss_val: 0.6910
Run:02 Epoch: 0251 loss_train: 0.6980 loss_val: 0.7026
Run:02 Epoch: 0261 loss_train: 0.6870 loss_val: 0.6811
Run:02 Epoch: 0271 loss_train: 0.7034 loss_val: 0.6921
Run:02 Epoch: 0281 loss_train: 0.6877 loss_val: 0.6900
Run:02 Epoch: 0291 loss_train: 0.6972 loss_val: 0.6922
Run:02 Epoch: 0301 loss_train: 0.6835 loss_val: 0.6955
Run:02 Epoch: 0311 loss_train: 0.6898 loss_val: 0.6972
Run:02 Epoch: 0321 loss_train: 0.6985 loss_val: 0.7154
Run:02 Epoch: 0331 loss_train: 0.6814 loss_val: 0.6844
Run:02 Epoch: 0341 loss_train: 0.6921 loss_val: 0.6803
Run:02 Epoch: 0351 loss_train: 0.7066 loss_val: 0.7107
Run:02 Epoch: 0361 loss_train: 0.6805 loss_val: 0.6809
Run:02 Epoch: 0371 loss_train: 0.7036 loss_val: 0.7096
Run:02 Epoch: 0381 loss_train: 0.6876 loss_val: 0.6910
Run:02 Epoch: 0391 loss_train: 0.7023 loss_val: 0.6825
Run:02 Epoch: 0401 loss_train: 0.6874 loss_val: 0.7015
Run:02 Epoch: 0411 loss_train: 0.6861 loss_val: 0.6910
Run:02 Epoch: 0421 loss_train: 0.6967 loss_val: 0.7029
Run:02 Epoch: 0431 loss_train: 0.6967 loss_val: 0.6803
Run:02 Epoch: 0441 loss_train: 0.6944 loss_val: 0.6926
Run:02 Epoch: 0451 loss_train: 0.6932 loss_val: 0.6854
Run:02 Epoch: 0461 loss_train: 0.6848 loss_val: 0.6947
Run:02 Epoch: 0471 loss_train: 0.6880 loss_val: 0.6809
Run:02 Epoch: 0481 loss_train: 0.6966 Run Train:  67%|██████▋   | 2/3 [24:20:12<12:10:24, 43824.27s/it]/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_val: 0.6833
Run:02 Epoch: 0491 loss_train: 0.6895 loss_val: 0.6979
Run:02 Epoch: 0501 loss_train: 0.6990 loss_val: 0.7039
Run:02 Epoch: 0511 loss_train: 0.6986 loss_val: 0.7034
Run:02 Epoch: 0521 loss_train: 0.6882 loss_val: 0.6869
Run:02 Epoch: 0531 loss_train: 0.6938 loss_val: 0.6802
Run:02 Epoch: 0541 loss_train: 0.7000 loss_val: 0.6954
Run:02 Epoch: 0551 loss_train: 0.6937 loss_val: 0.7004
Run:02 Epoch: 0561 loss_train: 0.6952 loss_val: 0.6895
Run:02 Epoch: 0571 loss_train: 0.6984 loss_val: 0.6731
Run:02 Epoch: 0581 loss_train: 0.6903 loss_val: 0.6960
Run:02 Epoch: 0591 loss_train: 0.6916 loss_val: 0.6744
Run:02 Epoch: 0601 loss_train: 0.6877 loss_val: 0.6781
Run:02 Epoch: 0611 loss_train: 0.6920 loss_val: 0.6921
Run:02 Epoch: 0621 loss_train: 0.6903 loss_val: 0.6929
Run:02 Epoch: 0631 loss_train: 0.6974 loss_val: 0.6894
Run:02 Epoch: 0641 loss_train: 0.6852 loss_val: 0.6811
Run:02 Epoch: 0651 loss_train: 0.6859 loss_val: 0.7069
Run:02 Epoch: 0661 loss_train: 0.6944 loss_val: 0.6897
Run:02 Epoch: 0671 loss_train: 0.7002 loss_val: 0.6816
Run:02 Epoch: 0681 loss_train: 0.7000 loss_val: 0.6962
Run:02 Epoch: 0691 loss_train: 0.6954 loss_val: 0.6802
Run:02 Epoch: 0701 loss_train: 0.6892 loss_val: 0.6975
Run:02 Epoch: 0711 loss_train: 0.6843 loss_val: 0.6833
Run:02 Epoch: 0721 loss_train: 0.6971 loss_val: 0.7116
Run:02 Epoch: 0731 loss_train: 0.6826 loss_val: 0.6888
Run:02 Epoch: 0741 loss_train: 0.6881 loss_val: 0.7000
Run:02 Epoch: 0751 loss_train: 0.6878 loss_val: 0.6909
Run:02 Epoch: 0761 loss_train: 0.6979 loss_val: 0.6914
Run:02 Epoch: 0771 loss_train: 0.6850 loss_val: 0.6915
Run:02 Epoch: 0781 loss_train: 0.6908 loss_val: 0.6748
Run:02 Epoch: 0791 loss_train: 0.7034 loss_val: 0.6954
Run:02 Epoch: 0801 loss_train: 0.6874 loss_val: 0.6799
Run:02 Epoch: 0811 loss_train: 0.6941 loss_val: 0.6794
Run:02 Epoch: 0821 loss_train: 0.6967 loss_val: 0.6766
Run:02 Epoch: 0831 loss_train: 0.6993 loss_val: 0.6916
Run:02 Epoch: 0841 loss_train: 0.6924 loss_val: 0.6829
Run:02 Epoch: 0851 loss_train: 0.6874 loss_val: 0.6697
Run:02 Epoch: 0861 loss_train: 0.6958 loss_val: 0.6885
Run:02 Epoch: 0871 loss_train: 0.6908 loss_val: 0.6737
Run:02 Epoch: 0881 loss_train: 0.6929 loss_val: 0.6777
Run:02 Epoch: 0891 loss_train: 0.6883 loss_val: 0.6727
Run:02 Epoch: 0901 loss_train: 0.7019 loss_val: 0.6966
Run:02 Epoch: 0911 loss_train: 0.6946 loss_val: 0.6569
Run:02 Epoch: 0921 loss_train: 0.6915 loss_val: 0.6926
Run:02 Epoch: 0931 loss_train: 0.6869 loss_val: 0.6774
Run:02 Epoch: 0941 loss_train: 0.6910 loss_val: 0.6701
Run:02 Epoch: 0951 loss_train: 0.6932 loss_val: 0.6879
Run:02 Epoch: 0961 loss_train: 0.6850 loss_val: 0.6665
Run:02 Epoch: 0971 loss_train: 0.6908 loss_val: 0.6795
Run:02 Epoch: 0981 loss_train: 0.6831 loss_val: 0.6935
Run:02 Epoch: 0991 loss_train: 0.6921 loss_val: 0.6696
Run:03 Epoch: 0001 loss_train: 0.6936 loss_val: 0.6917
Run:03 Epoch: 0011 loss_train: 0.6945 loss_val: 0.6907
Run:03 Epoch: 0021 loss_train: 0.6956 loss_val: 0.6894
Run:03 Epoch: 0031 loss_train: 0.6941 loss_val: 0.6901
Run:03 Epoch: 0041 loss_train: 0.6900 loss_val: 0.6911
Run:03 Epoch: 0051 loss_train: 0.6888 loss_val: 0.6916
Run:03 Epoch: 0061 loss_train: 0.6879 loss_val: 0.6896
Run:03 Epoch: 0071 loss_train: 0.6860 loss_val: 0.6943
Run:03 Epoch: 0081 loss_train: 0.6898 loss_val: 0.6954
Run:03 Epoch: 0091 loss_train: 0.6907 loss_val: 0.6919
Run:03 Epoch: 0101 loss_train: 0.6953 loss_val: 0.6998
Run:03 Epoch: 0111 loss_train: 0.6956 loss_val: 0.6947
Run:03 Epoch: 0121 loss_train: 0.7006 loss_val: 0.7094
Run:03 Epoch: 0131 loss_train: 0.6909 loss_val: 0.7041
Run:03 Epoch: 0141 loss_train: 0.6841 loss_val: 0.6995
Run:03 Epoch: 0151 loss_train: 0.6888 loss_val: 0.6904
Run:03 Epoch: 0161 loss_train: 0.6890 loss_val: 0.6965
Run:03 Epoch: 0171 loss_train: 0.6892 loss_val: 0.6960
Run:03 Epoch: 0181 loss_train: 0.6990 loss_val: 0.6946
Run:03 Epoch: 0191 loss_train: 0.6925 loss_val: 0.7019
Run:03 Epoch: 0201 loss_train: 0.6927 loss_val: 0.6920
Run:03 Epoch: 0211 loss_train: 0.6925 loss_val: 0.6978
Run:03 Epoch: 0221 loss_train: 0.6963 loss_val: 0.7082
Run:03 Epoch: 0231 loss_train: 0.6863 loss_val: 0.6843
Run:03 Epoch: 0241 loss_train: 0.6945 loss_val: 0.7059
Run:03 Epoch: 0251 loss_train: 0.6797 loss_val: 0.6844
Run:03 Epoch: 0261 loss_train: 0.6792 loss_val: 0.6853
Run:03 Epoch: 0271 loss_train: 0.6940 loss_val: 0.6893
Run:03 Epoch: 0281 loss_train: 0.6913 loss_val: 0.6893
Run:03 Epoch: 0291 loss_train: 0.6841 loss_val: 0.6810
Run:03 Epoch: 0301 loss_train: 0.6988 loss_val: 0.6899
Run:03 Epoch: 0311 loss_train: 0.6909 loss_val: 0.6912
Run:03 Epoch: 0321 loss_train: 0.6835 loss_val: 0.6865
Run:03 Epoch: 0331 loss_train: 0.7006 loss_val: 0.6847
Run:03 Epoch: 0341 loss_train: 0.6883 loss_val: 0.6937
Run:03 Epoch: 0351 loss_train: 0.6881 loss_val: 0.6843
Run:03 Epoch: 0361 loss_train: 0.6834 loss_val: 0.6813
Run:03 Epoch: 0371 loss_train: 0.7022 loss_val: 0.6929
Run:03 Epoch: 0381 loss_train: 0.6857 loss_val: 0.6754
Run:03 Epoch: 0391 loss_train: 0.7104 loss_val: 0.6957
Run:03 Epoch: 0401 loss_train: 0.6843 loss_val: 0.6826
Run:03 Epoch: 0411 loss_train: 0.6916 loss_val: 0.7137
Run:03 Epoch: 0421 loss_train: 0.6876 loss_val: 0.6775
Run:03 Epoch: 0431 loss_train: 0.6753 loss_val: 0.6850
Run:03 Epoch: 0441 loss_train: 0.6960 loss_val: 0.6814
Run:03 Epoch: 0451 loss_train: 0.7002 loss_val: 0.6891
Run:03 Epoch: 0461 loss_train: 0.6927 loss_val: 0.6834
Run:03 Epoch: 0471 loss_train: 0.6900 loss_val: 0.6819
Run:03 Epoch: 0481 loss_train: 0.6856 loss_val: 0.6642
Run:03 Epoch: 0491 loss_train: 0.6918 loss_val: 0.6961
Run:03 Epoch: 0501 loss_train: 0.6945 loss_val: 0.6929
Run:03 Epoch: 0511 loss_train: 0.6862 loss_val: 0.6820
Run:03 Epoch: 0521 loss_train: 0.6889 loss_val: 0.6870
Run:03 Epoch: 0531 loss_train: 0.6951 loss_val: 0.6725
Run:03 Epoch: 0541 loss_train: 0.6905 loss_val: 0.6851
Run:03 Epoch: 0551 loss_train: 0.6890 loss_val: 0.6871
Run:03 Epoch: 0561 loss_train: 0.6923 loss_val: 0.6712
Run:03 Epoch: 0571 loss_train: 0.6936 loss_val: 0.7015
Run:03 Epoch: 0581 loss_train: 0.6906 loss_val: 0.6857
Run:03 Epoch: 0591 loss_train: 0.6905 loss_val: 0.7029
Run:03 Epoch: 0601 loss_train: 0.6877 loss_val: 0.6711
Run:03 Epoch: 0611 loss_train: 0.6881 loss_val: 0.6908
Run:03 Epoch: 0621 loss_train: 0.6954 loss_val: 0.6861
Run:03 Epoch: 0631 loss_train: 0.6865 loss_val: 0.6900
Run:03 Epoch: 0641 loss_train: 0.6868 loss_val: 0.6593
Run:03 Epoch: 0651 loss_train: 0.6909 loss_val: 0.6883
Run:03 Epoch: 0661 loss_train: 0.6977 loss_val: 0.6806
Run:03 Epoch: 0671 loss_train: 0.6846 loss_val: 0.6623
Run:03 Epoch: 0681 loss_train: 0.6941 loss_val: 0.6899
Run:03 Epoch: 0691 loss_train: 0.6870 loss_val: 0.6924
Run:03 Epoch: 0701 loss_train: 0.6875 loss_val: 0.6819
Run:03 Epoch: 0711 loss_train: 0.7002 loss_val: 0.6838
Run:03 Epoch: 0721 loss_train: 0.6873 loss_val: 0.6815
Run:03 Epoch: 0731 loss_train: 0.6936 loss_val: 0.6699
Run:03 Epoch: 0741 loss_train: 0.6962 loss_val: 0.6800
Run:03 Epoch: 0751 loss_train: 0.6877 loss_val: 0.6818
Run:03 Epoch: 0761 loss_train: 0.6985 loss_val: 0.6878
Run:03 Epoch: 0771 loss_train: 0.6884 loss_val: 0.6691
Run:03 Epoch: 0781 loss_train: 0.6898 loss_val: 0.6750
Run:03 Epoch: 0791 loss_train: 0.6943 loss_val: 0.6754
Run:03 Epoch: 0801 loss_train: 0.6897 loss_val: 0.6820
Run:03 Epoch: 0811 loss_train: 0.6886 loss_val: 0.6879
Run:03 Epoch: 0821 loss_train: 0.7026 loss_val: 0.6846
Run:03 Epoch: 0831 loss_train: 0.6792 loss_val: 0.6589
Run:03 Epoch: 0841 loss_train: 0.6909 loss_val: 0.6803
Run:03 Epoch: 0851 loss_train: 0.6896 loss_val: 0.6915
Run:03 Epoch: 0861 loss_train: 0.6881 loss_val: 0.6754
Run:03 Epoch: 0871 loss_train: 0.6927 loss_val: 0.6607
Run:03 Epoch: 0881 loss_train: 0.6881 loss_val: 0.6727
Run:03 Epoch: 0891 loss_train: 0.6865 loss_val: 0.6787
Run:03 Epoch: 0901 loss_train: 0.6960 loss_val: 0.6935
Run:03 Epoch: 0911 loss_train: 0.6847 loss_val: 0.6783
Run:03 Epoch: 0921 loss_train: 0.6939 loss_val: 0.6837
Run:03 Epoch: 0931 loss_train: 0.6867 loss_val: 0.6822
Run:03 Epoch: 0941 loss_train: 0.6914 loss_val: 0.6946
Run:03 Epoch: 0951 loss_train: 0.6827 loss_val: 0.6833
Run:03 Epoch: 0961 loss_train: 0.6991 loss_val: 0.6959
Run:03 Epoch: 0971 Run Train: 100%|██████████| 3/3 [36:28:00<00:00, 43752.70s/it]   Run Train: 100%|██████████| 3/3 [36:28:00<00:00, 43760.00s/it]
loss_train: 0.6896 loss_val: 0.6932
Run:03 Epoch: 0981 loss_train: 0.6852 loss_val: 0.6965
Run:03 Epoch: 0991 loss_train: 0.6922 loss_val: 0.6684
test acc: 0.5405405405405405 test acc std 0.02919252566850387


test micro f1: 0.5405405405405405 test macro f1 0.5287948213260847
