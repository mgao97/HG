args
 Namespace(batch_size=128, concat=10, conditional=True, cuda=True, dataset='cora', dropout=0.5, epochs=1500, hidden=256, lam=1.0, latent_size=10, lr=0.01, num_models=100, pretrain_epochs=15, pretrain_lr=0.05, runs=3, samples=4, seed=42, tem=0.5, update_epochs=20, warmup=200, weight_decay=0.0005)
This is cocitation_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data.
Run Train:   0%|                                                                                                                                          | 0/3 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.9463 loss_val: 1.9178
Run:01 Epoch: 0002 loss_train: 1.9186 loss_val: 1.9208
Run:01 Epoch: 0003 loss_train: 1.9244 loss_val: 1.9175
Run:01 Epoch: 0004 loss_train: 1.9558 loss_val: 1.9398
Run:01 Epoch: 0005 loss_train: 2.0035 loss_val: 1.9115
Run:01 Epoch: 0006 loss_train: 1.9668 loss_val: 1.8980
Run:01 Epoch: 0007 loss_train: 1.9458 loss_val: 1.9008
Run:01 Epoch: 0008 loss_train: 1.9509 loss_val: 1.9182
Run:01 Epoch: 0009 loss_train: 1.9704 loss_val: 1.9117
Run:01 Epoch: 0010 loss_train: 1.9620 loss_val: 1.8888
Run:01 Epoch: 0011 loss_train: 1.9339 loss_val: 1.8747
Run:01 Epoch: 0012 loss_train: 1.9171 loss_val: 1.8753
Run:01 Epoch: 0013 loss_train: 1.9235 loss_val: 1.8852
Run:01 Epoch: 0014 loss_train: 1.9357 loss_val: 1.8675
Run:01 Epoch: 0015 loss_train: 1.9173 loss_val: 1.8441
Run:01 Epoch: 0016 loss_train: 1.8881 loss_val: 1.8337
Run:01 Epoch: 0017 loss_train: 1.8796 loss_val: 1.8311
Run:01 Epoch: 0018 loss_train: 1.8803 loss_val: 1.8134
Run:01 Epoch: 0019 loss_train: 1.8540 loss_val: 1.7890
Run:01 Epoch: 0020 loss_train: 1.8228 loss_val: 1.7689
Run:01 Epoch: 0021 loss_train: 1.8029 loss_val: 1.7612
Run:01 Epoch: 0022 loss_train: 1.7931 loss_val: 1.7380
Run:01 Epoch: 0023 loss_train: 1.7678 loss_val: 1.7193
Run:01 Epoch: 0024 loss_train: 1.7430 loss_val: 1.6959
Run:01 Epoch: 0025 loss_train: 1.7232 loss_val: 1.6734
Run:01 Epoch: 0026 loss_train: 1.6971 loss_val: 1.6550
Run:01 Epoch: 0027 loss_train: 1.6775 loss_val: 1.6357
Run:01 Epoch: 0028 loss_train: 1.6574 loss_val: 1.6118
Run:01 Epoch: 0029 loss_train: 1.6322 loss_val: 1.5896
Run:01 Epoch: 0030 loss_train: 1.6107 loss_val: 1.5756
Run:01 Epoch: 0031 loss_train: 1.5908 loss_val: 1.5541
Run:01 Epoch: 0032 loss_train: 1.5700 loss_val: 1.5340
Run:01 Epoch: 0033 loss_train: 1.5512 loss_val: 1.5217
Run:01 Epoch: 0034 loss_train: 1.5420 loss_val: 1.5087
Run:01 Epoch: 0035 loss_train: 1.5302 loss_val: 1.5008
Run:01 Epoch: 0036 loss_train: 1.5306 loss_val: 1.4819
Run:01 Epoch: 0037 loss_train: 1.5047 loss_val: 1.4693
Run:01 Epoch: 0038 loss_train: 1.4965 loss_val: 1.4714
Run:01 Epoch: 0039 loss_train: 1.4892 loss_val: 1.4501
Run:01 Epoch: 0040 loss_train: 1.4786 loss_val: 1.4476
Run:01 Epoch: 0041 loss_train: 1.4722 loss_val: 1.4357
Run:01 Epoch: 0042 loss_train: 1.4613 loss_val: 1.4256
Run:01 Epoch: 0043 loss_train: 1.4552 loss_val: 1.4079
Run:01 Epoch: 0044 loss_train: 1.4440 loss_val: 1.4117
Run:01 Epoch: 0045 loss_train: 1.4455 loss_val: 1.4089
Run:01 Epoch: 0046 loss_train: 1.4277 loss_val: 1.4086
Run:01 Epoch: 0047 loss_train: 1.4305 loss_val: 1.3853
Run:01 Epoch: 0048 loss_train: 1.4176 loss_val: 1.3859
Run:01 Epoch: 0049 loss_train: 1.4195 loss_val: 1.3744
Run:01 Epoch: 0050 loss_train: 1.4075 loss_val: 1.3941
Run:01 Epoch: 0051 loss_train: 1.4085 loss_val: 1.3659
Run:01 Epoch: 0052 loss_train: 1.4021 loss_val: 1.3621
Run:01 Epoch: 0053 loss_train: 1.3999 loss_val: 1.3617
Run:01 Epoch: 0054 loss_train: 1.3856 loss_val: 1.3562
Run:01 Epoch: 0055 loss_train: 1.3845 loss_val: 1.3541
Run:01 Epoch: 0056 loss_train: 1.3768 loss_val: 1.3454
Run:01 Epoch: 0057 loss_train: 1.3780 loss_val: 1.3454
Run:01 Epoch: 0058 loss_train: 1.3671 loss_val: 1.3294
Run:01 Epoch: 0059 loss_train: 1.3629 loss_val: 1.3406
Run:01 Epoch: 0060 loss_train: 1.3614 loss_val: 1.3311
Run:01 Epoch: 0061 loss_train: 1.3643 loss_val: 1.3310
Run:01 Epoch: 0062 loss_train: 1.3537 loss_val: 1.3271
Run:01 Epoch: 0063 loss_train: 1.3524 loss_val: 1.3250
Run:01 Epoch: 0064 loss_train: 1.3476 loss_val: 1.3264
Run:01 Epoch: 0065 loss_train: 1.3462 loss_val: 1.3175
Run:01 Epoch: 0066 loss_train: 1.3381 loss_val: 1.3133
Run:01 Epoch: 0067 loss_train: 1.3394 loss_val: 1.3017
Run:01 Epoch: 0068 loss_train: 1.3361 loss_val: 1.3103
Run:01 Epoch: 0069 loss_train: 1.3330 loss_val: 1.3055
Run:01 Epoch: 0070 loss_train: 1.3260 loss_val: 1.3015
Run:01 Epoch: 0071 loss_train: 1.3236 loss_val: 1.2987
Run:01 Epoch: 0072 loss_train: 1.3189 loss_val: 1.3045
Run:01 Epoch: 0073 loss_train: 1.3170 loss_val: 1.2935
Run:01 Epoch: 0074 loss_train: 1.3136 loss_val: 1.2991
Run:01 Epoch: 0075 loss_train: 1.3133 loss_val: 1.2992
Run:01 Epoch: 0076 loss_train: 1.3062 loss_val: 1.2900
Run:01 Epoch: 0077 loss_train: 1.3044 loss_val: 1.2876
Run:01 Epoch: 0078 loss_train: 1.3077 loss_val: 1.2792
Run:01 Epoch: 0079 loss_train: 1.2996 loss_val: 1.2831
Run:01 Epoch: 0080 loss_train: 1.2983 loss_val: 1.2773
Run:01 Epoch: 0081 loss_train: 1.2959 loss_val: 1.2851
Run:01 Epoch: 0082 loss_train: 1.2909 loss_val: 1.2808
Run:01 Epoch: 0083 loss_train: 1.2888 loss_val: 1.2710
Run:01 Epoch: 0084 loss_train: 1.2878 loss_val: 1.2713
Run:01 Epoch: 0085 loss_train: 1.2871 loss_val: 1.2623
Run:01 Epoch: 0086 loss_train: 1.2831 loss_val: 1.2635
Run:01 Epoch: 0087 loss_train: 1.2777 loss_val: 1.2695
Run:01 Epoch: 0088 loss_train: 1.2787 loss_val: 1.2647
Run:01 Epoch: 0089 loss_train: 1.2741 loss_val: 1.2572
Run:01 Epoch: 0090 loss_train: 1.2746 loss_val: 1.2596
Run:01 Epoch: 0091 loss_train: 1.2665 loss_val: 1.2565
Run:01 Epoch: 0092 loss_train: 1.2671 loss_val: 1.2603
Run:01 Epoch: 0093 loss_train: 1.2646 loss_val: 1.2507
Run:01 Epoch: 0094 loss_train: 1.2628 loss_val: 1.2499
Run:01 Epoch: 0095 loss_train: 1.2639 loss_val: 1.2517
Run:01 Epoch: 0096 loss_train: 1.2598 loss_val: 1.2463
Run:01 Epoch: 0097 loss_train: 1.2573 loss_val: 1.2471
Run:01 Epoch: 0098 loss_train: 1.2552 loss_val: 1.2450
Run:01 Epoch: 0099 loss_train: 1.2508 loss_val: 1.2412
Run:01 Epoch: 0100 loss_train: 1.2524 loss_val: 1.2370
Run:01 Epoch: 0101 loss_train: 1.2486 loss_val: 1.2427
Run:01 Epoch: 0102 loss_train: 1.2493 loss_val: 1.2413
Run:01 Epoch: 0103 loss_train: 1.2484 loss_val: 1.2393
Run:01 Epoch: 0104 loss_train: 1.2444 loss_val: 1.2307
Run:01 Epoch: 0105 loss_train: 1.2433 loss_val: 1.2348
Run:01 Epoch: 0106 loss_train: 1.2408 loss_val: 1.2343
Run:01 Epoch: 0107 loss_train: 1.2379 loss_val: 1.2350
Run:01 Epoch: 0108 loss_train: 1.2355 loss_val: 1.2300
Run:01 Epoch: 0109 loss_train: 1.2350 loss_val: 1.2324
Run:01 Epoch: 0110 loss_train: 1.2335 loss_val: 1.2318
Run:01 Epoch: 0111 loss_train: 1.2329 loss_val: 1.2245
Run:01 Epoch: 0112 loss_train: 1.2265 loss_val: 1.2248
Run:01 Epoch: 0113 loss_train: 1.2290 loss_val: 1.2236
Run:01 Epoch: 0114 loss_train: 1.2247 loss_val: 1.2237
Run:01 Epoch: 0115 loss_train: 1.2248 loss_val: 1.2257
Run:01 Epoch: 0116 loss_train: 1.2253 loss_val: 1.2220
Run:01 Epoch: 0117 loss_train: 1.2268 loss_val: 1.2243
Run:01 Epoch: 0118 loss_train: 1.2227 loss_val: 1.2167
Run:01 Epoch: 0119 loss_train: 1.2233 loss_val: 1.2212
Run:01 Epoch: 0120 loss_train: 1.2201 loss_val: 1.2190
Run:01 Epoch: 0121 loss_train: 1.2205 loss_val: 1.2161
Run:01 Epoch: 0122 loss_train: 1.2185 loss_val: 1.2164
Run:01 Epoch: 0123 loss_train: 1.2212 loss_val: 1.2153
Run:01 Epoch: 0124 loss_train: 1.2168 loss_val: 1.2181
Run:01 Epoch: 0125 loss_train: 1.2164 loss_val: 1.2151
Run:01 Epoch: 0126 loss_train: 1.2164 loss_val: 1.2151
Run:01 Epoch: 0127 loss_train: 1.2146 loss_val: 1.2199
Run:01 Epoch: 0128 loss_train: 1.2151 loss_val: 1.2180
Run:01 Epoch: 0129 loss_train: 1.2133 loss_val: 1.2117
Run:01 Epoch: 0130 loss_train: 1.2132 loss_val: 1.2163
Run:01 Epoch: 0131 loss_train: 1.2132 loss_val: 1.2112
Run:01 Epoch: 0132 loss_train: 1.2123 loss_val: 1.2171
Run:01 Epoch: 0133 loss_train: 1.2125 loss_val: 1.2127
Run:01 Epoch: 0134 loss_train: 1.2098 loss_val: 1.2080
Run:01 Epoch: 0135 loss_train: 1.2091 loss_val: 1.2111
Run:01 Epoch: 0136 loss_train: 1.2082 loss_val: 1.2103
Run:01 Epoch: 0137 loss_train: 1.2079 loss_val: 1.2044
Run:01 Epoch: 0138 loss_train: 1.2091 loss_val: 1.2081
Run:01 Epoch: 0139 loss_train: 1.2088 loss_val: 1.2113
Run:01 Epoch: 0140 loss_train: 1.2086 loss_val: 1.2121
Run:01 Epoch: 0141 loss_train: 1.2067 loss_val: 1.2184
Run:01 Epoch: 0142 loss_train: 1.2076 loss_val: 1.2032
Run:01 Epoch: 0143 loss_train: 1.2068 loss_val: 1.2099
Run:01 Epoch: 0144 loss_train: 1.2110 loss_val: 1.2124
Run:01 Epoch: 0145 loss_train: 1.2059 loss_val: 1.2125
Run:01 Epoch: 0146 loss_train: 1.2064 loss_val: 1.2108
Run:01 Epoch: 0147 loss_train: 1.2041 loss_val: 1.2074
Run:01 Epoch: 0148 loss_train: 1.2052 loss_val: 1.2138
Run:01 Epoch: 0149 loss_train: 1.2041 loss_val: 1.2113
Run:01 Epoch: 0150 loss_train: 1.2058 loss_val: 1.2076
Run:01 Epoch: 0151 loss_train: 1.2023 loss_val: 1.2056
Run:01 Epoch: 0152 loss_train: 1.2028 loss_val: 1.2109
Run:01 Epoch: 0153 loss_train: 1.2021 loss_val: 1.2076
Run:01 Epoch: 0154 loss_train: 1.2026 loss_val: 1.2118
Run:01 Epoch: 0155 loss_train: 1.2023 loss_val: 1.2086
Run:01 Epoch: 0156 loss_train: 1.2025 loss_val: 1.2085
Run:01 Epoch: 0157 loss_train: 1.2007 loss_val: 1.2145
Run:01 Epoch: 0158 loss_train: 1.2028 loss_val: 1.2087
Run:01 Epoch: 0159 loss_train: 1.2017 loss_val: 1.2080
Run:01 Epoch: 0160 loss_train: 1.2017 loss_val: 1.2070
Run:01 Epoch: 0161 loss_train: 1.2016 loss_val: 1.2091
Run:01 Epoch: 0162 loss_train: 1.2019 loss_val: 1.2116
Run:01 Epoch: 0163 loss_train: 1.1999 loss_val: 1.2128
Run:01 Epoch: 0164 loss_train: 1.2007 loss_val: 1.2028
Run:01 Epoch: 0165 loss_train: 1.1997 loss_val: 1.2110
Run:01 Epoch: 0166 loss_train: 1.2015 loss_val: 1.2095
Run:01 Epoch: 0167 loss_train: 1.1997 loss_val: 1.2066
Run:01 Epoch: 0168 loss_train: 1.1998 loss_val: 1.2054
Run:01 Epoch: 0169 loss_train: 1.1953 loss_val: 1.2099
Run:01 Epoch: 0170 loss_train: 1.2000 loss_val: 1.2012
Run:01 Epoch: 0171 loss_train: 1.2006 loss_val: 1.2059
Run:01 Epoch: 0172 loss_train: 1.1967 loss_val: 1.2078
Run:01 Epoch: 0173 loss_train: 1.1981 loss_val: 1.2068
Run:01 Epoch: 0174 loss_train: 1.1977 loss_val: 1.2059
Run:01 Epoch: 0175 loss_train: 1.1958 loss_val: 1.2073
Run:01 Epoch: 0176 loss_train: 1.1984 loss_val: 1.2072
Run:01 Epoch: 0177 loss_train: 1.1981 loss_val: 1.2079
Run:01 Epoch: 0178 loss_train: 1.1965 loss_val: 1.2030
Run:01 Epoch: 0179 loss_train: 1.1998 loss_val: 1.2031
Run:01 Epoch: 0180 loss_train: 1.1982 loss_val: 1.2096
Run:01 Epoch: 0181 loss_train: 1.1973 loss_val: 1.2078
Run:01 Epoch: 0182 loss_train: 1.1998 loss_val: 1.2049
Run:01 Epoch: 0183 loss_train: 1.1951 loss_val: 1.2015
Run:01 Epoch: 0184 loss_train: 1.1962 loss_val: 1.2079
Run:01 Epoch: 0185 loss_train: 1.1966 loss_val: 1.2049
Run:01 Epoch: 0186 loss_train: 1.1965 loss_val: 1.2081
Run:01 Epoch: 0187 loss_train: 1.1972 loss_val: 1.2066
Run:01 Epoch: 0188 loss_train: 1.1959 loss_val: 1.2082
Run:01 Epoch: 0189 loss_train: 1.1960 loss_val: 1.2042
Run:01 Epoch: 0190 loss_train: 1.1981 loss_val: 1.2085
Run:01 Epoch: 0191 loss_train: 1.1952 loss_val: 1.2050
Run:01 Epoch: 0192 loss_train: 1.1954 loss_val: 1.2064
Run:01 Epoch: 0193 loss_train: 1.1936 loss_val: 1.2102
Run:01 Epoch: 0194 loss_train: 1.1977 loss_val: 1.2040
Run:01 Epoch: 0195 loss_train: 1.1963 loss_val: 1.2053
Run:01 Epoch: 0196 loss_train: 1.1960 loss_val: 1.2051
Run:01 Epoch: 0197 loss_train: 1.1979 loss_val: 1.2023
Run:01 Epoch: 0198 loss_train: 1.1948 loss_val: 1.2050
Run:01 Epoch: 0199 loss_train: 1.1942 loss_val: 1.2049
Run:01 Epoch: 0200 loss_train: 1.1965 loss_val: 1.2022
Run:01 Epoch: 0201 loss_train: 1.1958 loss_val: 1.2089
Run:01 Epoch: 0202 loss_train: 1.1967 loss_val: 1.2074
Run:01 Epoch: 0203 loss_train: 1.1949 loss_val: 1.2046
Run:01 Epoch: 0204 loss_train: 1.1969 loss_val: 1.2017
Run:01 Epoch: 0205 loss_train: 1.1935 loss_val: 1.2117
Run:01 Epoch: 0206 loss_train: 1.1944 loss_val: 1.2022
Run:01 Epoch: 0207 loss_train: 1.1939 loss_val: 1.2058
Run:01 Epoch: 0208 loss_train: 1.1963 loss_val: 1.2075
Run:01 Epoch: 0209 loss_train: 1.1949 loss_val: 1.2089
Run:01 Epoch: 0210 loss_train: 1.1940 loss_val: 1.2043
Run:01 Epoch: 0211 loss_train: 1.1931 loss_val: 1.2008
Run:01 Epoch: 0212 loss_train: 1.1976 loss_val: 1.2088
Run:01 Epoch: 0213 loss_train: 1.1957 loss_val: 1.2033
Run:01 Epoch: 0214 loss_train: 1.1944 loss_val: 1.2034
Run:01 Epoch: 0215 loss_train: 1.1952 loss_val: 1.1985
Run:01 Epoch: 0216 loss_train: 1.1961 loss_val: 1.2049
Run:01 Epoch: 0217 loss_train: 1.1948 loss_val: 1.2082
Run:01 Epoch: 0218 loss_train: 1.1935 loss_val: 1.2038
Run:01 Epoch: 0219 loss_train: 1.1951 loss_val: 1.2064
Run:01 Epoch: 0220 loss_train: 1.1940 loss_val: 1.2062
Run:01 Epoch: 0221 loss_train: 1.1939 loss_val: 1.2038
Run:01 Epoch: 0222 loss_train: 1.1943 loss_val: 1.2032
Run:01 Epoch: 0223 loss_train: 1.1932 loss_val: 1.2010
Run:01 Epoch: 0224 loss_train: 1.1941 loss_val: 1.2032
Run:01 Epoch: 0225 loss_train: 1.1946 loss_val: 1.2079
Run:01 Epoch: 0226 loss_train: 1.1926 loss_val: 1.2066
Run:01 Epoch: 0227 loss_train: 1.1930 loss_val: 1.1998
Run:01 Epoch: 0228 loss_train: 1.1933 loss_val: 1.2050
Run:01 Epoch: 0229 loss_train: 1.1924 loss_val: 1.2051
Run:01 Epoch: 0230 loss_train: 1.1920 loss_val: 1.2088
Run:01 Epoch: 0231 loss_train: 1.1959 loss_val: 1.2065
Run:01 Epoch: 0232 loss_train: 1.1930 loss_val: 1.2051
Run:01 Epoch: 0233 loss_train: 1.1942 loss_val: 1.2063
Run:01 Epoch: 0234 loss_train: 1.1951 loss_val: 1.2029
Run:01 Epoch: 0235 loss_train: 1.1953 loss_val: 1.2063
Run:01 Epoch: 0236 loss_train: 1.1947 loss_val: 1.1998
Run:01 Epoch: 0237 loss_train: 1.1945 loss_val: 1.2072
Run:01 Epoch: 0238 loss_train: 1.1926 loss_val: 1.1992
Run:01 Epoch: 0239 loss_train: 1.1915 loss_val: 1.2023
Run:01 Epoch: 0240 loss_train: 1.1922 loss_val: 1.2063
Run:01 Epoch: 0241 loss_train: 1.1924 loss_val: 1.2022
Run:01 Epoch: 0242 loss_train: 1.1898 loss_val: 1.2051
Run:01 Epoch: 0243 loss_train: 1.1940 loss_val: 1.2050
Run:01 Epoch: 0244 loss_train: 1.1910 loss_val: 1.2032
Run:01 Epoch: 0245 loss_train: 1.1941 loss_val: 1.2041
Run:01 Epoch: 0246 loss_train: 1.1938 loss_val: 1.2049
Run:01 Epoch: 0247 loss_train: 1.1948 loss_val: 1.2049
Run:01 Epoch: 0248 loss_train: 1.1932 loss_val: 1.2111
Run:01 Epoch: 0249 loss_train: 1.1923 loss_val: 1.2051
Run:01 Epoch: 0250 loss_train: 1.1926 loss_val: 1.2079
Run:01 Epoch: 0251 loss_train: 1.1924 loss_val: 1.2035
Run:01 Epoch: 0252 loss_train: 1.1926 loss_val: 1.2002
Run:01 Epoch: 0253 loss_train: 1.1885 loss_val: 1.2044
Run:01 Epoch: 0254 loss_train: 1.1931 loss_val: 1.2085
Run:01 Epoch: 0255 loss_train: 1.1941 loss_val: 1.2039
Run:01 Epoch: 0256 loss_train: 1.1919 loss_val: 1.2025
Run:01 Epoch: 0257 loss_train: 1.1916 loss_val: 1.2005
Run:01 Epoch: 0258 loss_train: 1.1916 loss_val: 1.2015
Run:01 Epoch: 0259 loss_train: 1.1910 loss_val: 1.2058
Run:01 Epoch: 0260 loss_train: 1.1913 loss_val: 1.2083
Run:01 Epoch: 0261 loss_train: 1.1934 loss_val: 1.2024
Run:01 Epoch: 0262 loss_train: 1.1921 loss_val: 1.2046
Run:01 Epoch: 0263 loss_train: 1.1922 loss_val: 1.2055
Run:01 Epoch: 0264 loss_train: 1.1915 loss_val: 1.2045
Run:01 Epoch: 0265 loss_train: 1.1913 loss_val: 1.2024
Run:01 Epoch: 0266 loss_train: 1.1901 loss_val: 1.2060
Run:01 Epoch: 0267 loss_train: 1.1902 loss_val: 1.2026
Run:01 Epoch: 0268 loss_train: 1.1890 loss_val: 1.2037
Run:01 Epoch: 0269 loss_train: 1.1904 loss_val: 1.2031
Run:01 Epoch: 0270 loss_train: 1.1920 loss_val: 1.2056
Run:01 Epoch: 0271 loss_train: 1.1923 loss_val: 1.2058
Run:01 Epoch: 0272 loss_train: 1.1923 loss_val: 1.2022
Run:01 Epoch: 0273 loss_train: 1.1937 loss_val: 1.2068
Run:01 Epoch: 0274 loss_train: 1.1919 loss_val: 1.2040
Run:01 Epoch: 0275 loss_train: 1.1905 loss_val: 1.2080
Run:01 Epoch: 0276 loss_train: 1.1938 loss_val: 1.2083
Run:01 Epoch: 0277 loss_train: 1.1933 loss_val: 1.2080
Run:01 Epoch: 0278 loss_train: 1.1929 loss_val: 1.2043
Run:01 Epoch: 0279 loss_train: 1.1908 loss_val: 1.2057
Run:01 Epoch: 0280 loss_train: 1.1911 loss_val: 1.2111
Run:01 Epoch: 0281 loss_train: 1.1922 loss_val: 1.2026
Run:01 Epoch: 0282 loss_train: 1.1909 loss_val: 1.2026
Run:01 Epoch: 0283 loss_train: 1.1926 loss_val: 1.2063
Run:01 Epoch: 0284 loss_train: 1.1914 loss_val: 1.2087
Run:01 Epoch: 0285 loss_train: 1.1931 loss_val: 1.2084
Run:01 Epoch: 0286 loss_train: 1.1905 loss_val: 1.2043
Run:01 Epoch: 0287 loss_train: 1.1918 loss_val: 1.2042
Run:01 Epoch: 0288 loss_train: 1.1907 loss_val: 1.2050
Run:01 Epoch: 0289 loss_train: 1.1921 loss_val: 1.2036
Run:01 Epoch: 0290 loss_train: 1.1903 loss_val: 1.2059
Run:01 Epoch: 0291 loss_train: 1.1935 loss_val: 1.2009
Run:01 Epoch: 0292 loss_train: 1.1914 loss_val: 1.2011
Run:01 Epoch: 0293 loss_train: 1.1875 loss_val: 1.1998
Run:01 Epoch: 0294 loss_train: 1.1917 loss_val: 1.2018
Run:01 Epoch: 0295 loss_train: 1.1917 loss_val: 1.2088
Run:01 Epoch: 0296 loss_train: 1.1899 loss_val: 1.2083
Run:01 Epoch: 0297 loss_train: 1.1898 loss_val: 1.2041
Run:01 Epoch: 0298 loss_train: 1.1890 loss_val: 1.2063
Run:01 Epoch: 0299 loss_train: 1.1930 loss_val: 1.2033
Run:01 Epoch: 0300 loss_train: 1.1934 loss_val: 1.2039
Run:01 Epoch: 0301 loss_train: 1.1909 loss_val: 1.1991
Run:01 Epoch: 0302 loss_train: 1.1919 loss_val: 1.2060
Run:01 Epoch: 0303 loss_train: 1.1876 loss_val: 1.2098
Run:01 Epoch: 0304 loss_train: 1.1899 loss_val: 1.2088
Run:01 Epoch: 0305 loss_train: 1.1908 loss_val: 1.2071
Run:01 Epoch: 0306 loss_train: 1.1921 loss_val: 1.2067
Run:01 Epoch: 0307 loss_train: 1.1902 loss_val: 1.2021
Run:01 Epoch: 0308 loss_train: 1.1926 loss_val: 1.2077
Run:01 Epoch: 0309 loss_train: 1.1908 loss_val: 1.2023
Run:01 Epoch: 0310 loss_train: 1.1893 loss_val: 1.2034
Run:01 Epoch: 0311 loss_train: 1.1894 loss_val: 1.2018
Run:01 Epoch: 0312 loss_train: 1.1922 loss_val: 1.2064
Run:01 Epoch: 0313 loss_train: 1.1898 loss_val: 1.2073
Run:01 Epoch: 0314 loss_train: 1.1886 loss_val: 1.2014
Run:01 Epoch: 0315 loss_train: 1.1944 loss_val: 1.2058
Run:01 Epoch: 0316 loss_train: 1.1903 loss_val: 1.2049
Run:01 Epoch: 0317 loss_train: 1.1914 loss_val: 1.2057
Run:01 Epoch: 0318 loss_train: 1.1891 loss_val: 1.2039
Run:01 Epoch: 0319 loss_train: 1.1929 loss_val: 1.2003
Run:01 Epoch: 0320 loss_train: 1.1899 loss_val: 1.2006
Run:01 Epoch: 0321 loss_train: 1.1920 loss_val: 1.1998
Run:01 Epoch: 0322 loss_train: 1.1899 loss_val: 1.2037
Run:01 Epoch: 0323 loss_train: 1.1909 loss_val: 1.2062
Run:01 Epoch: 0324 loss_train: 1.1900 loss_val: 1.2017
Run:01 Epoch: 0325 loss_train: 1.1885 loss_val: 1.2006
Run:01 Epoch: 0326 loss_train: 1.1907 loss_val: 1.2036
Run:01 Epoch: 0327 loss_train: 1.1913 loss_val: 1.2094
Run:01 Epoch: 0328 loss_train: 1.1903 loss_val: 1.2034
Run:01 Epoch: 0329 loss_train: 1.1915 loss_val: 1.2019
Run:01 Epoch: 0330 loss_train: 1.1920 loss_val: 1.2058
Run:01 Epoch: 0331 loss_train: 1.1924 loss_val: 1.2032
Run:01 Epoch: 0332 loss_train: 1.1932 loss_val: 1.2063
Run:01 Epoch: 0333 loss_train: 1.1910 loss_val: 1.2028
Run:01 Epoch: 0334 loss_train: 1.1919 loss_val: 1.2047
Run:01 Epoch: 0335 loss_train: 1.1908 loss_val: 1.1997
Run:01 Epoch: 0336 loss_train: 1.1900 loss_val: 1.2024
Run:01 Epoch: 0337 loss_train: 1.1881 loss_val: 1.2040
Run:01 Epoch: 0338 loss_train: 1.1899 loss_val: 1.2016
Run:01 Epoch: 0339 loss_train: 1.1910 loss_val: 1.2062
Run:01 Epoch: 0340 loss_train: 1.1921 loss_val: 1.2043
Run:01 Epoch: 0341 loss_train: 1.1901 loss_val: 1.2033
Run:01 Epoch: 0342 loss_train: 1.1908 loss_val: 1.2002
Run:01 Epoch: 0343 loss_train: 1.1899 loss_val: 1.2026
Run:01 Epoch: 0344 loss_train: 1.1892 loss_val: 1.2047
Run:01 Epoch: 0345 loss_train: 1.1908 loss_val: 1.2026
Run:01 Epoch: 0346 loss_train: 1.1896 loss_val: 1.2047
Run:01 Epoch: 0347 loss_train: 1.1904 loss_val: 1.2032
Run:01 Epoch: 0348 loss_train: 1.1932 loss_val: 1.2062
Run:01 Epoch: 0349 loss_train: 1.1913 loss_val: 1.2065
Run:01 Epoch: 0350 loss_train: 1.1901 loss_val: 1.2002
Run:01 Epoch: 0351 loss_train: 1.1884 loss_val: 1.2021
Run:01 Epoch: 0352 loss_train: 1.1897 loss_val: 1.2030
Run:01 Epoch: 0353 loss_train: 1.1926 loss_val: 1.2110
Run:01 Epoch: 0354 loss_train: 1.1853 loss_val: 1.2030
Run:01 Epoch: 0355 loss_train: 1.1913 loss_val: 1.2039
Run:01 Epoch: 0356 loss_train: 1.1887 loss_val: 1.2042
Run:01 Epoch: 0357 loss_train: 1.1911 loss_val: 1.2060
Run:01 Epoch: 0358 loss_train: 1.1923 loss_val: 1.2068
Run:01 Epoch: 0359 loss_train: 1.1914 loss_val: 1.2062
Run:01 Epoch: 0360 loss_train: 1.1907 loss_val: 1.2029
Run:01 Epoch: 0361 loss_train: 1.1895 loss_val: 1.2006
Run:01 Epoch: 0362 loss_train: 1.1909 loss_val: 1.2087
Run:01 Epoch: 0363 loss_train: 1.1882 loss_val: 1.2045
Run:01 Epoch: 0364 loss_train: 1.1884 loss_val: 1.2028
Run:01 Epoch: 0365 loss_train: 1.1910 loss_val: 1.2045
Run:01 Epoch: 0366 loss_train: 1.1897 loss_val: 1.2059
Run:01 Epoch: 0367 loss_train: 1.1906 loss_val: 1.2092
Run:01 Epoch: 0368 loss_train: 1.1907 loss_val: 1.2047
Run:01 Epoch: 0369 loss_train: 1.1887 loss_val: 1.1987
Run:01 Epoch: 0370 loss_train: 1.1883 loss_val: 1.2027
Run:01 Epoch: 0371 loss_train: 1.1907 loss_val: 1.2036
Run:01 Epoch: 0372 loss_train: 1.1886 loss_val: 1.2041
Run:01 Epoch: 0373 loss_train: 1.1912 loss_val: 1.2071
Run:01 Epoch: 0374 loss_train: 1.1898 loss_val: 1.2071
Run:01 Epoch: 0375 loss_train: 1.1912 loss_val: 1.2034
Run:01 Epoch: 0376 loss_train: 1.1905 loss_val: 1.2033
Run:01 Epoch: 0377 loss_train: 1.1888 loss_val: 1.2061
Run:01 Epoch: 0378 loss_train: 1.1893 loss_val: 1.2008
Run:01 Epoch: 0379 loss_train: 1.1902 loss_val: 1.2032
Run:01 Epoch: 0380 loss_train: 1.1888 loss_val: 1.2093
Run:01 Epoch: 0381 loss_train: 1.1901 loss_val: 1.2031
Run:01 Epoch: 0382 loss_train: 1.1903 loss_val: 1.2038
Run:01 Epoch: 0383 loss_train: 1.1882 loss_val: 1.2043
Run:01 Epoch: 0384 loss_train: 1.1905 loss_val: 1.2008
Run:01 Epoch: 0385 loss_train: 1.1898 loss_val: 1.2025
Run:01 Epoch: 0386 loss_train: 1.1895 loss_val: 1.2027
Run:01 Epoch: 0387 loss_train: 1.1908 loss_val: 1.2027
Run:01 Epoch: 0388 loss_train: 1.1880 loss_val: 1.2040
Run:01 Epoch: 0389 loss_train: 1.1871 loss_val: 1.2054
Run:01 Epoch: 0390 loss_train: 1.1922 loss_val: 1.2039
Run:01 Epoch: 0391 loss_train: 1.1909 loss_val: 1.2070
Run:01 Epoch: 0392 loss_train: 1.1922 loss_val: 1.2045
Run:01 Epoch: 0393 loss_train: 1.1887 loss_val: 1.2014
Run:01 Epoch: 0394 loss_train: 1.1932 loss_val: 1.2002
Run:01 Epoch: 0395 loss_train: 1.1916 loss_val: 1.2063
Run:01 Epoch: 0396 loss_train: 1.1896 loss_val: 1.2006
Run:01 Epoch: 0397 loss_train: 1.1894 loss_val: 1.2035
Run:01 Epoch: 0398 loss_train: 1.1904 loss_val: 1.2059
Run:01 Epoch: 0399 loss_train: 1.1876 loss_val: 1.1991
Run:01 Epoch: 0400 loss_train: 1.1907 loss_val: 1.2050
Run:01 Epoch: 0401 loss_train: 1.1908 loss_val: 1.2039
Run:01 Epoch: 0402 loss_train: 1.1918 loss_val: 1.2073
Run:01 Epoch: 0403 loss_train: 1.1905 loss_val: 1.2065
Run:01 Epoch: 0404 loss_train: 1.1898 loss_val: 1.2072
Run:01 Epoch: 0405 loss_train: 1.1903 loss_val: 1.1992
Run:01 Epoch: 0406 loss_train: 1.1862 loss_val: 1.2022
Run:01 Epoch: 0407 loss_train: 1.1900 loss_val: 1.2012
Run:01 Epoch: 0408 loss_train: 1.1916 loss_val: 1.2049
Run:01 Epoch: 0409 loss_train: 1.1910 loss_val: 1.2046
Run:01 Epoch: 0410 loss_train: 1.1912 loss_val: 1.2023
Run:01 Epoch: 0411 loss_train: 1.1927 loss_val: 1.2031
Run:01 Epoch: 0412 loss_train: 1.1907 loss_val: 1.2055
Run:01 Epoch: 0413 loss_train: 1.1893 loss_val: 1.2047
Run:01 Epoch: 0414 loss_train: 1.1878 loss_val: 1.2048
Run:01 Epoch: 0415 loss_train: 1.1899 loss_val: 1.2037
Run:01 Epoch: 0416 loss_train: 1.1920 loss_val: 1.2053
Run:01 Epoch: 0417 loss_train: 1.1906 loss_val: 1.2077
Run:01 Epoch: 0418 loss_train: 1.1880 loss_val: 1.2080
Run:01 Epoch: 0419 loss_train: 1.1924 loss_val: 1.2027
Run:01 Epoch: 0420 loss_train: 1.1893 loss_val: 1.2066
Run:01 Epoch: 0421 loss_train: 1.1912 loss_val: 1.2079
Run:01 Epoch: 0422 loss_train: 1.1874 loss_val: 1.2052
Run:01 Epoch: 0423 loss_train: 1.1882 loss_val: 1.2088
Run:01 Epoch: 0424 loss_train: 1.1905 loss_val: 1.2047
Run:01 Epoch: 0425 loss_train: 1.1890 loss_val: 1.2002
Run:01 Epoch: 0426 loss_train: 1.1917 loss_val: 1.2035
Run:01 Epoch: 0427 loss_train: 1.1859 loss_val: 1.2067
Run:01 Epoch: 0428 loss_train: 1.1905 loss_val: 1.2079
Run:01 Epoch: 0429 loss_train: 1.1918 loss_val: 1.2024
Run:01 Epoch: 0430 loss_train: 1.1882 loss_val: 1.2022
Run:01 Epoch: 0431 loss_train: 1.1897 loss_val: 1.2012
Run:01 Epoch: 0432 loss_train: 1.1898 loss_val: 1.2062
Run:01 Epoch: 0433 loss_train: 1.1906 loss_val: 1.2025
Run:01 Epoch: 0434 loss_train: 1.1906 loss_val: 1.1985
Run:01 Epoch: 0435 loss_train: 1.1867 loss_val: 1.2020
Run:01 Epoch: 0436 loss_train: 1.1898 loss_val: 1.2021
Run:01 Epoch: 0437 loss_train: 1.1910 loss_val: 1.2048
Run:01 Epoch: 0438 loss_train: 1.1889 loss_val: 1.2067
Run:01 Epoch: 0439 loss_train: 1.1907 loss_val: 1.2014
Run:01 Epoch: 0440 loss_train: 1.1894 loss_val: 1.1975
Run:01 Epoch: 0441 loss_train: 1.1876 loss_val: 1.2034
Run:01 Epoch: 0442 loss_train: 1.1898 loss_val: 1.2025
Run:01 Epoch: 0443 loss_train: 1.1874 loss_val: 1.2105
Run:01 Epoch: 0444 loss_train: 1.1886 loss_val: 1.1996
Run:01 Epoch: 0445 loss_train: 1.1905 loss_val: 1.1987
Run:01 Epoch: 0446 loss_train: 1.1900 loss_val: 1.2027
Run:01 