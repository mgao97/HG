/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
args
 Namespace(samples=4, concat=6, runs=2, latent_size=10, dataset='cocitationciteseer', seed=42, epochs=1500, lr=0.0005, weight_decay=0.0005, hidden=64, dropout=0.5, batch_size=128, tem=0.6, lam=1.0, pretrain_epochs=8, pretrain_lr=0.005, conditional=True, update_epochs=20, num_models=100, warmup=200, cuda=False)
This is cocitation_citeseer dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data.
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7921 loss_val: 1.7917
Run:01 Epoch: 0011 loss_train: 1.7899 loss_val: 1.7893
Run:01 Epoch: 0021 loss_train: 1.7871 loss_val: 1.7862
Run:01 Epoch: 0031 loss_train: 1.7834 loss_val: 1.7820
Run:01 Epoch: 0041 loss_train: 1.7795 loss_val: 1.7775
Run:01 Epoch: 0051 loss_train: 1.7758 loss_val: 1.7736
Run:01 Epoch: 0061 loss_train: 1.7732 loss_val: 1.7711
Run:01 Epoch: 0071 loss_train: 1.7716 loss_val: 1.7701
Run:01 Epoch: 0081 loss_train: 1.7707 loss_val: 1.7700
Run:01 Epoch: 0091 loss_train: 1.7704 loss_val: 1.7700
Run:01 Epoch: 0101 loss_train: 1.7696 loss_val: 1.7694
Run:01 Epoch: 0111 loss_train: 1.7684 loss_val: 1.7682
Run:01 Epoch: 0121 loss_train: 1.7667 loss_val: 1.7668
Run:01 Epoch: 0131 loss_train: 1.7657 loss_val: 1.7654
Run:01 Epoch: 0141 loss_train: 1.7637 loss_val: 1.7639
Run:01 Epoch: 0151 loss_train: 1.7617 loss_val: 1.7622
Run:01 Epoch: 0161 loss_train: 1.7595 loss_val: 1.7602
Run:01 Epoch: 0171 loss_train: 1.7567 loss_val: 1.7580
Run:01 Epoch: 0181 loss_train: 1.7544 loss_val: 1.7556
Run:01 Epoch: 0191 loss_train: 1.7515 loss_val: 1.7531
Run:01 Epoch: 0201 loss_train: 1.7485 loss_val: 1.7504
Run:01 Epoch: 0211 loss_train: 1.7450 loss_val: 1.7475
Run:01 Epoch: 0221 loss_train: 1.7420 loss_val: 1.7444
Run:01 Epoch: 0231 loss_train: 1.7379 loss_val: 1.7412
Run:01 Epoch: 0241 loss_train: 1.7349 loss_val: 1.7380
Run:01 Epoch: 0251 loss_train: 1.7304 loss_val: 1.7344
Run:01 Epoch: 0261 loss_train: 1.7266 loss_val: 1.7308
Run:01 Epoch: 0271 loss_train: 1.7220 loss_val: 1.7270
Run:01 Epoch: 0281 loss_train: 1.7181 loss_val: 1.7231
Run:01 Epoch: 0291 loss_train: 1.7139 loss_val: 1.7192
Run:01 Epoch: 0301 loss_train: 1.7095 loss_val: 1.7152
Run:01 Epoch: 0311 loss_train: 1.7041 loss_val: 1.7111
Run:01 Epoch: 0321 loss_train: 1.7007 loss_val: 1.7069
Run:01 Epoch: 0331 loss_train: 1.6956 loss_val: 1.7027
Run:01 Epoch: 0341 loss_train: 1.6910 loss_val: 1.6985
Run:01 Epoch: 0351 loss_train: 1.6863 loss_val: 1.6942
Run:01 Epoch: 0361 loss_train: 1.6807 loss_val: 1.6899
Run:01 Epoch: 0371 loss_train: 1.6770 loss_val: 1.6856
Run:01 Epoch: 0381 loss_train: 1.6730 loss_val: 1.6812
Run:01 Epoch: 0391 loss_train: 1.6680 loss_val: 1.6769
Run:01 Epoch: 0401 loss_train: 1.6635 loss_val: 1.6726
Run:01 Epoch: 0411 loss_train: 1.6581 loss_val: 1.6684
Run:01 Epoch: 0421 loss_train: 1.6538 loss_val: 1.6642
Run:01 Epoch: 0431 loss_train: 1.6496 loss_val: 1.6599
Run:01 Epoch: 0441 loss_train: 1.6449 loss_val: 1.6557
Run:01 Epoch: 0451 loss_train: 1.6413 loss_val: 1.6514
Run:01 Epoch: 0461 loss_train: 1.6365 loss_val: 1.6473
Run:01 Epoch: 0471 loss_train: 1.6314 loss_val: 1.6432
Run:01 Epoch: 0481 loss_train: 1.6275 loss_val: 1.6391
Run:01 Epoch: 0491 loss_train: 1.6235 loss_val: 1.6351
Run:01 Epoch: 0501 loss_train: 1.6190 loss_val: 1.6312
Run:01 Epoch: 0511 loss_train: 1.6149 loss_val: 1.6273
Run:01 Epoch: 0521 loss_train: 1.6117 loss_val: 1.6234
Run:01 Epoch: 0531 loss_train: 1.6071 loss_val: 1.6196
Run:01 Epoch: 0541 loss_train: 1.6035 loss_val: 1.6159
Run:01 Epoch: 0551 loss_train: 1.5982 loss_val: 1.6122
Run:01 Epoch: 0561 loss_train: 1.5949 loss_val: 1.6087
Run:01 Epoch: 0571 loss_train: 1.5919 loss_val: 1.6050
Run:01 Epoch: 0581 loss_train: 1.5893 loss_val: 1.6016
Run:01 Epoch: 0591 loss_train: 1.5843 loss_val: 1.5982
Run:01 Epoch: 0601 loss_train: 1.5805 loss_val: 1.5947
Run:01 Epoch: 0611 loss_train: 1.5783 loss_val: 1.5913
Run:01 Epoch: 0621 loss_train: 1.5740 loss_val: 1.5881
Run:01 Epoch: 0631 loss_train: 1.5707 loss_val: 1.5849
Run:01 Epoch: 0641 loss_train: 1.5684 loss_val: 1.5817
Run:01 Epoch: 0651 loss_train: 1.5646 loss_val: 1.5785
Run:01 Epoch: 0661 loss_train: 1.5606 loss_val: 1.5755
Run:01 Epoch: 0671 loss_train: 1.5585 loss_val: 1.5724
Run:01 Epoch: 0681 loss_train: 1.5564 loss_val: 1.5695
Run:01 Epoch: 0691 loss_train: 1.5524 loss_val: 1.5665
Run:01 Epoch: 0701 loss_train: 1.5492 loss_val: 1.5638
Run:01 Epoch: 0711 loss_train: 1.5478 loss_val: 1.5609
Run:01 Epoch: 0721 loss_train: 1.5441 loss_val: 1.5584
Run:01 Epoch: 0731 loss_train: 1.5414 loss_val: 1.5555
Run:01 Epoch: 0741 loss_train: 1.5372 loss_val: 1.5529
Run:01 Epoch: 0751 loss_train: 1.5357 loss_val: 1.5502
Run:01 Epoch: 0761 loss_train: 1.5326 loss_val: 1.5477
Run:01 Epoch: 0771 loss_train: 1.5312 loss_val: 1.5452
Run:01 Epoch: 0781 loss_train: 1.5289 loss_val: 1.5426
Run:01 Epoch: 0791 loss_train: 1.5260 loss_val: 1.5403
Run:01 Epoch: 0801 loss_train: 1.5227 loss_val: 1.5379
Run:01 Epoch: 0811 loss_train: 1.5202 loss_val: 1.5356
Run:01 Epoch: 0821 loss_train: 1.5199 loss_val: 1.5333
Run:01 Epoch: 0831 loss_train: 1.5165 loss_val: 1.5312
Run:01 Epoch: 0841 loss_train: 1.5144 loss_val: 1.5289
Run:01 Epoch: 0851 loss_train: 1.5123 loss_val: 1.5268
Run:01 Epoch: 0861 loss_train: 1.5105 loss_val: 1.5247
Run:01 Epoch: 0871 loss_train: 1.5080 loss_val: 1.5226
Run:01 Epoch: 0881 loss_train: 1.5050 loss_val: 1.5204
Run:01 Epoch: 0891 loss_train: 1.5034 loss_val: 1.5184
Run:01 Epoch: 0901 loss_train: 1.5021 loss_val: 1.5165
Run:01 Epoch: 0911 loss_train: 1.4994 loss_val: 1.5145
Run:01 Epoch: 0921 loss_train: 1.4991 loss_val: 1.5127
Run:01 Epoch: 0931 loss_train: 1.4959 loss_val: 1.5107
Run:01 Epoch: 0941 loss_train: 1.4940 loss_val: 1.5088
Run:01 Epoch: 0951 loss_train: 1.4924 loss_val: 1.5071
Run:01 Epoch: 0961 loss_train: 1.4917 loss_val: 1.5052
Run:01 Epoch: 0971 loss_train: 1.4873 loss_val: 1.5034
Run:01 Epoch: 0981 loss_train: 1.4867 loss_val: 1.5018
Run:01 Epoch: 0991 loss_train: 1.4847 loss_val: 1.5001
Run:01 Epoch: 1001 loss_train: 1.4854 loss_val: 1.4983
Run:01 Epoch: 1011 loss_train: 1.4791 loss_val: 1.4967
Run:01 Epoch: 1021 loss_train: 1.4781 loss_val: 1.4950
Run:01 Epoch: 1031 loss_train: 1.4790 loss_val: 1.4933
Run:01 Epoch: 1041 loss_train: 1.4763 loss_val: 1.4917
Run:01 Epoch: 1051 loss_train: 1.4749 loss_val: 1.4900
Run:01 Epoch: 1061 loss_train: 1.4721 loss_val: 1.4884
Run:01 Epoch: 1071 loss_train: 1.4727 loss_val: 1.4868
Run:01 Epoch: 1081 loss_train: 1.4704 loss_val: 1.4853
Run:01 Epoch: 1091 loss_train: 1.4666 loss_val: 1.4838
Run:01 Epoch: 1101 loss_train: 1.4687 loss_val: 1.4823
Run:01 Epoch: 1111 loss_train: 1.4642 loss_val: 1.4806
Run:01 Epoch: 1121 loss_train: 1.4644 loss_val: 1.4792
Run:01 Epoch: 1131 loss_train: 1.4623 loss_val: 1.4778
Run:01 Epoch: 1141 loss_train: 1.4612 loss_val: 1.4764
Run:01 Epoch: 1151 loss_train: 1.4580 loss_val: 1.4751
Run:01 Epoch: 1161 loss_train: 1.4579 loss_val: 1.4734
Run:01 Epoch: 1171 loss_train: 1.4568 loss_val: 1.4723
Run:01 Epoch: 1181 loss_train: 1.4553 loss_val: 1.4710
Run:01 Epoch: 1191 loss_train: 1.4551 loss_val: 1.4694
Run:01 Epoch: 1201 loss_train: 1.4522 loss_val: 1.4684
Run:01 Epoch: 1211 loss_train: 1.4515 loss_val: 1.4671
Run:01 Epoch: 1221 loss_train: 1.4506 loss_val: 1.4659
Run:01 Epoch: 1231 loss_train: 1.4476 loss_val: 1.4647
Run:01 Epoch: 1241 loss_train: 1.4470 loss_val: 1.4634
Run:01 Epoch: 1251 loss_train: 1.4474 loss_val: 1.4623
Run:01 Epoch: 1261 loss_train: 1.4442 loss_val: 1.4611
Run:01 Epoch: 1271 loss_train: 1.4416 loss_val: 1.4598
Run:01 Epoch: 1281 loss_train: 1.4413 loss_val: 1.4587
Run:01 Epoch: 1291 loss_train: 1.4423 loss_val: 1.4574
Run:01 Epoch: 1301 loss_train: 1.4407 loss_val: 1.4564
Run:01 Epoch: 1311 loss_train: 1.4376 loss_val: 1.4555
Run:01 Epoch: 1321 loss_train: 1.4367 loss_val: 1.4542
Run:01 Epoch: 1331 loss_train: 1.4364 loss_val: 1.4532
Run:01 Epoch: 1341 loss_train: 1.4348 loss_val: 1.4523
Run:01 Epoch: 1351 loss_train: 1.4343 loss_val: 1.4511
Run:01 Epoch: 1361 loss_train: 1.4340 loss_val: 1.4503
Run:01 Epoch: 1371 loss_train: 1.4318 loss_val: 1.4492
Run:01 Epoch: 1381 loss_train: 1.4321 loss_val: 1.4483
Run:01 Epoch: 1391 loss_train: 1.4288 loss_val: 1.4472
Run:01 Epoch: 1401 loss_train: 1.4289 loss_val: 1.4462
Run:01 Epoch: 1411 loss_train: 1.4274 loss_val: 1.4452
Run:01 Epoch: 1421 loss_train: 1.4287 loss_val: 1.4443
Run:01 Epoch: 1431 loss_train: 1.4263 loss_val: 1.4434
Run:01 Epoch: 1441 loss_train: 1.4236 loss_val: 1.4425
Run:01 Epoch: 1451 loss_train: 1.4241 loss_val: 1.4416
Run:01 Epoch: 1461 loss_train: 1.4231 loss_val: 1.4407
Run:01 Epoch: 1471 loss_train: 1.4219 loss_val: 1.4398
Run:01 Epoch: 1481 loss_train: 1.4230 Run Train:  50%|█████     | 1/2 [12:44<12:44, 764.73s/it]loss_val: 1.4391
Run:01 Epoch: 1491 loss_train: 1.4184 loss_val: 1.4382
Run:02 Epoch: 0001 loss_train: 1.4213 loss_val: 1.4373
Run:02 Epoch: 0011 loss_train: 1.4203 loss_val: 1.4367
Run:02 Epoch: 0021 loss_train: 1.4182 loss_val: 1.4360
Run:02 Epoch: 0031 loss_train: 1.4180 loss_val: 1.4352
Run:02 Epoch: 0041 loss_train: 1.4140 loss_val: 1.4343
Run:02 Epoch: 0051 loss_train: 1.4157 loss_val: 1.4334
Run:02 Epoch: 0061 loss_train: 1.4150 loss_val: 1.4328
Run:02 Epoch: 0071 loss_train: 1.4136 loss_val: 1.4319
Run:02 Epoch: 0081 loss_train: 1.4125 loss_val: 1.4312
Run:02 Epoch: 0091 loss_train: 1.4120 loss_val: 1.4308
Run:02 Epoch: 0101 loss_train: 1.4120 loss_val: 1.4299
Run:02 Epoch: 0111 loss_train: 1.4101 loss_val: 1.4290
Run:02 Epoch: 0121 loss_train: 1.4113 loss_val: 1.4285
Run:02 Epoch: 0131 loss_train: 1.4082 loss_val: 1.4277
Run:02 Epoch: 0141 loss_train: 1.4093 loss_val: 1.4270
Run:02 Epoch: 0151 loss_train: 1.4085 loss_val: 1.4261
Run:02 Epoch: 0161 loss_train: 1.4089 loss_val: 1.4257
Run:02 Epoch: 0171 loss_train: 1.4078 loss_val: 1.4250
Run:02 Epoch: 0181 loss_train: 1.4069 loss_val: 1.4244
Run:02 Epoch: 0191 loss_train: 1.4024 loss_val: 1.4237
Run:02 Epoch: 0201 loss_train: 1.4026 loss_val: 1.4232
Run:02 Epoch: 0211 loss_train: 1.4017 loss_val: 1.4224
Run:02 Epoch: 0221 loss_train: 1.4043 loss_val: 1.4217
Run:02 Epoch: 0231 loss_train: 1.4021 loss_val: 1.4211
Run:02 Epoch: 0241 loss_train: 1.4003 loss_val: 1.4205
Run:02 Epoch: 0251 loss_train: 1.3996 loss_val: 1.4200
Run:02 Epoch: 0261 loss_train: 1.4008 loss_val: 1.4193
Run:02 Epoch: 0271 loss_train: 1.3974 loss_val: 1.4186
Run:02 Epoch: 0281 loss_train: 1.3967 loss_val: 1.4181
Run:02 Epoch: 0291 loss_train: 1.3993 loss_val: 1.4174
Run:02 Epoch: 0301 loss_train: 1.3948 loss_val: 1.4169
Run:02 Epoch: 0311 loss_train: 1.3952 loss_val: 1.4163
Run:02 Epoch: 0321 loss_train: 1.3961 loss_val: 1.4157
Run:02 Epoch: 0331 loss_train: 1.3941 loss_val: 1.4152
Run:02 Epoch: 0341 loss_train: 1.3921 loss_val: 1.4146
Run:02 Epoch: 0351 loss_train: 1.3925 loss_val: 1.4139
Run:02 Epoch: 0361 loss_train: 1.3923 loss_val: 1.4138
Run:02 Epoch: 0371 loss_train: 1.3897 loss_val: 1.4131
Run:02 Epoch: 0381 loss_train: 1.3930 loss_val: 1.4123
Run:02 Epoch: 0391 loss_train: 1.3899 loss_val: 1.4122
Run:02 Epoch: 0401 loss_train: 1.3902 loss_val: 1.4116
Run:02 Epoch: 0411 loss_train: 1.3898 loss_val: 1.4110
Run:02 Epoch: 0421 loss_train: 1.3877 loss_val: 1.4105
Run:02 Epoch: 0431 loss_train: 1.3888 loss_val: 1.4100
Run:02 Epoch: 0441 loss_train: 1.3863 loss_val: 1.4095
Run:02 Epoch: 0451 loss_train: 1.3873 loss_val: 1.4090
Run:02 Epoch: 0461 loss_train: 1.3861 loss_val: 1.4084
Run:02 Epoch: 0471 loss_train: 1.3861 loss_val: 1.4083
Run:02 Epoch: 0481 loss_train: 1.3864 loss_val: 1.4078
Run:02 Epoch: 0491 loss_train: 1.3861 loss_val: 1.4074
Run:02 Epoch: 0501 loss_train: 1.3838 loss_val: 1.4070
Run:02 Epoch: 0511 loss_train: 1.3828 loss_val: 1.4064
Run:02 Epoch: 0521 loss_train: 1.3825 loss_val: 1.4058
Run:02 Epoch: 0531 loss_train: 1.3841 loss_val: 1.4054
Run:02 Epoch: 0541 loss_train: 1.3826 loss_val: 1.4052
Run:02 Epoch: 0551 loss_train: 1.3807 loss_val: 1.4045
Run:02 Epoch: 0561 loss_train: 1.3809 loss_val: 1.4044
Run:02 Epoch: 0571 loss_train: 1.3815 loss_val: 1.4038
Run:02 Epoch: 0581 loss_train: 1.3824 loss_val: 1.4033
Run:02 Epoch: 0591 loss_train: 1.3779 loss_val: 1.4032
Run:02 Epoch: 0601 loss_train: 1.3811 loss_val: 1.4027
Run:02 Epoch: 0611 loss_train: 1.3779 loss_val: 1.4022
Run:02 Epoch: 0621 loss_train: 1.3775 loss_val: 1.4020
Run:02 Epoch: 0631 loss_train: 1.3776 loss_val: 1.4017
Run:02 Epoch: 0641 loss_train: 1.3784 loss_val: 1.4013
Run:02 Epoch: 0651 loss_train: 1.3789 loss_val: 1.4009
Run:02 Epoch: 0661 loss_train: 1.3775 loss_val: 1.4004
Run:02 Epoch: 0671 loss_train: 1.3758 loss_val: 1.4002
Run:02 Epoch: 0681 loss_train: 1.3763 loss_val: 1.3996
Run:02 Epoch: 0691 loss_train: 1.3740 loss_val: 1.3992
Run:02 Epoch: 0701 loss_train: 1.3748 loss_val: 1.3991
Run:02 Epoch: 0711 loss_train: 1.3742 loss_val: 1.3987
Run:02 Epoch: 0721 loss_train: 1.3759 loss_val: 1.3984
Run:02 Epoch: 0731 loss_train: 1.3739 loss_val: 1.3979
Run:02 Epoch: 0741 loss_train: 1.3748 loss_val: 1.3976
Run:02 Epoch: 0751 loss_train: 1.3740 loss_val: 1.3972
Run:02 Epoch: 0761 loss_train: 1.3725 loss_val: 1.3970
Run:02 Epoch: 0771 loss_train: 1.3740 loss_val: 1.3967
Run:02 Epoch: 0781 loss_train: 1.3729 loss_val: 1.3962
Run:02 Epoch: 0791 loss_train: 1.3710 loss_val: 1.3961
Run:02 Epoch: 0801 loss_train: 1.3706 loss_val: 1.3957
Run:02 Epoch: 0811 loss_train: 1.3705 loss_val: 1.3956
Run:02 Epoch: 0821 loss_train: 1.3704 loss_val: 1.3952
Run:02 Epoch: 0831 loss_train: 1.3686 loss_val: 1.3949
Run:02 Epoch: 0841 loss_train: 1.3695 loss_val: 1.3948
Run:02 Epoch: 0851 loss_train: 1.3718 loss_val: 1.3945
Run:02 Epoch: 0861 loss_train: 1.3699 loss_val: 1.3942
Run:02 Epoch: 0871 loss_train: 1.3668 loss_val: 1.3938
Run:02 Epoch: 0881 loss_train: 1.3679 loss_val: 1.3935
Run:02 Epoch: 0891 loss_train: 1.3652 loss_val: 1.3931
Run:02 Epoch: 0901 loss_train: 1.3679 loss_val: 1.3929
Run:02 Epoch: 0911 loss_train: 1.3674 loss_val: 1.3928
Run:02 Epoch: 0921 loss_train: 1.3667 loss_val: 1.3923
Run:02 Epoch: 0931 loss_train: 1.3670 loss_val: 1.3922
Run:02 Epoch: 0941 loss_train: 1.3643 loss_val: 1.3919
Run:02 Epoch: 0951 loss_train: 1.3667 loss_val: 1.3914
Run:02 Epoch: 0961 loss_train: 1.3640 loss_val: 1.3913
Run:02 Epoch: 0971 loss_train: 1.3648 loss_val: 1.3912
Run:02 Epoch: 0981 loss_train: 1.3647 loss_val: 1.3908
Run:02 Epoch: 0991 loss_train: 1.3639 loss_val: 1.3906
Run:02 Epoch: 1001 loss_train: 1.3659 loss_val: 1.3904
Run:02 Epoch: 1011 loss_train: 1.3637 loss_val: 1.3901
Run:02 Epoch: 1021 loss_train: 1.3627 loss_val: 1.3896
Run:02 Epoch: 1031 loss_train: 1.3617 loss_val: 1.3896
Run:02 Epoch: 1041 loss_train: 1.3647 loss_val: 1.3893
Run:02 Epoch: 1051 loss_train: 1.3630 loss_val: 1.3892
Run:02 Epoch: 1061 loss_train: 1.3623 loss_val: 1.3889
Run:02 Epoch: 1071 loss_train: 1.3617 loss_val: 1.3890
Run:02 Epoch: 1081 loss_train: 1.3626 loss_val: 1.3886
Run:02 Epoch: 1091 loss_train: 1.3615 loss_val: 1.3884
Run:02 Epoch: 1101 loss_train: 1.3605 loss_val: 1.3883
Run:02 Epoch: 1111 loss_train: 1.3622 loss_val: 1.3877
Run:02 Epoch: 1121 loss_train: 1.3603 loss_val: 1.3877
Run:02 Epoch: 1131 loss_train: 1.3610 loss_val: 1.3874
Run:02 Epoch: 1141 loss_train: 1.3593 loss_val: 1.3872
Run:02 Epoch: 1151 loss_train: 1.3606 loss_val: 1.3872
Run:02 Epoch: 1161 loss_train: 1.3590 loss_val: 1.3869
Run:02 Epoch: 1171 loss_train: 1.3585 loss_val: 1.3866
Run:02 Epoch: 1181 loss_train: 1.3571 loss_val: 1.3867
Run:02 Epoch: 1191 loss_train: 1.3589 loss_val: 1.3863
Run:02 Epoch: 1201 loss_train: 1.3589 loss_val: 1.3861
Run:02 Epoch: 1211 loss_train: 1.3578 loss_val: 1.3860
Run:02 Epoch: 1221 loss_train: 1.3581 loss_val: 1.3856
Run:02 Epoch: 1231 loss_train: 1.3575 loss_val: 1.3856
Run:02 Epoch: 1241 loss_train: 1.3571 loss_val: 1.3855
Run:02 Epoch: 1251 loss_train: 1.3564 loss_val: 1.3853
Run:02 Epoch: 1261 loss_train: 1.3567 loss_val: 1.3850
Run:02 Epoch: 1271 loss_train: 1.3585 loss_val: 1.3849
Run:02 Epoch: 1281 loss_train: 1.3546 loss_val: 1.3846
Run:02 Epoch: 1291 loss_train: 1.3551 loss_val: 1.3845
Run:02 Epoch: 1301 loss_train: 1.3570 loss_val: 1.3843
Run:02 Epoch: 1311 loss_train: 1.3580 loss_val: 1.3840
Run:02 Epoch: 1321 loss_train: 1.3539 loss_val: 1.3839
Run:02 Epoch: 1331 loss_train: 1.3537 loss_val: 1.3835
Run:02 Epoch: 1341 loss_train: 1.3569 loss_val: 1.3837
Run:02 Epoch: 1351 loss_train: 1.3542 loss_val: 1.3831
Run:02 Epoch: 1361 loss_train: 1.3519 loss_val: 1.3831
Run:02 Epoch: 1371 loss_train: 1.3517 loss_val: 1.3832
Run:02 Epoch: 1381 loss_train: 1.3556 loss_val: 1.3827
Run:02 Epoch: 1391 loss_train: 1.3525 loss_val: 1.3826
Run:02 Epoch: 1401 loss_train: 1.3534 loss_val: 1.3827
Run:02 Epoch: 1411 loss_train: 1.3525 loss_val: 1.3823
Run:02 Epoch: 1421 loss_train: 1.3549 loss_val: 1.3824
Run:02 Epoch: 1431 loss_train: 1.3525 loss_val: 1.3820
Run:02 Epoch: 1441 loss_train: 1.3521 loss_val: 1.3819
Run:02 Epoch: 1451 loss_train: 1.3519 loss_val: 1.3817
Run:02 Epoch: 1461 loss_train: 1.3549 loss_val: 1.3817
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [1:52:31<00:00, 3836.54s/it]Run Train: 100%|██████████| 2/2 [1:52:31<00:00, 3375.77s/it]
/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_train: 1.3517 loss_val: 1.3816
Run:02 Epoch: 1481 loss_train: 1.3515 loss_val: 1.3813
Run:02 Epoch: 1491 loss_train: 1.3499 loss_val: 1.3812
test acc: 0.4414251207729469 test acc std 0.0018115942028985588


test micro f1: 0.4414251207729469 test macro f1 0.38220129042730877
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7902 loss_val: 1.7886
Run:01 Epoch: 0011 loss_train: 1.7741 loss_val: 1.7724
Run:01 Epoch: 0021 loss_train: 1.7684 loss_val: 1.7683
Run:01 Epoch: 0031 loss_train: 1.7591 loss_val: 1.7590
Run:01 Epoch: 0041 loss_train: 1.7393 loss_val: 1.7409
Run:01 Epoch: 0051 loss_train: 1.7086 loss_val: 1.7130
Run:01 Epoch: 0061 loss_train: 1.6713 loss_val: 1.6777
Run:01 Epoch: 0071 loss_train: 1.6318 loss_val: 1.6402
Run:01 Epoch: 0081 loss_train: 1.5939 loss_val: 1.6040
Run:01 Epoch: 0091 loss_train: 1.5595 loss_val: 1.5698
Run:01 Epoch: 0101 loss_train: 1.5286 loss_val: 1.5401
Run:01 Epoch: 0111 loss_train: 1.5030 loss_val: 1.5135
Run:01 Epoch: 0121 loss_train: 1.4802 loss_val: 1.4913
Run:01 Epoch: 0131 loss_train: 1.4601 loss_val: 1.4720
Run:01 Epoch: 0141 loss_train: 1.4451 loss_val: 1.4567
Run:01 Epoch: 0151 loss_train: 1.4297 loss_val: 1.4436
Run:01 Epoch: 0161 loss_train: 1.4183 loss_val: 1.4331
Run:01 Epoch: 0171 loss_train: 1.4088 loss_val: 1.4244
Run:01 Epoch: 0181 loss_train: 1.3984 loss_val: 1.4165
Run:01 Epoch: 0191 loss_train: 1.3918 loss_val: 1.4110
Run:01 Epoch: 0201 loss_train: 1.3879 loss_val: 1.4053
Run:01 Epoch: 0211 loss_train: 1.3821 loss_val: 1.4013
Run:01 Epoch: 0221 loss_train: 1.3761 loss_val: 1.3981
Run:01 Epoch: 0231 loss_train: 1.3725 loss_val: 1.3947
Run:01 Epoch: 0241 loss_train: 1.3686 loss_val: 1.3916
Run:01 Epoch: 0251 loss_train: 1.3628 loss_val: 1.3893
Run:01 Epoch: 0261 loss_train: 1.3625 loss_val: 1.3871
Run:01 Epoch: 0271 loss_train: 1.3573 loss_val: 1.3849
Run:01 Epoch: 0281 loss_train: 1.3583 loss_val: 1.3839
Run:01 Epoch: 0291 loss_train: 1.3532 loss_val: 1.3826
Run:01 Epoch: 0301 loss_train: 1.3503 loss_val: 1.3809
Run:01 Epoch: 0311 loss_train: 1.3492 loss_val: 1.3796
Run:01 Epoch: 0321 loss_train: 1.3496 loss_val: 1.3793
Run:01 Epoch: 0331 loss_train: 1.3432 loss_val: 1.3782
Run:01 Epoch: 0341 loss_train: 1.3462 loss_val: 1.3773
Run:01 Epoch: 0351 loss_train: 1.3453 loss_val: 1.3766
Run:01 Epoch: 0361 loss_train: 1.3458 loss_val: 1.3754
Run:01 Epoch: 0371 loss_train: 1.3437 loss_val: 1.3763
Run:01 Epoch: 0381 loss_train: 1.3435 loss_val: 1.3749
Run:01 Epoch: 0391 loss_train: 1.3415 loss_val: 1.3741
Run:01 Epoch: 0401 loss_train: 1.3418 loss_val: 1.3746
Run:01 Epoch: 0411 loss_train: 1.3386 loss_val: 1.3732
Run:01 Epoch: 0421 loss_train: 1.3401 loss_val: 1.3730
Run:01 Epoch: 0431 loss_train: 1.3375 loss_val: 1.3729
Run:01 Epoch: 0441 loss_train: 1.3370 loss_val: 1.3726
Run:01 Epoch: 0451 loss_train: 1.3375 loss_val: 1.3727
Run:01 Epoch: 0461 loss_train: 1.3379 loss_val: 1.3726
Run:01 Epoch: 0471 loss_train: 1.3356 loss_val: 1.3718
Run:01 Epoch: 0481 loss_train: 1.3351 loss_val: 1.3715
Run:01 Epoch: 0491 loss_train: 1.3376 loss_val: 1.3719
Run:01 Epoch: 0501 loss_train: 1.3361 loss_val: 1.3707
Run:01 Epoch: 0511 loss_train: 1.3333 loss_val: 1.3716
Run:01 Epoch: 0521 loss_train: 1.3346 loss_val: 1.3709
Run:01 Epoch: 0531 loss_train: 1.3313 loss_val: 1.3709
Run:01 Epoch: 0541 loss_train: 1.3347 loss_val: 1.3707
Run:01 Epoch: 0551 loss_train: 1.3355 loss_val: 1.3709
Run:01 Epoch: 0561 loss_train: 1.3342 loss_val: 1.3702
Run:01 Epoch: 0571 loss_train: 1.3333 loss_val: 1.3698
Run:01 Epoch: 0581 loss_train: 1.3314 loss_val: 1.3704
Run:01 Epoch: 0591 loss_train: 1.3319 loss_val: 1.3709
Run:01 Epoch: 0601 loss_train: 1.3330 loss_val: 1.3698
Run:01 Epoch: 0611 loss_train: 1.3343 loss_val: 1.3702
Run:01 Epoch: 0621 loss_train: 1.3314 loss_val: 1.3701
Run:01 Epoch: 0631 loss_train: 1.3314 loss_val: 1.3700
Run:01 Epoch: 0641 loss_train: 1.3323 loss_val: 1.3701
Run:01 Epoch: 0651 loss_train: 1.3295 loss_val: 1.3704
Run:01 Epoch: 0661 loss_train: 1.3318 loss_val: 1.3698
Run:01 Epoch: 0671 loss_train: 1.3326 loss_val: 1.3698
Run:01 Epoch: 0681 loss_train: 1.3313 loss_val: 1.3693
Run:01 Epoch: 0691 loss_train: 1.3327 loss_val: 1.3708
Run:01 Epoch: 0701 loss_train: 1.3313 loss_val: 1.3694
Run:01 Epoch: 0711 loss_train: 1.3333 loss_val: 1.3702
Run:01 Epoch: 0721 loss_train: 1.3299 loss_val: 1.3694
Run:01 Epoch: 0731 loss_train: 1.3290 loss_val: 1.3703
Run:01 Epoch: 0741 loss_train: 1.3306 loss_val: 1.3700
Run:01 Epoch: 0751 loss_train: 1.3304 loss_val: 1.3700
Run:01 Epoch: 0761 loss_train: 1.3324 loss_val: 1.3692
Run:01 Epoch: 0771 loss_train: 1.3311 loss_val: 1.3691
Run:01 Epoch: 0781 loss_train: 1.3329 loss_val: 1.3692
Run:01 Epoch: 0791 loss_train: 1.3317 loss_val: 1.3695
Run:01 Epoch: 0801 loss_train: 1.3320 loss_val: 1.3695
Run:01 Epoch: 0811 loss_train: 1.3329 loss_val: 1.3694
Run:01 Epoch: 0821 loss_train: 1.3309 loss_val: 1.3696
Run:01 Epoch: 0831 loss_train: 1.3309 loss_val: 1.3689
Run:01 Epoch: 0841 loss_train: 1.3322 loss_val: 1.3692
Run:01 Epoch: 0851 loss_train: 1.3302 loss_val: 1.3697
Run:01 Epoch: 0861 loss_train: 1.3306 loss_val: 1.3691
Run:01 Epoch: 0871 loss_train: 1.3320 loss_val: 1.3691
Run:01 Epoch: 0881 loss_train: 1.3296 loss_val: 1.3688
Run:01 Epoch: 0891 loss_train: 1.3301 loss_val: 1.3692
Run:01 Epoch: 0901 loss_train: 1.3317 loss_val: 1.3690
Run:01 Epoch: 0911 loss_train: 1.3307 loss_val: 1.3690
Run:01 Epoch: 0921 loss_train: 1.3320 loss_val: 1.3689
Run:01 Epoch: 0931 loss_train: 1.3294 loss_val: 1.3693
Run:01 Epoch: 0941 loss_train: 1.3318 loss_val: 1.3695
Run:01 Epoch: 0951 loss_train: 1.3310 loss_val: 1.3693
Run:01 Epoch: 0961 loss_train: 1.3322 loss_val: 1.3696
Run:01 Epoch: 0971 loss_train: 1.3307 loss_val: 1.3689
Run:01 Epoch: 0981 loss_train: 1.3300 loss_val: 1.3692
Run:01 Epoch: 0991 loss_train: 1.3286 loss_val: 1.3688
Run:01 Epoch: 1001 loss_train: 1.3322 loss_val: 1.3690
Run:01 Epoch: 1011 loss_train: 1.3282 loss_val: 1.3702
Run:01 Epoch: 1021 loss_train: 1.3304 loss_val: 1.3700
Run:01 Epoch: 1031 loss_train: 1.3298 loss_val: 1.3689
Run:01 Epoch: 1041 loss_train: 1.3326 loss_val: 1.3688
Run:01 Epoch: 1051 loss_train: 1.3318 loss_val: 1.3694
Run:01 Epoch: 1061 loss_train: 1.3319 loss_val: 1.3702
Run:01 Epoch: 1071 loss_train: 1.3304 loss_val: 1.3701
Run:01 Epoch: 1081 loss_train: 1.3305 loss_val: 1.3692
Run:01 Epoch: 1091 loss_train: 1.3313 loss_val: 1.3694
Run:01 Epoch: 1101 loss_train: 1.3304 loss_val: 1.3691
Run:01 Epoch: 1111 loss_train: 1.3313 loss_val: 1.3698
Run:01 Epoch: 1121 loss_train: 1.3303 loss_val: 1.3693
Run:01 Epoch: 1131 loss_train: 1.3304 loss_val: 1.3692
Run:01 Epoch: 1141 loss_train: 1.3304 loss_val: 1.3688
Run:01 Epoch: 1151 loss_train: 1.3294 loss_val: 1.3687
Run:01 Epoch: 1161 loss_train: 1.3290 loss_val: 1.3690
Run:01 Epoch: 1171 loss_train: 1.3321 loss_val: 1.3691
Run:01 Epoch: 1181 loss_train: 1.3297 loss_val: 1.3699
Run:01 Epoch: 1191 loss_train: 1.3320 loss_val: 1.3700
Run:01 Epoch: 1201 loss_train: 1.3312 loss_val: 1.3703
Run:01 Epoch: 1211 loss_train: 1.3303 loss_val: 1.3707
Run:01 Epoch: 1221 loss_train: 1.3318 loss_val: 1.3690
Run:01 Epoch: 1231 loss_train: 1.3307 loss_val: 1.3698
Run:01 Epoch: 1241 loss_train: 1.3305 loss_val: 1.3700
Run:01 Epoch: 1251 loss_train: 1.3304 loss_val: 1.3695
Run:01 Epoch: 1261 loss_train: 1.3296 loss_val: 1.3691
Run:01 Epoch: 1271 loss_train: 1.3295 loss_val: 1.3687
Run:01 Epoch: 1281 loss_train: 1.3289 loss_val: 1.3692
Run:01 Epoch: 1291 loss_train: 1.3318 loss_val: 1.3702
Run:01 Epoch: 1301 loss_train: 1.3308 loss_val: 1.3693
Run:01 Epoch: 1311 loss_train: 1.3294 loss_val: 1.3686
Run:01 Epoch: 1321 loss_train: 1.3312 loss_val: 1.3689
Run:01 Epoch: 1331 loss_train: 1.3289 loss_val: 1.3692
Run:01 Epoch: 1341 loss_train: 1.3309 loss_val: 1.3698
Run:01 Epoch: 1351 loss_train: 1.3309 loss_val: 1.3698
Run:01 Epoch: 1361 loss_train: 1.3291 loss_val: 1.3693
Run:01 Epoch: 1371 loss_train: 1.3296 loss_val: 1.3696
Run:01 Epoch: 1381 loss_train: 1.3296 loss_val: 1.3701
Run:01 Epoch: 1391 loss_train: 1.3328 loss_val: 1.3699
Run:01 Epoch: 1401 loss_train: 1.3295 loss_val: 1.3695
Run:01 Epoch: 1411 loss_train: 1.3319 loss_val: 1.3691
Run:01 Epoch: 1421 loss_train: 1.3310 loss_val: 1.3699
Run:01 Epoch: 1431 loss_train: 1.3291 loss_val: 1.3702
Run:01 Epoch: 1441 loss_train: 1.3319 loss_val: 1.3700
Run:01 Epoch: 1451 loss_train: 1.3325 loss_val: 1.3697
Run:01 Epoch: 1461 loss_train: 1.3278 loss_val: 1.3701
Run:01 Epoch: 1471 loss_train: 1.3279 loss_val: 1.3697
Run:01 Epoch: 1481 loss_train: 1.3304 Run Train:  50%|█████     | 1/2 [06:54<06:54, 414.86s/it]loss_val: 1.3697
Run:01 Epoch: 1491 loss_train: 1.3312 loss_val: 1.3688
Run:02 Epoch: 0001 loss_train: 1.3275 loss_val: 1.3701
Run:02 Epoch: 0011 loss_train: 1.3305 loss_val: 1.3700
Run:02 Epoch: 0021 loss_train: 1.3300 loss_val: 1.3691
Run:02 Epoch: 0031 loss_train: 1.3306 loss_val: 1.3693
Run:02 Epoch: 0041 loss_train: 1.3288 loss_val: 1.3697
Run:02 Epoch: 0051 loss_train: 1.3301 loss_val: 1.3695
Run:02 Epoch: 0061 loss_train: 1.3311 loss_val: 1.3679
Run:02 Epoch: 0071 loss_train: 1.3309 loss_val: 1.3696
Run:02 Epoch: 0081 loss_train: 1.3292 loss_val: 1.3696
Run:02 Epoch: 0091 loss_train: 1.3302 loss_val: 1.3694
Run:02 Epoch: 0101 loss_train: 1.3310 loss_val: 1.3696
Run:02 Epoch: 0111 loss_train: 1.3298 loss_val: 1.3699
Run:02 Epoch: 0121 loss_train: 1.3303 loss_val: 1.3700
Run:02 Epoch: 0131 loss_train: 1.3303 loss_val: 1.3694
Run:02 Epoch: 0141 loss_train: 1.3296 loss_val: 1.3694
Run:02 Epoch: 0151 loss_train: 1.3314 loss_val: 1.3711
Run:02 Epoch: 0161 loss_train: 1.3304 loss_val: 1.3703
Run:02 Epoch: 0171 loss_train: 1.3296 loss_val: 1.3691
Run:02 Epoch: 0181 loss_train: 1.3299 loss_val: 1.3696
Run:02 Epoch: 0191 loss_train: 1.3301 loss_val: 1.3699
Run:02 Epoch: 0201 loss_train: 1.3295 loss_val: 1.3693
Run:02 Epoch: 0211 loss_train: 1.3317 loss_val: 1.3698
Run:02 Epoch: 0221 loss_train: 1.3316 loss_val: 1.3702
Run:02 Epoch: 0231 loss_train: 1.3305 loss_val: 1.3701
Run:02 Epoch: 0241 loss_train: 1.3314 loss_val: 1.3694
Run:02 Epoch: 0251 loss_train: 1.3306 loss_val: 1.3691
Run:02 Epoch: 0261 loss_train: 1.3307 loss_val: 1.3698
Run:02 Epoch: 0271 loss_train: 1.3280 loss_val: 1.3696
Run:02 Epoch: 0281 loss_train: 1.3308 loss_val: 1.3689
Run:02 Epoch: 0291 loss_train: 1.3298 loss_val: 1.3692
Run:02 Epoch: 0301 loss_train: 1.3308 loss_val: 1.3701
Run:02 Epoch: 0311 loss_train: 1.3318 loss_val: 1.3693
Run:02 Epoch: 0321 loss_train: 1.3296 loss_val: 1.3698
Run:02 Epoch: 0331 loss_train: 1.3290 loss_val: 1.3700
Run:02 Epoch: 0341 loss_train: 1.3308 loss_val: 1.3699
Run:02 Epoch: 0351 loss_train: 1.3285 loss_val: 1.3696
Run:02 Epoch: 0361 loss_train: 1.3313 loss_val: 1.3704
Run:02 Epoch: 0371 loss_train: 1.3300 loss_val: 1.3700
Run:02 Epoch: 0381 loss_train: 1.3312 loss_val: 1.3691
Run:02 Epoch: 0391 loss_train: 1.3293 loss_val: 1.3687
Run:02 Epoch: 0401 loss_train: 1.3298 loss_val: 1.3691
Run:02 Epoch: 0411 loss_train: 1.3307 loss_val: 1.3698
Run:02 Epoch: 0421 loss_train: 1.3294 loss_val: 1.3698
Run:02 Epoch: 0431 loss_train: 1.3285 loss_val: 1.3697
Run:02 Epoch: 0441 loss_train: 1.3294 loss_val: 1.3694
Run:02 Epoch: 0451 loss_train: 1.3291 loss_val: 1.3703
Run:02 Epoch: 0461 loss_train: 1.3311 loss_val: 1.3700
Run:02 Epoch: 0471 loss_train: 1.3291 loss_val: 1.3694
Run:02 Epoch: 0481 loss_train: 1.3281 loss_val: 1.3690
Run:02 Epoch: 0491 loss_train: 1.3284 loss_val: 1.3683
Run:02 Epoch: 0501 loss_train: 1.3290 loss_val: 1.3685
Run:02 Epoch: 0511 loss_train: 1.3292 loss_val: 1.3696
Run:02 Epoch: 0521 loss_train: 1.3298 loss_val: 1.3697
Run:02 Epoch: 0531 loss_train: 1.3300 loss_val: 1.3690
Run:02 Epoch: 0541 loss_train: 1.3303 loss_val: 1.3683
Run:02 Epoch: 0551 loss_train: 1.3302 loss_val: 1.3695
Run:02 Epoch: 0561 loss_train: 1.3290 loss_val: 1.3695
Run:02 Epoch: 0571 loss_train: 1.3304 loss_val: 1.3699
Run:02 Epoch: 0581 loss_train: 1.3286 loss_val: 1.3688
Run:02 Epoch: 0591 loss_train: 1.3290 loss_val: 1.3687
Run:02 Epoch: 0601 loss_train: 1.3316 loss_val: 1.3687
Run:02 Epoch: 0611 loss_train: 1.3333 loss_val: 1.3701
Run:02 Epoch: 0621 loss_train: 1.3291 loss_val: 1.3693
Run:02 Epoch: 0631 loss_train: 1.3308 loss_val: 1.3692
Run:02 Epoch: 0641 loss_train: 1.3310 loss_val: 1.3696
Run:02 Epoch: 0651 loss_train: 1.3273 loss_val: 1.3683
Run:02 Epoch: 0661 loss_train: 1.3300 loss_val: 1.3685
Run:02 Epoch: 0671 loss_train: 1.3312 loss_val: 1.3699
Run:02 Epoch: 0681 loss_train: 1.3311 loss_val: 1.3704
Run:02 Epoch: 0691 loss_train: 1.3317 loss_val: 1.3700
Run:02 Epoch: 0701 loss_train: 1.3300 loss_val: 1.3687
Run:02 Epoch: 0711 loss_train: 1.3311 loss_val: 1.3692
Run:02 Epoch: 0721 loss_train: 1.3289 loss_val: 1.3696
Run:02 Epoch: 0731 loss_train: 1.3317 loss_val: 1.3704
Run:02 Epoch: 0741 loss_train: 1.3314 loss_val: 1.3704
Run:02 Epoch: 0751 loss_train: 1.3289 loss_val: 1.3692
Run:02 Epoch: 0761 loss_train: 1.3291 loss_val: 1.3687
Run:02 Epoch: 0771 loss_train: 1.3285 loss_val: 1.3688
Run:02 Epoch: 0781 loss_train: 1.3306 loss_val: 1.3699
Run:02 Epoch: 0791 loss_train: 1.3307 loss_val: 1.3693
Run:02 Epoch: 0801 loss_train: 1.3298 loss_val: 1.3694
Run:02 Epoch: 0811 loss_train: 1.3281 loss_val: 1.3698
Run:02 Epoch: 0821 loss_train: 1.3292 loss_val: 1.3700
Run:02 Epoch: 0831 loss_train: 1.3296 loss_val: 1.3692
Run:02 Epoch: 0841 loss_train: 1.3306 loss_val: 1.3691
Run:02 Epoch: 0851 loss_train: 1.3307 loss_val: 1.3698
Run:02 Epoch: 0861 loss_train: 1.3309 loss_val: 1.3690
Run:02 Epoch: 0871 loss_train: 1.3294 loss_val: 1.3686
Run:02 Epoch: 0881 loss_train: 1.3308 loss_val: 1.3690
Run:02 Epoch: 0891 loss_train: 1.3286 loss_val: 1.3694
Run:02 Epoch: 0901 loss_train: 1.3316 loss_val: 1.3701
Run:02 Epoch: 0911 loss_train: 1.3278 loss_val: 1.3689
Run:02 Epoch: 0921 loss_train: 1.3296 loss_val: 1.3688
Run:02 Epoch: 0931 loss_train: 1.3306 loss_val: 1.3693
Run:02 Epoch: 0941 loss_train: 1.3287 loss_val: 1.3698
Run:02 Epoch: 0951 loss_train: 1.3303 loss_val: 1.3685
Run:02 Epoch: 0961 loss_train: 1.3292 loss_val: 1.3693
Run:02 Epoch: 0971 loss_train: 1.3292 loss_val: 1.3700
Run:02 Epoch: 0981 loss_train: 1.3305 loss_val: 1.3693
Run:02 Epoch: 0991 loss_train: 1.3295 loss_val: 1.3697
Run:02 Epoch: 1001 loss_train: 1.3285 loss_val: 1.3693
Run:02 Epoch: 1011 loss_train: 1.3305 loss_val: 1.3684
Run:02 Epoch: 1021 loss_train: 1.3293 loss_val: 1.3689
Run:02 Epoch: 1031 loss_train: 1.3304 loss_val: 1.3699
Run:02 Epoch: 1041 loss_train: 1.3297 loss_val: 1.3693
Run:02 Epoch: 1051 loss_train: 1.3305 loss_val: 1.3694
Run:02 Epoch: 1061 loss_train: 1.3292 loss_val: 1.3690
Run:02 Epoch: 1071 loss_train: 1.3298 loss_val: 1.3694
Run:02 Epoch: 1081 loss_train: 1.3308 loss_val: 1.3690
Run:02 Epoch: 1091 loss_train: 1.3297 loss_val: 1.3692
Run:02 Epoch: 1101 loss_train: 1.3288 loss_val: 1.3695
Run:02 Epoch: 1111 loss_train: 1.3310 loss_val: 1.3697
Run:02 Epoch: 1121 loss_train: 1.3293 loss_val: 1.3708
Run:02 Epoch: 1131 loss_train: 1.3312 loss_val: 1.3698
Run:02 Epoch: 1141 loss_train: 1.3301 loss_val: 1.3694
Run:02 Epoch: 1151 loss_train: 1.3288 loss_val: 1.3690
Run:02 Epoch: 1161 loss_train: 1.3297 loss_val: 1.3699
Run:02 Epoch: 1171 loss_train: 1.3291 loss_val: 1.3700
Run:02 Epoch: 1181 loss_train: 1.3302 loss_val: 1.3686
Run:02 Epoch: 1191 loss_train: 1.3289 loss_val: 1.3691
Run:02 Epoch: 1201 loss_train: 1.3291 loss_val: 1.3693
Run:02 Epoch: 1211 loss_train: 1.3296 loss_val: 1.3701
Run:02 Epoch: 1221 loss_train: 1.3275 loss_val: 1.3689
Run:02 Epoch: 1231 loss_train: 1.3287 loss_val: 1.3690
Run:02 Epoch: 1241 loss_train: 1.3319 loss_val: 1.3707
Run:02 Epoch: 1251 loss_train: 1.3320 loss_val: 1.3706
Run:02 Epoch: 1261 loss_train: 1.3310 loss_val: 1.3686
Run:02 Epoch: 1271 loss_train: 1.3293 loss_val: 1.3686
Run:02 Epoch: 1281 loss_train: 1.3310 loss_val: 1.3692
Run:02 Epoch: 1291 loss_train: 1.3287 loss_val: 1.3691
Run:02 Epoch: 1301 loss_train: 1.3288 loss_val: 1.3700
Run:02 Epoch: 1311 loss_train: 1.3305 loss_val: 1.3697
Run:02 Epoch: 1321 loss_train: 1.3302 loss_val: 1.3698
Run:02 Epoch: 1331 loss_train: 1.3313 loss_val: 1.3690
Run:02 Epoch: 1341 loss_train: 1.3297 loss_val: 1.3681
Run:02 Epoch: 1351 loss_train: 1.3314 loss_val: 1.3693
Run:02 Epoch: 1361 loss_train: 1.3318 loss_val: 1.3697
Run:02 Epoch: 1371 loss_train: 1.3296 loss_val: 1.3702
Run:02 Epoch: 1381 loss_train: 1.3311 loss_val: 1.3695
Run:02 Epoch: 1391 loss_train: 1.3314 loss_val: 1.3694
Run:02 Epoch: 1401 loss_train: 1.3285 loss_val: 1.3695
Run:02 Epoch: 1411 loss_train: 1.3310 loss_val: 1.3696
Run:02 Epoch: 1421 loss_train: 1.3287 loss_val: 1.3688
Run:02 Epoch: 1431 loss_train: 1.3314 loss_val: 1.3695
Run:02 Epoch: 1441 loss_train: 1.3294 loss_val: 1.3704
Run:02 Epoch: 1451 loss_train: 1.3305 loss_val: 1.3701
Run:02 Epoch: 1461 loss_train: 1.3295 loss_val: 1.3687
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [13:36<00:00, 407.30s/it]Run Train: 100%|██████████| 2/2 [13:36<00:00, 408.43s/it]
/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_train: 1.3281 loss_val: 1.3687
Run:02 Epoch: 1481 loss_train: 1.3304 loss_val: 1.3694
Run:02 Epoch: 1491 loss_train: 1.3314 loss_val: 1.3694
test acc: 0.43719806763285024 test acc std 0.0


test micro f1: 0.43719806763285024 test macro f1 0.37844991828955205
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7904 loss_val: 1.7733
Run:01 Epoch: 0011 loss_train: 1.7448 loss_val: 1.7381
Run:01 Epoch: 0021 loss_train: 1.6138 loss_val: 1.6027
Run:01 Epoch: 0031 loss_train: 1.4801 loss_val: 1.4785
Run:01 Epoch: 0041 loss_train: 1.4091 loss_val: 1.4146
Run:01 Epoch: 0051 loss_train: 1.3747 loss_val: 1.3861
Run:01 Epoch: 0061 loss_train: 1.3560 loss_val: 1.3766
Run:01 Epoch: 0071 loss_train: 1.3518 loss_val: 1.3735
Run:01 Epoch: 0081 loss_train: 1.3501 loss_val: 1.3747
Run:01 Epoch: 0091 loss_train: 1.3545 loss_val: 1.3769
Run:01 Epoch: 0101 loss_train: 1.3566 loss_val: 1.3784
Run:01 Epoch: 0111 loss_train: 1.3555 loss_val: 1.3772
Run:01 Epoch: 0121 loss_train: 1.3517 loss_val: 1.3749
Run:01 Epoch: 0131 loss_train: 1.3577 loss_val: 1.3767
Run:01 Epoch: 0141 loss_train: 1.3571 loss_val: 1.3762
Run:01 Epoch: 0151 loss_train: 1.3560 loss_val: 1.3756
Run:01 Epoch: 0161 loss_train: 1.3524 loss_val: 1.3771
Run:01 Epoch: 0171 loss_train: 1.3566 loss_val: 1.3764
Run:01 Epoch: 0181 loss_train: 1.3554 loss_val: 1.3878
Run:01 Epoch: 0191 loss_train: 1.3535 loss_val: 1.3779
Run:01 Epoch: 0201 loss_train: 1.3533 loss_val: 1.3755
Run:01 Epoch: 0211 loss_train: 1.3535 loss_val: 1.3736
Run:01 Epoch: 0221 loss_train: 1.3504 loss_val: 1.3726
Run:01 Epoch: 0231 loss_train: 1.3491 loss_val: 1.3745
Run:01 Epoch: 0241 loss_train: 1.3506 loss_val: 1.3759
Run:01 Epoch: 0251 loss_train: 1.3489 loss_val: 1.3783
Run:01 Epoch: 0261 loss_train: 1.3456 loss_val: 1.3740
Run:01 Epoch: 0271 loss_train: 1.3496 loss_val: 1.3730
Run:01 Epoch: 0281 loss_train: 1.3484 loss_val: 1.3738
Run:01 Epoch: 0291 loss_train: 1.3496 loss_val: 1.3742
Run:01 Epoch: 0301 loss_train: 1.3524 loss_val: 1.3746
Run:01 Epoch: 0311 loss_train: 1.3492 loss_val: 1.3758
Run:01 Epoch: 0321 loss_train: 1.3483 loss_val: 1.3737
Run:01 Epoch: 0331 loss_train: 1.3493 loss_val: 1.3740
Run:01 Epoch: 0341 loss_train: 1.3503 loss_val: 1.3762
Run:01 Epoch: 0351 loss_train: 1.3513 loss_val: 1.3726
Run:01 Epoch: 0361 loss_train: 1.3499 loss_val: 1.3728
Run:01 Epoch: 0371 loss_train: 1.3513 loss_val: 1.3748
Run:01 Epoch: 0381 loss_train: 1.3516 loss_val: 1.3782
Run:01 Epoch: 0391 loss_train: 1.3470 loss_val: 1.3752
Run:01 Epoch: 0401 loss_train: 1.3480 loss_val: 1.3747
Run:01 Epoch: 0411 loss_train: 1.3485 loss_val: 1.3759
Run:01 Epoch: 0421 loss_train: 1.3526 loss_val: 1.3755
Run:01 Epoch: 0431 loss_train: 1.3525 loss_val: 1.3769
Run:01 Epoch: 0441 loss_train: 1.3487 loss_val: 1.3743
Run:01 Epoch: 0451 loss_train: 1.3481 loss_val: 1.3747
Run:01 Epoch: 0461 loss_train: 1.3519 loss_val: 1.3752
Run:01 Epoch: 0471 loss_train: 1.3478 loss_val: 1.3763
Run:01 Epoch: 0481 loss_train: 1.3465 loss_val: 1.3744
Run:01 Epoch: 0491 loss_train: 1.3497 loss_val: 1.3741
Run:01 Epoch: 0501 loss_train: 1.3492 loss_val: 1.3724
Run:01 Epoch: 0511 loss_train: 1.3449 loss_val: 1.3728
Run:01 Epoch: 0521 loss_train: 1.3455 loss_val: 1.3747
Run:01 Epoch: 0531 loss_train: 1.3490 loss_val: 1.3759
Run:01 Epoch: 0541 loss_train: 1.3487 loss_val: 1.3738
Run:01 Epoch: 0551 loss_train: 1.3482 loss_val: 1.3744
Run:01 Epoch: 0561 loss_train: 1.3481 loss_val: 1.3747
Run:01 Epoch: 0571 loss_train: 1.3502 loss_val: 1.3760
Run:01 Epoch: 0581 loss_train: 1.3489 loss_val: 1.3724
Run:01 Epoch: 0591 loss_train: 1.3498 loss_val: 1.3746
Run:01 Epoch: 0601 loss_train: 1.3481 loss_val: 1.3737
Run:01 Epoch: 0611 loss_train: 1.3453 loss_val: 1.3740
Run:01 Epoch: 0621 loss_train: 1.3466 loss_val: 1.3761
Run:01 Epoch: 0631 loss_train: 1.3454 loss_val: 1.3785
Run:01 Epoch: 0641 loss_train: 1.3480 loss_val: 1.3766
Run:01 Epoch: 0651 loss_train: 1.3510 loss_val: 1.3738
Run:01 Epoch: 0661 loss_train: 1.3465 loss_val: 1.3751
Run:01 Epoch: 0671 loss_train: 1.3472 loss_val: 1.3736
Run:01 Epoch: 0681 loss_train: 1.3433 loss_val: 1.3770
Run:01 Epoch: 0691 loss_train: 1.3504 loss_val: 1.3830
Run:01 Epoch: 0701 loss_train: 1.3454 loss_val: 1.3741
Run:01 Epoch: 0711 loss_train: 1.3444 loss_val: 1.3733
Run:01 Epoch: 0721 loss_train: 1.3464 loss_val: 1.3764
Run:01 Epoch: 0731 loss_train: 1.3457 loss_val: 1.3735
Run:01 Epoch: 0741 loss_train: 1.3472 loss_val: 1.3750
Run:01 Epoch: 0751 loss_train: 1.3506 loss_val: 1.3778
Run:01 Epoch: 0761 loss_train: 1.3470 loss_val: 1.3725
Run:01 Epoch: 0771 loss_train: 1.3488 loss_val: 1.3732
Run:01 Epoch: 0781 loss_train: 1.3475 loss_val: 1.3732
Run:01 Epoch: 0791 loss_train: 1.3439 loss_val: 1.3744
Run:01 Epoch: 0801 loss_train: 1.3475 loss_val: 1.3757
Run:01 Epoch: 0811 loss_train: 1.3454 loss_val: 1.3716
Run:01 Epoch: 0821 loss_train: 1.3463 loss_val: 1.3757
Run:01 Epoch: 0831 loss_train: 1.3486 loss_val: 1.3755
Run:01 Epoch: 0841 loss_train: 1.3463 loss_val: 1.3744
Run:01 Epoch: 0851 loss_train: 1.3471 loss_val: 1.3726
Run:01 Epoch: 0861 loss_train: 1.3462 loss_val: 1.3735
Run:01 Epoch: 0871 loss_train: 1.3472 loss_val: 1.3715
Run:01 Epoch: 0881 loss_train: 1.3478 loss_val: 1.3748
Run:01 Epoch: 0891 loss_train: 1.3455 loss_val: 1.3722
Run:01 Epoch: 0901 loss_train: 1.3435 loss_val: 1.3793
Run:01 Epoch: 0911 loss_train: 1.3508 loss_val: 1.3721
Run:01 Epoch: 0921 loss_train: 1.3458 loss_val: 1.3717
Run:01 Epoch: 0931 loss_train: 1.3461 loss_val: 1.3769
Run:01 Epoch: 0941 loss_train: 1.3424 loss_val: 1.3726
Run:01 Epoch: 0951 loss_train: 1.3469 loss_val: 1.3762
Run:01 Epoch: 0961 loss_train: 1.3473 loss_val: 1.3728
Run:01 Epoch: 0971 loss_train: 1.3430 loss_val: 1.3724
Run:01 Epoch: 0981 loss_train: 1.3414 loss_val: 1.3726
Run:01 Epoch: 0991 loss_train: 1.3440 loss_val: 1.3770
Run:01 Epoch: 1001 loss_train: 1.3423 loss_val: 1.3701
Run:01 Epoch: 1011 loss_train: 1.3451 loss_val: 1.3757
Run:01 Epoch: 1021 loss_train: 1.3447 loss_val: 1.3723
Run:01 Epoch: 1031 loss_train: 1.3447 loss_val: 1.3750
Run:01 Epoch: 1041 loss_train: 1.3418 loss_val: 1.3725
Run:01 Epoch: 1051 loss_train: 1.3451 loss_val: 1.3736
Run:01 Epoch: 1061 loss_train: 1.3440 loss_val: 1.3735
Run:01 Epoch: 1071 loss_train: 1.3467 loss_val: 1.3724
Run:01 Epoch: 1081 loss_train: 1.3435 loss_val: 1.3726
Run:01 Epoch: 1091 loss_train: 1.3452 loss_val: 1.3732
Run:01 Epoch: 1101 loss_train: 1.3446 loss_val: 1.3743
Run:01 Epoch: 1111 loss_train: 1.3432 loss_val: 1.3739
Run:01 Epoch: 1121 loss_train: 1.3443 loss_val: 1.3743
Run:01 Epoch: 1131 loss_train: 1.3444 loss_val: 1.3753
Run:01 Epoch: 1141 loss_train: 1.3488 loss_val: 1.3735
Run:01 Epoch: 1151 loss_train: 1.3396 loss_val: 1.3733
Run:01 Epoch: 1161 loss_train: 1.3438 loss_val: 1.3729
Run:01 Epoch: 1171 loss_train: 1.3435 loss_val: 1.3728
Run:01 Epoch: 1181 loss_train: 1.3462 loss_val: 1.3775
Run:01 Epoch: 1191 loss_train: 1.3451 loss_val: 1.3720
Run:01 Epoch: 1201 loss_train: 1.3452 loss_val: 1.3784
Run:01 Epoch: 1211 loss_train: 1.3475 loss_val: 1.3728
Run:01 Epoch: 1221 loss_train: 1.3426 loss_val: 1.3721
Run:01 Epoch: 1231 loss_train: 1.3464 loss_val: 1.3749
Run:01 Epoch: 1241 loss_train: 1.3477 loss_val: 1.3728
Run:01 Epoch: 1251 loss_train: 1.3468 loss_val: 1.3758
Run:01 Epoch: 1261 loss_train: 1.3480 loss_val: 1.3741
Run:01 Epoch: 1271 loss_train: 1.3433 loss_val: 1.3739
Run:01 Epoch: 1281 loss_train: 1.3445 loss_val: 1.3759
Run:01 Epoch: 1291 loss_train: 1.3465 loss_val: 1.3732
Run:01 Epoch: 1301 loss_train: 1.3456 loss_val: 1.3714
Run:01 Epoch: 1311 loss_train: 1.3466 loss_val: 1.3727
Run:01 Epoch: 1321 loss_train: 1.3451 loss_val: 1.3765
Run:01 Epoch: 1331 loss_train: 1.3427 loss_val: 1.3721
Run:01 Epoch: 1341 loss_train: 1.3458 loss_val: 1.3721
Run:01 Epoch: 1351 loss_train: 1.3456 loss_val: 1.3719
Run:01 Epoch: 1361 loss_train: 1.3436 loss_val: 1.3758
Run:01 Epoch: 1371 loss_train: 1.3471 loss_val: 1.3725
Run:01 Epoch: 1381 loss_train: 1.3453 loss_val: 1.3758
Run:01 Epoch: 1391 loss_train: 1.3447 loss_val: 1.3728
Run:01 Epoch: 1401 loss_train: 1.3436 loss_val: 1.3737
Run:01 Epoch: 1411 loss_train: 1.3462 loss_val: 1.3765
Run:01 Epoch: 1421 loss_train: 1.3437 loss_val: 1.3741
Run:01 Epoch: 1431 loss_train: 1.3442 loss_val: 1.3745
Run:01 Epoch: 1441 loss_train: 1.3443 loss_val: 1.3772
Run:01 Epoch: 1451 loss_train: 1.3458 loss_val: 1.3725
Run:01 Epoch: 1461 loss_train: 1.3438 loss_val: 1.3753
Run:01 Epoch: 1471 loss_train: 1.3453 loss_val: 1.3747
Run:01 Epoch: 1481 loss_train: 1.3446 Run Train:  50%|█████     | 1/2 [06:42<06:42, 402.95s/it]loss_val: 1.3753
Run:01 Epoch: 1491 loss_train: 1.3461 loss_val: 1.3763
Run:02 Epoch: 0001 loss_train: 1.3454 loss_val: 1.3722
Run:02 Epoch: 0011 loss_train: 1.3443 loss_val: 1.3733
Run:02 Epoch: 0021 loss_train: 1.3470 loss_val: 1.3731
Run:02 Epoch: 0031 loss_train: 1.3451 loss_val: 1.3747
Run:02 Epoch: 0041 loss_train: 1.3433 loss_val: 1.3740
Run:02 Epoch: 0051 loss_train: 1.3458 loss_val: 1.3741
Run:02 Epoch: 0061 loss_train: 1.3479 loss_val: 1.3759
Run:02 Epoch: 0071 loss_train: 1.3441 loss_val: 1.3705
Run:02 Epoch: 0081 loss_train: 1.3452 loss_val: 1.3731
Run:02 Epoch: 0091 loss_train: 1.3443 loss_val: 1.3725
Run:02 Epoch: 0101 loss_train: 1.3432 loss_val: 1.3751
Run:02 Epoch: 0111 loss_train: 1.3484 loss_val: 1.3717
Run:02 Epoch: 0121 loss_train: 1.3484 loss_val: 1.3755
Run:02 Epoch: 0131 loss_train: 1.3458 loss_val: 1.3721
Run:02 Epoch: 0141 loss_train: 1.3441 loss_val: 1.3735
Run:02 Epoch: 0151 loss_train: 1.3432 loss_val: 1.3749
Run:02 Epoch: 0161 loss_train: 1.3449 loss_val: 1.3732
Run:02 Epoch: 0171 loss_train: 1.3455 loss_val: 1.3756
Run:02 Epoch: 0181 loss_train: 1.3480 loss_val: 1.3750
Run:02 Epoch: 0191 loss_train: 1.3442 loss_val: 1.3720
Run:02 Epoch: 0201 loss_train: 1.3439 loss_val: 1.3780
Run:02 Epoch: 0211 loss_train: 1.3445 loss_val: 1.3747
Run:02 Epoch: 0221 loss_train: 1.3430 loss_val: 1.3755
Run:02 Epoch: 0231 loss_train: 1.3470 loss_val: 1.3735
Run:02 Epoch: 0241 loss_train: 1.3469 loss_val: 1.3742
Run:02 Epoch: 0251 loss_train: 1.3466 loss_val: 1.3750
Run:02 Epoch: 0261 loss_train: 1.3445 loss_val: 1.3717
Run:02 Epoch: 0271 loss_train: 1.3465 loss_val: 1.3814
Run:02 Epoch: 0281 loss_train: 1.3489 loss_val: 1.3749
Run:02 Epoch: 0291 loss_train: 1.3457 loss_val: 1.3730
Run:02 Epoch: 0301 loss_train: 1.3428 loss_val: 1.3732
Run:02 Epoch: 0311 loss_train: 1.3424 loss_val: 1.3717
Run:02 Epoch: 0321 loss_train: 1.3414 loss_val: 1.3754
Run:02 Epoch: 0331 loss_train: 1.3466 loss_val: 1.3712
Run:02 Epoch: 0341 loss_train: 1.3434 loss_val: 1.3720
Run:02 Epoch: 0351 loss_train: 1.3483 loss_val: 1.3761
Run:02 Epoch: 0361 loss_train: 1.3441 loss_val: 1.3751
Run:02 Epoch: 0371 loss_train: 1.3438 loss_val: 1.3769
Run:02 Epoch: 0381 loss_train: 1.3430 loss_val: 1.3703
Run:02 Epoch: 0391 loss_train: 1.3438 loss_val: 1.3734
Run:02 Epoch: 0401 loss_train: 1.3475 loss_val: 1.3729
Run:02 Epoch: 0411 loss_train: 1.3455 loss_val: 1.3713
Run:02 Epoch: 0421 loss_train: 1.3449 loss_val: 1.3791
Run:02 Epoch: 0431 loss_train: 1.3498 loss_val: 1.3726
Run:02 Epoch: 0441 loss_train: 1.3441 loss_val: 1.3740
Run:02 Epoch: 0451 loss_train: 1.3447 loss_val: 1.3741
Run:02 Epoch: 0461 loss_train: 1.3430 loss_val: 1.3745
Run:02 Epoch: 0471 loss_train: 1.3435 loss_val: 1.3716
Run:02 Epoch: 0481 loss_train: 1.3431 loss_val: 1.3753
Run:02 Epoch: 0491 loss_train: 1.3439 loss_val: 1.3735
Run:02 Epoch: 0501 loss_train: 1.3444 loss_val: 1.3730
Run:02 Epoch: 0511 loss_train: 1.3450 loss_val: 1.3723
Run:02 Epoch: 0521 loss_train: 1.3427 loss_val: 1.3722
Run:02 Epoch: 0531 loss_train: 1.3456 loss_val: 1.3729
Run:02 Epoch: 0541 loss_train: 1.3450 loss_val: 1.3741
Run:02 Epoch: 0551 loss_train: 1.3457 loss_val: 1.3729
Run:02 Epoch: 0561 loss_train: 1.3470 loss_val: 1.3746
Run:02 Epoch: 0571 loss_train: 1.3443 loss_val: 1.3732
Run:02 Epoch: 0581 loss_train: 1.3445 loss_val: 1.3750
Run:02 Epoch: 0591 loss_train: 1.3418 loss_val: 1.3723
Run:02 Epoch: 0601 loss_train: 1.3434 loss_val: 1.3732
Run:02 Epoch: 0611 loss_train: 1.3450 loss_val: 1.3722
Run:02 Epoch: 0621 loss_train: 1.3440 loss_val: 1.3726
Run:02 Epoch: 0631 loss_train: 1.3462 loss_val: 1.3744
Run:02 Epoch: 0641 loss_train: 1.3422 loss_val: 1.3738
Run:02 Epoch: 0651 loss_train: 1.3434 loss_val: 1.3754
Run:02 Epoch: 0661 loss_train: 1.3455 loss_val: 1.3736
Run:02 Epoch: 0671 loss_train: 1.3427 loss_val: 1.3723
Run:02 Epoch: 0681 loss_train: 1.3429 loss_val: 1.3733
Run:02 Epoch: 0691 loss_train: 1.3429 loss_val: 1.3744
Run:02 Epoch: 0701 loss_train: 1.3461 loss_val: 1.3737
Run:02 Epoch: 0711 loss_train: 1.3452 loss_val: 1.3727
Run:02 Epoch: 0721 loss_train: 1.3474 loss_val: 1.3719
Run:02 Epoch: 0731 loss_train: 1.3450 loss_val: 1.3742
Run:02 Epoch: 0741 loss_train: 1.3448 loss_val: 1.3726
Run:02 Epoch: 0751 loss_train: 1.3461 loss_val: 1.3760
Run:02 Epoch: 0761 loss_train: 1.3451 loss_val: 1.3751
Run:02 Epoch: 0771 loss_train: 1.3443 loss_val: 1.3740
Run:02 Epoch: 0781 loss_train: 1.3445 loss_val: 1.3726
Run:02 Epoch: 0791 loss_train: 1.3501 loss_val: 1.3768
Run:02 Epoch: 0801 loss_train: 1.3452 loss_val: 1.3722
Run:02 Epoch: 0811 loss_train: 1.3443 loss_val: 1.3725
Run:02 Epoch: 0821 loss_train: 1.3447 loss_val: 1.3725
Run:02 Epoch: 0831 loss_train: 1.3455 loss_val: 1.3734
Run:02 Epoch: 0841 loss_train: 1.3454 loss_val: 1.3728
Run:02 Epoch: 0851 loss_train: 1.3450 loss_val: 1.3740
Run:02 Epoch: 0861 loss_train: 1.3439 loss_val: 1.3796
Run:02 Epoch: 0871 loss_train: 1.3452 loss_val: 1.3727
Run:02 Epoch: 0881 loss_train: 1.3455 loss_val: 1.3730
Run:02 Epoch: 0891 loss_train: 1.3437 loss_val: 1.3719
Run:02 Epoch: 0901 loss_train: 1.3442 loss_val: 1.3755
Run:02 Epoch: 0911 loss_train: 1.3419 loss_val: 1.3714
Run:02 Epoch: 0921 loss_train: 1.3441 loss_val: 1.3746
Run:02 Epoch: 0931 loss_train: 1.3447 loss_val: 1.3733
Run:02 Epoch: 0941 loss_train: 1.3458 loss_val: 1.3737
Run:02 Epoch: 0951 loss_train: 1.3441 loss_val: 1.3769
Run:02 Epoch: 0961 loss_train: 1.3462 loss_val: 1.3757
Run:02 Epoch: 0971 loss_train: 1.3444 loss_val: 1.3750
Run:02 Epoch: 0981 loss_train: 1.3449 loss_val: 1.3742
Run:02 Epoch: 0991 loss_train: 1.3429 loss_val: 1.3763
Run:02 Epoch: 1001 loss_train: 1.3476 loss_val: 1.3732
Run:02 Epoch: 1011 loss_train: 1.3437 loss_val: 1.3780
Run:02 Epoch: 1021 loss_train: 1.3450 loss_val: 1.3751
Run:02 Epoch: 1031 loss_train: 1.3478 loss_val: 1.3723
Run:02 Epoch: 1041 loss_train: 1.3456 loss_val: 1.3732
Run:02 Epoch: 1051 loss_train: 1.3454 loss_val: 1.3782
Run:02 Epoch: 1061 loss_train: 1.3441 loss_val: 1.3728
Run:02 Epoch: 1071 loss_train: 1.3504 loss_val: 1.3740
Run:02 Epoch: 1081 loss_train: 1.3411 loss_val: 1.3743
Run:02 Epoch: 1091 loss_train: 1.3457 loss_val: 1.3727
Run:02 Epoch: 1101 loss_train: 1.3440 loss_val: 1.3729
Run:02 Epoch: 1111 loss_train: 1.3458 loss_val: 1.3731
Run:02 Epoch: 1121 loss_train: 1.3444 loss_val: 1.3738
Run:02 Epoch: 1131 loss_train: 1.3444 loss_val: 1.3735
Run:02 Epoch: 1141 loss_train: 1.3445 loss_val: 1.3746
Run:02 Epoch: 1151 loss_train: 1.3458 loss_val: 1.3742
Run:02 Epoch: 1161 loss_train: 1.3453 loss_val: 1.3729
Run:02 Epoch: 1171 loss_train: 1.3459 loss_val: 1.3772
Run:02 Epoch: 1181 loss_train: 1.3433 loss_val: 1.3714
Run:02 Epoch: 1191 loss_train: 1.3414 loss_val: 1.3746
Run:02 Epoch: 1201 loss_train: 1.3411 loss_val: 1.3747
Run:02 Epoch: 1211 loss_train: 1.3477 loss_val: 1.3706
Run:02 Epoch: 1221 loss_train: 1.3445 loss_val: 1.3760
Run:02 Epoch: 1231 loss_train: 1.3441 loss_val: 1.3723
Run:02 Epoch: 1241 loss_train: 1.3471 loss_val: 1.3764
Run:02 Epoch: 1251 loss_train: 1.3480 loss_val: 1.3741
Run:02 Epoch: 1261 loss_train: 1.3423 loss_val: 1.3726
Run:02 Epoch: 1271 loss_train: 1.3485 loss_val: 1.3754
Run:02 Epoch: 1281 loss_train: 1.3494 loss_val: 1.3759
Run:02 Epoch: 1291 loss_train: 1.3479 loss_val: 1.3746
Run:02 Epoch: 1301 loss_train: 1.3445 loss_val: 1.3749
Run:02 Epoch: 1311 loss_train: 1.3419 loss_val: 1.3743
Run:02 Epoch: 1321 loss_train: 1.3478 loss_val: 1.3742
Run:02 Epoch: 1331 loss_train: 1.3451 loss_val: 1.3731
Run:02 Epoch: 1341 loss_train: 1.3431 loss_val: 1.3746
Run:02 Epoch: 1351 loss_train: 1.3468 loss_val: 1.3774
Run:02 Epoch: 1361 loss_train: 1.3437 loss_val: 1.3772
Run:02 Epoch: 1371 loss_train: 1.3453 loss_val: 1.3743
Run:02 Epoch: 1381 loss_train: 1.3455 loss_val: 1.3727
Run:02 Epoch: 1391 loss_train: 1.3405 loss_val: 1.3749
Run:02 Epoch: 1401 loss_train: 1.3436 loss_val: 1.3711
Run:02 Epoch: 1411 loss_train: 1.3451 loss_val: 1.3765
Run:02 Epoch: 1421 loss_train: 1.3454 loss_val: 1.3743
Run:02 Epoch: 1431 loss_train: 1.3471 loss_val: 1.3729
Run:02 Epoch: 1441 loss_train: 1.3443 loss_val: 1.3730
Run:02 Epoch: 1451 loss_train: 1.3433 loss_val: 1.3718
Run:02 Epoch: 1461 loss_train: 1.3459 loss_val: 1.3760
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [13:24<00:00, 402.22s/it]Run Train: 100%|██████████| 2/2 [13:24<00:00, 402.33s/it]
loss_train: 1.3447 loss_val: 1.3745
Run:02 Epoch: 1481 loss_train: 1.3434 loss_val: 1.3728
Run:02 Epoch: 1491 loss_train: 1.3456 loss_val: 1.3706
test acc: 0.4359903381642512 test acc std 0.0024154589371980784


test micro f1: 0.4359903381642512 test macro f1 0.37752328076231234
