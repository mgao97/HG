/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
args
 Namespace(samples=4, concat=6, runs=2, latent_size=10, dataset='cocitationciteseer', seed=42, epochs=1500, lr=0.0001, weight_decay=0.0005, hidden=64, dropout=0.5, batch_size=128, tem=0.6, lam=1.0, pretrain_epochs=8, pretrain_lr=0.005, conditional=True, update_epochs=20, num_models=100, warmup=200, cuda=False)
This is cocitation_citeseer dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data.
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7921 loss_val: 1.7919
Run:01 Epoch: 0011 loss_train: 1.7917 loss_val: 1.7915
Run:01 Epoch: 0021 loss_train: 1.7913 loss_val: 1.7910
Run:01 Epoch: 0031 loss_train: 1.7908 loss_val: 1.7905
Run:01 Epoch: 0041 loss_train: 1.7903 loss_val: 1.7900
Run:01 Epoch: 0051 loss_train: 1.7898 loss_val: 1.7894
Run:01 Epoch: 0061 loss_train: 1.7892 loss_val: 1.7888
Run:01 Epoch: 0071 loss_train: 1.7886 loss_val: 1.7881
Run:01 Epoch: 0081 loss_train: 1.7878 loss_val: 1.7873
Run:01 Epoch: 0091 loss_train: 1.7871 loss_val: 1.7865
Run:01 Epoch: 0101 loss_train: 1.7863 loss_val: 1.7856
Run:01 Epoch: 0111 loss_train: 1.7854 loss_val: 1.7846
Run:01 Epoch: 0121 loss_train: 1.7844 loss_val: 1.7836
Run:01 Epoch: 0131 loss_train: 1.7837 loss_val: 1.7826
Run:01 Epoch: 0141 loss_train: 1.7828 loss_val: 1.7815
Run:01 Epoch: 0151 loss_train: 1.7817 loss_val: 1.7804
Run:01 Epoch: 0161 loss_train: 1.7808 loss_val: 1.7793
Run:01 Epoch: 0171 loss_train: 1.7797 loss_val: 1.7783
Run:01 Epoch: 0181 loss_train: 1.7789 loss_val: 1.7773
Run:01 Epoch: 0191 loss_train: 1.7781 loss_val: 1.7763
Run:01 Epoch: 0201 loss_train: 1.7774 loss_val: 1.7755
Run:01 Epoch: 0211 loss_train: 1.7765 loss_val: 1.7746
Run:01 Epoch: 0221 loss_train: 1.7758 loss_val: 1.7739
Run:01 Epoch: 0231 loss_train: 1.7751 loss_val: 1.7732
Run:01 Epoch: 0241 loss_train: 1.7746 loss_val: 1.7726
Run:01 Epoch: 0251 loss_train: 1.7738 loss_val: 1.7721
Run:01 Epoch: 0261 loss_train: 1.7735 loss_val: 1.7716
Run:01 Epoch: 0271 loss_train: 1.7730 loss_val: 1.7712
Run:01 Epoch: 0281 loss_train: 1.7725 loss_val: 1.7709
Run:01 Epoch: 0291 loss_train: 1.7722 loss_val: 1.7706
Run:01 Epoch: 0301 loss_train: 1.7718 loss_val: 1.7704
Run:01 Epoch: 0311 loss_train: 1.7713 loss_val: 1.7702
Run:01 Epoch: 0321 loss_train: 1.7712 loss_val: 1.7700
Run:01 Epoch: 0331 loss_train: 1.7712 loss_val: 1.7699
Run:01 Epoch: 0341 loss_train: 1.7708 loss_val: 1.7697
Run:01 Epoch: 0351 loss_train: 1.7705 loss_val: 1.7696
Run:01 Epoch: 0361 loss_train: 1.7701 loss_val: 1.7696
Run:01 Epoch: 0371 loss_train: 1.7700 loss_val: 1.7695
Run:01 Epoch: 0381 loss_train: 1.7703 loss_val: 1.7694
Run:01 Epoch: 0391 loss_train: 1.7702 loss_val: 1.7693
Run:01 Epoch: 0401 loss_train: 1.7701 loss_val: 1.7692
Run:01 Epoch: 0411 loss_train: 1.7695 loss_val: 1.7691
Run:01 Epoch: 0421 loss_train: 1.7697 loss_val: 1.7690
Run:01 Epoch: 0431 loss_train: 1.7695 loss_val: 1.7689
Run:01 Epoch: 0441 loss_train: 1.7693 loss_val: 1.7688
Run:01 Epoch: 0451 loss_train: 1.7689 loss_val: 1.7686
Run:01 Epoch: 0461 loss_train: 1.7687 loss_val: 1.7685
Run:01 Epoch: 0471 loss_train: 1.7688 loss_val: 1.7684
Run:01 Epoch: 0481 loss_train: 1.7685 loss_val: 1.7682
Run:01 Epoch: 0491 loss_train: 1.7684 loss_val: 1.7680
Run:01 Epoch: 0501 loss_train: 1.7682 loss_val: 1.7679
Run:01 Epoch: 0511 loss_train: 1.7682 loss_val: 1.7677
Run:01 Epoch: 0521 loss_train: 1.7676 loss_val: 1.7675
Run:01 Epoch: 0531 loss_train: 1.7674 loss_val: 1.7673
Run:01 Epoch: 0541 loss_train: 1.7675 loss_val: 1.7671
Run:01 Epoch: 0551 loss_train: 1.7668 loss_val: 1.7669
Run:01 Epoch: 0561 loss_train: 1.7664 loss_val: 1.7666
Run:01 Epoch: 0571 loss_train: 1.7663 loss_val: 1.7664
Run:01 Epoch: 0581 loss_train: 1.7664 loss_val: 1.7662
Run:01 Epoch: 0591 loss_train: 1.7657 loss_val: 1.7659
Run:01 Epoch: 0601 loss_train: 1.7653 loss_val: 1.7657
Run:01 Epoch: 0611 loss_train: 1.7652 loss_val: 1.7654
Run:01 Epoch: 0621 loss_train: 1.7649 loss_val: 1.7651
Run:01 Epoch: 0631 loss_train: 1.7645 loss_val: 1.7648
Run:01 Epoch: 0641 loss_train: 1.7641 loss_val: 1.7646
Run:01 Epoch: 0651 loss_train: 1.7638 loss_val: 1.7643
Run:01 Epoch: 0661 loss_train: 1.7634 loss_val: 1.7640
Run:01 Epoch: 0671 loss_train: 1.7632 loss_val: 1.7637
Run:01 Epoch: 0681 loss_train: 1.7631 loss_val: 1.7634
Run:01 Epoch: 0691 loss_train: 1.7628 loss_val: 1.7631
Run:01 Epoch: 0701 loss_train: 1.7622 loss_val: 1.7627
Run:01 Epoch: 0711 loss_train: 1.7618 loss_val: 1.7624
Run:01 Epoch: 0721 loss_train: 1.7612 loss_val: 1.7621
Run:01 Epoch: 0731 loss_train: 1.7609 loss_val: 1.7617
Run:01 Epoch: 0741 loss_train: 1.7604 loss_val: 1.7613
Run:01 Epoch: 0751 loss_train: 1.7602 loss_val: 1.7610
Run:01 Epoch: 0761 loss_train: 1.7596 loss_val: 1.7606
Run:01 Epoch: 0771 loss_train: 1.7594 loss_val: 1.7602
Run:01 Epoch: 0781 loss_train: 1.7589 loss_val: 1.7598
Run:01 Epoch: 0791 loss_train: 1.7583 loss_val: 1.7594
Run:01 Epoch: 0801 loss_train: 1.7579 loss_val: 1.7589
Run:01 Epoch: 0811 loss_train: 1.7573 loss_val: 1.7585
Run:01 Epoch: 0821 loss_train: 1.7571 loss_val: 1.7581
Run:01 Epoch: 0831 loss_train: 1.7563 loss_val: 1.7576
Run:01 Epoch: 0841 loss_train: 1.7559 loss_val: 1.7572
Run:01 Epoch: 0851 loss_train: 1.7554 loss_val: 1.7567
Run:01 Epoch: 0861 loss_train: 1.7545 loss_val: 1.7563
Run:01 Epoch: 0871 loss_train: 1.7544 loss_val: 1.7558
Run:01 Epoch: 0881 loss_train: 1.7532 loss_val: 1.7553
Run:01 Epoch: 0891 loss_train: 1.7530 loss_val: 1.7548
Run:01 Epoch: 0901 loss_train: 1.7527 loss_val: 1.7543
Run:01 Epoch: 0911 loss_train: 1.7516 loss_val: 1.7538
Run:01 Epoch: 0921 loss_train: 1.7517 loss_val: 1.7533
Run:01 Epoch: 0931 loss_train: 1.7507 loss_val: 1.7527
Run:01 Epoch: 0941 loss_train: 1.7503 loss_val: 1.7522
Run:01 Epoch: 0951 loss_train: 1.7494 loss_val: 1.7516
Run:01 Epoch: 0961 loss_train: 1.7489 loss_val: 1.7511
Run:01 Epoch: 0971 loss_train: 1.7476 loss_val: 1.7506
Run:01 Epoch: 0981 loss_train: 1.7475 loss_val: 1.7500
Run:01 Epoch: 0991 loss_train: 1.7467 loss_val: 1.7494
Run:01 Epoch: 1001 loss_train: 1.7469 loss_val: 1.7489
Run:01 Epoch: 1011 loss_train: 1.7456 loss_val: 1.7483
Run:01 Epoch: 1021 loss_train: 1.7447 loss_val: 1.7477
Run:01 Epoch: 1031 loss_train: 1.7446 loss_val: 1.7471
Run:01 Epoch: 1041 loss_train: 1.7436 loss_val: 1.7465
Run:01 Epoch: 1051 loss_train: 1.7429 loss_val: 1.7459
Run:01 Epoch: 1061 loss_train: 1.7417 loss_val: 1.7453
Run:01 Epoch: 1071 loss_train: 1.7413 loss_val: 1.7446
Run:01 Epoch: 1081 loss_train: 1.7405 loss_val: 1.7440
Run:01 Epoch: 1091 loss_train: 1.7394 loss_val: 1.7433
Run:01 Epoch: 1101 loss_train: 1.7395 loss_val: 1.7427
Run:01 Epoch: 1111 loss_train: 1.7387 loss_val: 1.7420
Run:01 Epoch: 1121 loss_train: 1.7379 loss_val: 1.7414
Run:01 Epoch: 1131 loss_train: 1.7366 loss_val: 1.7407
Run:01 Epoch: 1141 loss_train: 1.7358 loss_val: 1.7400
Run:01 Epoch: 1151 loss_train: 1.7352 loss_val: 1.7393
Run:01 Epoch: 1161 loss_train: 1.7342 loss_val: 1.7386
Run:01 Epoch: 1171 loss_train: 1.7338 loss_val: 1.7380
Run:01 Epoch: 1181 loss_train: 1.7329 loss_val: 1.7373
Run:01 Epoch: 1191 loss_train: 1.7323 loss_val: 1.7366
Run:01 Epoch: 1201 loss_train: 1.7313 loss_val: 1.7359
Run:01 Epoch: 1211 loss_train: 1.7305 loss_val: 1.7352
Run:01 Epoch: 1221 loss_train: 1.7294 loss_val: 1.7344
Run:01 Epoch: 1231 loss_train: 1.7284 loss_val: 1.7337
Run:01 Epoch: 1241 loss_train: 1.7281 loss_val: 1.7330
Run:01 Epoch: 1251 loss_train: 1.7274 loss_val: 1.7322
Run:01 Epoch: 1261 loss_train: 1.7263 loss_val: 1.7315
Run:01 Epoch: 1271 loss_train: 1.7253 loss_val: 1.7308
Run:01 Epoch: 1281 loss_train: 1.7249 loss_val: 1.7300
Run:01 Epoch: 1291 loss_train: 1.7249 loss_val: 1.7293
Run:01 Epoch: 1301 loss_train: 1.7234 loss_val: 1.7286
Run:01 Epoch: 1311 loss_train: 1.7220 loss_val: 1.7278
Run:01 Epoch: 1321 loss_train: 1.7211 loss_val: 1.7271
Run:01 Epoch: 1331 loss_train: 1.7205 loss_val: 1.7263
Run:01 Epoch: 1341 loss_train: 1.7197 loss_val: 1.7255
Run:01 Epoch: 1351 loss_train: 1.7193 loss_val: 1.7248
Run:01 Epoch: 1361 loss_train: 1.7183 loss_val: 1.7240
Run:01 Epoch: 1371 loss_train: 1.7170 loss_val: 1.7232
Run:01 Epoch: 1381 loss_train: 1.7161 loss_val: 1.7224
Run:01 Epoch: 1391 loss_train: 1.7149 loss_val: 1.7217
Run:01 Epoch: 1401 loss_train: 1.7144 loss_val: 1.7209
Run:01 Epoch: 1411 loss_train: 1.7134 loss_val: 1.7201
Run:01 Epoch: 1421 loss_train: 1.7128 loss_val: 1.7193
Run:01 Epoch: 1431 loss_train: 1.7120 loss_val: 1.7186
Run:01 Epoch: 1441 loss_train: 1.7105 loss_val: 1.7178
Run:01 Epoch: 1451 loss_train: 1.7104 loss_val: 1.7170
Run:01 Epoch: 1461 loss_train: 1.7094 loss_val: 1.7162
Run:01 Epoch: 1471 loss_train: 1.7085 loss_val: 1.7154
Run:01 Epoch: 1481 loss_train: 1.7079 Run Train:  50%|█████     | 1/2 [10:00<10:00, 600.27s/it]loss_val: 1.7146
Run:01 Epoch: 1491 loss_train: 1.7062 loss_val: 1.7138
Run:02 Epoch: 0001 loss_train: 1.7064 loss_val: 1.7130
Run:02 Epoch: 0011 loss_train: 1.7055 loss_val: 1.7123
Run:02 Epoch: 0021 loss_train: 1.7047 loss_val: 1.7115
Run:02 Epoch: 0031 loss_train: 1.7030 loss_val: 1.7107
Run:02 Epoch: 0041 loss_train: 1.7022 loss_val: 1.7099
Run:02 Epoch: 0051 loss_train: 1.7015 loss_val: 1.7091
Run:02 Epoch: 0061 loss_train: 1.7013 loss_val: 1.7083
Run:02 Epoch: 0071 loss_train: 1.6993 loss_val: 1.7075
Run:02 Epoch: 0081 loss_train: 1.6989 loss_val: 1.7067
Run:02 Epoch: 0091 loss_train: 1.6985 loss_val: 1.7060
Run:02 Epoch: 0101 loss_train: 1.6973 loss_val: 1.7052
Run:02 Epoch: 0111 loss_train: 1.6967 loss_val: 1.7044
Run:02 Epoch: 0121 loss_train: 1.6962 loss_val: 1.7036
Run:02 Epoch: 0131 loss_train: 1.6943 loss_val: 1.7028
Run:02 Epoch: 0141 loss_train: 1.6940 loss_val: 1.7020
Run:02 Epoch: 0151 loss_train: 1.6929 loss_val: 1.7012
Run:02 Epoch: 0161 loss_train: 1.6922 loss_val: 1.7004
Run:02 Epoch: 0171 loss_train: 1.6913 loss_val: 1.6996
Run:02 Epoch: 0181 loss_train: 1.6905 loss_val: 1.6989
Run:02 Epoch: 0191 loss_train: 1.6893 loss_val: 1.6981
Run:02 Epoch: 0201 loss_train: 1.6879 loss_val: 1.6973
Run:02 Epoch: 0211 loss_train: 1.6882 loss_val: 1.6965
Run:02 Epoch: 0221 loss_train: 1.6869 loss_val: 1.6957
Run:02 Epoch: 0231 loss_train: 1.6860 loss_val: 1.6950
Run:02 Epoch: 0241 loss_train: 1.6861 loss_val: 1.6942
Run:02 Epoch: 0251 loss_train: 1.6846 loss_val: 1.6934
Run:02 Epoch: 0261 loss_train: 1.6834 loss_val: 1.6927
Run:02 Epoch: 0271 loss_train: 1.6823 loss_val: 1.6919
Run:02 Epoch: 0281 loss_train: 1.6813 loss_val: 1.6911
Run:02 Epoch: 0291 loss_train: 1.6815 loss_val: 1.6904
Run:02 Epoch: 0301 loss_train: 1.6793 loss_val: 1.6896
Run:02 Epoch: 0311 loss_train: 1.6793 loss_val: 1.6888
Run:02 Epoch: 0321 loss_train: 1.6787 loss_val: 1.6880
Run:02 Epoch: 0331 loss_train: 1.6775 loss_val: 1.6873
Run:02 Epoch: 0341 loss_train: 1.6765 loss_val: 1.6865
Run:02 Epoch: 0351 loss_train: 1.6769 loss_val: 1.6857
Run:02 Epoch: 0361 loss_train: 1.6748 loss_val: 1.6850
Run:02 Epoch: 0371 loss_train: 1.6737 loss_val: 1.6842
Run:02 Epoch: 0381 loss_train: 1.6729 loss_val: 1.6834
Run:02 Epoch: 0391 loss_train: 1.6729 loss_val: 1.6827
Run:02 Epoch: 0401 loss_train: 1.6718 loss_val: 1.6819
Run:02 Epoch: 0411 loss_train: 1.6714 loss_val: 1.6812
Run:02 Epoch: 0421 loss_train: 1.6700 loss_val: 1.6804
Run:02 Epoch: 0431 loss_train: 1.6703 loss_val: 1.6797
Run:02 Epoch: 0441 loss_train: 1.6680 loss_val: 1.6789
Run:02 Epoch: 0451 loss_train: 1.6671 loss_val: 1.6781
Run:02 Epoch: 0461 loss_train: 1.6662 loss_val: 1.6774
Run:02 Epoch: 0471 loss_train: 1.6662 loss_val: 1.6766
Run:02 Epoch: 0481 loss_train: 1.6651 loss_val: 1.6759
Run:02 Epoch: 0491 loss_train: 1.6636 loss_val: 1.6751
Run:02 Epoch: 0501 loss_train: 1.6636 loss_val: 1.6744
Run:02 Epoch: 0511 loss_train: 1.6627 loss_val: 1.6737
Run:02 Epoch: 0521 loss_train: 1.6613 loss_val: 1.6729
Run:02 Epoch: 0531 loss_train: 1.6613 loss_val: 1.6721
Run:02 Epoch: 0541 loss_train: 1.6599 loss_val: 1.6714
Run:02 Epoch: 0551 loss_train: 1.6590 loss_val: 1.6706
Run:02 Epoch: 0561 loss_train: 1.6582 loss_val: 1.6699
Run:02 Epoch: 0571 loss_train: 1.6590 loss_val: 1.6691
Run:02 Epoch: 0581 loss_train: 1.6574 loss_val: 1.6684
Run:02 Epoch: 0591 loss_train: 1.6557 loss_val: 1.6677
Run:02 Epoch: 0601 loss_train: 1.6552 loss_val: 1.6670
Run:02 Epoch: 0611 loss_train: 1.6538 loss_val: 1.6662
Run:02 Epoch: 0621 loss_train: 1.6532 loss_val: 1.6655
Run:02 Epoch: 0631 loss_train: 1.6531 loss_val: 1.6648
Run:02 Epoch: 0641 loss_train: 1.6532 loss_val: 1.6641
Run:02 Epoch: 0651 loss_train: 1.6517 loss_val: 1.6633
Run:02 Epoch: 0661 loss_train: 1.6516 loss_val: 1.6626
Run:02 Epoch: 0671 loss_train: 1.6503 loss_val: 1.6619
Run:02 Epoch: 0681 loss_train: 1.6497 loss_val: 1.6611
Run:02 Epoch: 0691 loss_train: 1.6488 loss_val: 1.6604
Run:02 Epoch: 0701 loss_train: 1.6477 loss_val: 1.6597
Run:02 Epoch: 0711 loss_train: 1.6465 loss_val: 1.6590
Run:02 Epoch: 0721 loss_train: 1.6472 loss_val: 1.6583
Run:02 Epoch: 0731 loss_train: 1.6456 loss_val: 1.6576
Run:02 Epoch: 0741 loss_train: 1.6453 loss_val: 1.6569
Run:02 Epoch: 0751 loss_train: 1.6439 loss_val: 1.6562
Run:02 Epoch: 0761 loss_train: 1.6444 loss_val: 1.6555
Run:02 Epoch: 0771 loss_train: 1.6430 loss_val: 1.6548
Run:02 Epoch: 0781 loss_train: 1.6420 loss_val: 1.6541
Run:02 Epoch: 0791 loss_train: 1.6410 loss_val: 1.6534
Run:02 Epoch: 0801 loss_train: 1.6410 loss_val: 1.6527
Run:02 Epoch: 0811 loss_train: 1.6401 loss_val: 1.6520
Run:02 Epoch: 0821 loss_train: 1.6392 loss_val: 1.6513
Run:02 Epoch: 0831 loss_train: 1.6384 loss_val: 1.6506
Run:02 Epoch: 0841 loss_train: 1.6370 loss_val: 1.6499
Run:02 Epoch: 0851 loss_train: 1.6375 loss_val: 1.6493
Run:02 Epoch: 0861 loss_train: 1.6367 loss_val: 1.6486
Run:02 Epoch: 0871 loss_train: 1.6356 loss_val: 1.6479
Run:02 Epoch: 0881 loss_train: 1.6347 loss_val: 1.6472
Run:02 Epoch: 0891 loss_train: 1.6325 loss_val: 1.6465
Run:02 Epoch: 0901 loss_train: 1.6325 loss_val: 1.6459
Run:02 Epoch: 0911 loss_train: 1.6324 loss_val: 1.6452
Run:02 Epoch: 0921 loss_train: 1.6326 loss_val: 1.6445
Run:02 Epoch: 0931 loss_train: 1.6315 loss_val: 1.6438
Run:02 Epoch: 0941 loss_train: 1.6299 loss_val: 1.6432
Run:02 Epoch: 0951 loss_train: 1.6296 loss_val: 1.6425
Run:02 Epoch: 0961 loss_train: 1.6296 loss_val: 1.6418
Run:02 Epoch: 0971 loss_train: 1.6284 loss_val: 1.6412
Run:02 Epoch: 0981 loss_train: 1.6274 loss_val: 1.6405
Run:02 Epoch: 0991 loss_train: 1.6267 loss_val: 1.6398
Run:02 Epoch: 1001 loss_train: 1.6261 loss_val: 1.6392
Run:02 Epoch: 1011 loss_train: 1.6254 loss_val: 1.6385
Run:02 Epoch: 1021 loss_train: 1.6246 loss_val: 1.6378
Run:02 Epoch: 1031 loss_train: 1.6235 loss_val: 1.6372
Run:02 Epoch: 1041 loss_train: 1.6242 loss_val: 1.6365
Run:02 Epoch: 1051 loss_train: 1.6223 loss_val: 1.6359
Run:02 Epoch: 1061 loss_train: 1.6221 loss_val: 1.6352
Run:02 Epoch: 1071 loss_train: 1.6225 loss_val: 1.6345
Run:02 Epoch: 1081 loss_train: 1.6199 loss_val: 1.6339
Run:02 Epoch: 1091 loss_train: 1.6199 loss_val: 1.6332
Run:02 Epoch: 1101 loss_train: 1.6183 loss_val: 1.6325
Run:02 Epoch: 1111 loss_train: 1.6187 loss_val: 1.6319
Run:02 Epoch: 1121 loss_train: 1.6171 loss_val: 1.6312
Run:02 Epoch: 1131 loss_train: 1.6171 loss_val: 1.6306
Run:02 Epoch: 1141 loss_train: 1.6156 loss_val: 1.6299
Run:02 Epoch: 1151 loss_train: 1.6155 loss_val: 1.6293
Run:02 Epoch: 1161 loss_train: 1.6141 loss_val: 1.6287
Run:02 Epoch: 1171 loss_train: 1.6153 loss_val: 1.6280
Run:02 Epoch: 1181 loss_train: 1.6128 loss_val: 1.6274
Run:02 Epoch: 1191 loss_train: 1.6124 loss_val: 1.6267
Run:02 Epoch: 1201 loss_train: 1.6129 loss_val: 1.6261
Run:02 Epoch: 1211 loss_train: 1.6122 loss_val: 1.6254
Run:02 Epoch: 1221 loss_train: 1.6106 loss_val: 1.6248
Run:02 Epoch: 1231 loss_train: 1.6100 loss_val: 1.6242
Run:02 Epoch: 1241 loss_train: 1.6095 loss_val: 1.6236
Run:02 Epoch: 1251 loss_train: 1.6086 loss_val: 1.6229
Run:02 Epoch: 1261 loss_train: 1.6081 loss_val: 1.6223
Run:02 Epoch: 1271 loss_train: 1.6086 loss_val: 1.6217
Run:02 Epoch: 1281 loss_train: 1.6064 loss_val: 1.6211
Run:02 Epoch: 1291 loss_train: 1.6067 loss_val: 1.6204
Run:02 Epoch: 1301 loss_train: 1.6056 loss_val: 1.6198
Run:02 Epoch: 1311 loss_train: 1.6061 loss_val: 1.6192
Run:02 Epoch: 1321 loss_train: 1.6036 loss_val: 1.6186
Run:02 Epoch: 1331 loss_train: 1.6041 loss_val: 1.6180
Run:02 Epoch: 1341 loss_train: 1.6037 loss_val: 1.6174
Run:02 Epoch: 1351 loss_train: 1.6020 loss_val: 1.6167
Run:02 Epoch: 1361 loss_train: 1.6014 loss_val: 1.6161
Run:02 Epoch: 1371 loss_train: 1.6000 loss_val: 1.6155
Run:02 Epoch: 1381 loss_train: 1.6003 loss_val: 1.6149
Run:02 Epoch: 1391 loss_train: 1.6008 loss_val: 1.6143
Run:02 Epoch: 1401 loss_train: 1.5994 loss_val: 1.6137
Run:02 Epoch: 1411 loss_train: 1.5989 loss_val: 1.6131
Run:02 Epoch: 1421 loss_train: 1.5982 loss_val: 1.6125
Run:02 Epoch: 1431 loss_train: 1.5980 loss_val: 1.6119
Run:02 Epoch: 1441 loss_train: 1.5970 loss_val: 1.6113
Run:02 Epoch: 1451 loss_train: 1.5967 loss_val: 1.6107
Run:02 Epoch: 1461 loss_train: 1.5963 loss_val: 1.6101
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [18:03<00:00, 531.39s/it]Run Train: 100%|██████████| 2/2 [18:03<00:00, 541.72s/it]
/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_train: 1.5939 loss_val: 1.6095
Run:02 Epoch: 1481 loss_train: 1.5942 loss_val: 1.6089
Run:02 Epoch: 1491 loss_train: 1.5933 loss_val: 1.6083
test acc: 0.3248792270531401 test acc std 0.049516908212560384


test micro f1: 0.3248792270531401 test macro f1 0.20474680748440827
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7902 loss_val: 1.7902
Run:01 Epoch: 0011 loss_train: 1.7861 loss_val: 1.7853
Run:01 Epoch: 0021 loss_train: 1.7799 loss_val: 1.7780
Run:01 Epoch: 0031 loss_train: 1.7746 loss_val: 1.7720
Run:01 Epoch: 0041 loss_train: 1.7718 loss_val: 1.7705
Run:01 Epoch: 0051 loss_train: 1.7714 loss_val: 1.7716
Run:01 Epoch: 0061 loss_train: 1.7697 loss_val: 1.7696
Run:01 Epoch: 0071 loss_train: 1.7669 loss_val: 1.7668
Run:01 Epoch: 0081 loss_train: 1.7637 loss_val: 1.7643
Run:01 Epoch: 0091 loss_train: 1.7600 loss_val: 1.7612
Run:01 Epoch: 0101 loss_train: 1.7555 loss_val: 1.7570
Run:01 Epoch: 0111 loss_train: 1.7501 loss_val: 1.7520
Run:01 Epoch: 0121 loss_train: 1.7433 loss_val: 1.7464
Run:01 Epoch: 0131 loss_train: 1.7361 loss_val: 1.7401
Run:01 Epoch: 0141 loss_train: 1.7279 loss_val: 1.7329
Run:01 Epoch: 0151 loss_train: 1.7199 loss_val: 1.7253
Run:01 Epoch: 0161 loss_train: 1.7104 loss_val: 1.7172
Run:01 Epoch: 0171 loss_train: 1.7012 loss_val: 1.7088
Run:01 Epoch: 0181 loss_train: 1.6915 loss_val: 1.7000
Run:01 Epoch: 0191 loss_train: 1.6821 loss_val: 1.6911
Run:01 Epoch: 0201 loss_train: 1.6733 loss_val: 1.6823
Run:01 Epoch: 0211 loss_train: 1.6627 loss_val: 1.6733
Run:01 Epoch: 0221 loss_train: 1.6531 loss_val: 1.6644
Run:01 Epoch: 0231 loss_train: 1.6433 loss_val: 1.6557
Run:01 Epoch: 0241 loss_train: 1.6341 loss_val: 1.6470
Run:01 Epoch: 0251 loss_train: 1.6258 loss_val: 1.6385
Run:01 Epoch: 0261 loss_train: 1.6161 loss_val: 1.6303
Run:01 Epoch: 0271 loss_train: 1.6082 loss_val: 1.6223
Run:01 Epoch: 0281 loss_train: 1.6007 loss_val: 1.6143
Run:01 Epoch: 0291 loss_train: 1.5921 loss_val: 1.6068
Run:01 Epoch: 0301 loss_train: 1.5835 loss_val: 1.5992
Run:01 Epoch: 0311 loss_train: 1.5763 loss_val: 1.5921
Run:01 Epoch: 0321 loss_train: 1.5694 loss_val: 1.5851
Run:01 Epoch: 0331 loss_train: 1.5615 loss_val: 1.5785
Run:01 Epoch: 0341 loss_train: 1.5553 loss_val: 1.5719
Run:01 Epoch: 0351 loss_train: 1.5514 loss_val: 1.5658
Run:01 Epoch: 0361 loss_train: 1.5436 loss_val: 1.5595
Run:01 Epoch: 0371 loss_train: 1.5376 loss_val: 1.5536
Run:01 Epoch: 0381 loss_train: 1.5316 loss_val: 1.5477
Run:01 Epoch: 0391 loss_train: 1.5267 loss_val: 1.5421
Run:01 Epoch: 0401 loss_train: 1.5205 loss_val: 1.5367
Run:01 Epoch: 0411 loss_train: 1.5145 loss_val: 1.5315
Run:01 Epoch: 0421 loss_train: 1.5101 loss_val: 1.5266
Run:01 Epoch: 0431 loss_train: 1.5048 loss_val: 1.5218
Run:01 Epoch: 0441 loss_train: 1.5013 loss_val: 1.5172
Run:01 Epoch: 0451 loss_train: 1.4975 loss_val: 1.5127
Run:01 Epoch: 0461 loss_train: 1.4913 loss_val: 1.5083
Run:01 Epoch: 0471 loss_train: 1.4875 loss_val: 1.5044
Run:01 Epoch: 0481 loss_train: 1.4837 loss_val: 1.5003
Run:01 Epoch: 0491 loss_train: 1.4805 loss_val: 1.4965
Run:01 Epoch: 0501 loss_train: 1.4753 loss_val: 1.4927
Run:01 Epoch: 0511 loss_train: 1.4720 loss_val: 1.4891
Run:01 Epoch: 0521 loss_train: 1.4694 loss_val: 1.4858
Run:01 Epoch: 0531 loss_train: 1.4661 loss_val: 1.4827
Run:01 Epoch: 0541 loss_train: 1.4634 loss_val: 1.4796
Run:01 Epoch: 0551 loss_train: 1.4623 loss_val: 1.4765
Run:01 Epoch: 0561 loss_train: 1.4572 loss_val: 1.4734
Run:01 Epoch: 0571 loss_train: 1.4549 loss_val: 1.4706
Run:01 Epoch: 0581 loss_train: 1.4503 loss_val: 1.4676
Run:01 Epoch: 0591 loss_train: 1.4476 loss_val: 1.4649
Run:01 Epoch: 0601 loss_train: 1.4463 loss_val: 1.4623
Run:01 Epoch: 0611 loss_train: 1.4434 loss_val: 1.4602
Run:01 Epoch: 0621 loss_train: 1.4404 loss_val: 1.4578
Run:01 Epoch: 0631 loss_train: 1.4389 loss_val: 1.4554
Run:01 Epoch: 0641 loss_train: 1.4353 loss_val: 1.4529
Run:01 Epoch: 0651 loss_train: 1.4338 loss_val: 1.4508
Run:01 Epoch: 0661 loss_train: 1.4318 loss_val: 1.4489
Run:01 Epoch: 0671 loss_train: 1.4316 loss_val: 1.4469
Run:01 Epoch: 0681 loss_train: 1.4294 loss_val: 1.4450
Run:01 Epoch: 0691 loss_train: 1.4262 loss_val: 1.4432
Run:01 Epoch: 0701 loss_train: 1.4230 loss_val: 1.4412
Run:01 Epoch: 0711 loss_train: 1.4218 loss_val: 1.4396
Run:01 Epoch: 0721 loss_train: 1.4198 loss_val: 1.4376
Run:01 Epoch: 0731 loss_train: 1.4177 loss_val: 1.4359
Run:01 Epoch: 0741 loss_train: 1.4150 loss_val: 1.4344
Run:01 Epoch: 0751 loss_train: 1.4159 loss_val: 1.4329
Run:01 Epoch: 0761 loss_train: 1.4144 loss_val: 1.4313
Run:01 Epoch: 0771 loss_train: 1.4107 loss_val: 1.4300
Run:01 Epoch: 0781 loss_train: 1.4099 loss_val: 1.4285
Run:01 Epoch: 0791 loss_train: 1.4089 loss_val: 1.4271
Run:01 Epoch: 0801 loss_train: 1.4080 loss_val: 1.4258
Run:01 Epoch: 0811 loss_train: 1.4061 loss_val: 1.4243
Run:01 Epoch: 0821 loss_train: 1.4031 loss_val: 1.4230
Run:01 Epoch: 0831 loss_train: 1.4027 loss_val: 1.4219
Run:01 Epoch: 0841 loss_train: 1.4021 loss_val: 1.4205
Run:01 Epoch: 0851 loss_train: 1.4008 loss_val: 1.4193
Run:01 Epoch: 0861 loss_train: 1.3965 loss_val: 1.4181
Run:01 Epoch: 0871 loss_train: 1.3959 loss_val: 1.4170
Run:01 Epoch: 0881 loss_train: 1.3940 loss_val: 1.4158
Run:01 Epoch: 0891 loss_train: 1.3947 loss_val: 1.4146
Run:01 Epoch: 0901 loss_train: 1.3941 loss_val: 1.4138
Run:01 Epoch: 0911 loss_train: 1.3901 loss_val: 1.4128
Run:01 Epoch: 0921 loss_train: 1.3908 loss_val: 1.4120
Run:01 Epoch: 0931 loss_train: 1.3877 loss_val: 1.4110
Run:01 Epoch: 0941 loss_train: 1.3883 loss_val: 1.4101
Run:01 Epoch: 0951 loss_train: 1.3870 loss_val: 1.4091
Run:01 Epoch: 0961 loss_train: 1.3851 loss_val: 1.4084
Run:01 Epoch: 0971 loss_train: 1.3844 loss_val: 1.4077
Run:01 Epoch: 0981 loss_train: 1.3848 loss_val: 1.4066
Run:01 Epoch: 0991 loss_train: 1.3814 loss_val: 1.4056
Run:01 Epoch: 1001 loss_train: 1.3826 loss_val: 1.4047
Run:01 Epoch: 1011 loss_train: 1.3809 loss_val: 1.4044
Run:01 Epoch: 1021 loss_train: 1.3816 loss_val: 1.4036
Run:01 Epoch: 1031 loss_train: 1.3789 loss_val: 1.4026
Run:01 Epoch: 1041 loss_train: 1.3784 loss_val: 1.4018
Run:01 Epoch: 1051 loss_train: 1.3753 loss_val: 1.4011
Run:01 Epoch: 1061 loss_train: 1.3747 loss_val: 1.4003
Run:01 Epoch: 1071 loss_train: 1.3749 loss_val: 1.3997
Run:01 Epoch: 1081 loss_train: 1.3760 loss_val: 1.3992
Run:01 Epoch: 1091 loss_train: 1.3754 loss_val: 1.3984
Run:01 Epoch: 1101 loss_train: 1.3730 loss_val: 1.3980
Run:01 Epoch: 1111 loss_train: 1.3715 loss_val: 1.3976
Run:01 Epoch: 1121 loss_train: 1.3716 loss_val: 1.3968
Run:01 Epoch: 1131 loss_train: 1.3733 loss_val: 1.3962
Run:01 Epoch: 1141 loss_train: 1.3692 loss_val: 1.3957
Run:01 Epoch: 1151 loss_train: 1.3690 loss_val: 1.3954
Run:01 Epoch: 1161 loss_train: 1.3674 loss_val: 1.3949
Run:01 Epoch: 1171 loss_train: 1.3674 loss_val: 1.3945
Run:01 Epoch: 1181 loss_train: 1.3674 loss_val: 1.3937
Run:01 Epoch: 1191 loss_train: 1.3680 loss_val: 1.3932
Run:01 Epoch: 1201 loss_train: 1.3681 loss_val: 1.3927
Run:01 Epoch: 1211 loss_train: 1.3649 loss_val: 1.3921
Run:01 Epoch: 1221 loss_train: 1.3655 loss_val: 1.3919
Run:01 Epoch: 1231 loss_train: 1.3652 loss_val: 1.3914
Run:01 Epoch: 1241 loss_train: 1.3640 loss_val: 1.3907
Run:01 Epoch: 1251 loss_train: 1.3654 loss_val: 1.3905
Run:01 Epoch: 1261 loss_train: 1.3642 loss_val: 1.3903
Run:01 Epoch: 1271 loss_train: 1.3627 loss_val: 1.3899
Run:01 Epoch: 1281 loss_train: 1.3612 loss_val: 1.3895
Run:01 Epoch: 1291 loss_train: 1.3611 loss_val: 1.3891
Run:01 Epoch: 1301 loss_train: 1.3648 loss_val: 1.3888
Run:01 Epoch: 1311 loss_train: 1.3572 loss_val: 1.3881
Run:01 Epoch: 1321 loss_train: 1.3617 loss_val: 1.3877
Run:01 Epoch: 1331 loss_train: 1.3585 loss_val: 1.3875
Run:01 Epoch: 1341 loss_train: 1.3583 loss_val: 1.3871
Run:01 Epoch: 1351 loss_train: 1.3574 loss_val: 1.3868
Run:01 Epoch: 1361 loss_train: 1.3556 loss_val: 1.3861
Run:01 Epoch: 1371 loss_train: 1.3599 loss_val: 1.3860
Run:01 Epoch: 1381 loss_train: 1.3578 loss_val: 1.3857
Run:01 Epoch: 1391 loss_train: 1.3586 loss_val: 1.3853
Run:01 Epoch: 1401 loss_train: 1.3574 loss_val: 1.3851
Run:01 Epoch: 1411 loss_train: 1.3564 loss_val: 1.3850
Run:01 Epoch: 1421 loss_train: 1.3580 loss_val: 1.3848
Run:01 Epoch: 1431 loss_train: 1.3540 loss_val: 1.3841
Run:01 Epoch: 1441 loss_train: 1.3545 loss_val: 1.3839
Run:01 Epoch: 1451 loss_train: 1.3571 loss_val: 1.3837
Run:01 Epoch: 1461 loss_train: 1.3538 loss_val: 1.3838
Run:01 Epoch: 1471 loss_train: 1.3526 loss_val: 1.3832
Run:01 Epoch: 1481 loss_train: 1.3524 Run Train:  50%|█████     | 1/2 [09:56<09:56, 596.89s/it]loss_val: 1.3829
Run:01 Epoch: 1491 loss_train: 1.3538 loss_val: 1.3827
Run:02 Epoch: 0001 loss_train: 1.3510 loss_val: 1.3823
Run:02 Epoch: 0011 loss_train: 1.3521 loss_val: 1.3821
Run:02 Epoch: 0021 loss_train: 1.3532 loss_val: 1.3818
Run:02 Epoch: 0031 loss_train: 1.3528 loss_val: 1.3816
Run:02 Epoch: 0041 loss_train: 1.3503 loss_val: 1.3813
Run:02 Epoch: 0051 loss_train: 1.3504 loss_val: 1.3812
Run:02 Epoch: 0061 loss_train: 1.3509 loss_val: 1.3811
Run:02 Epoch: 0071 loss_train: 1.3512 loss_val: 1.3807
Run:02 Epoch: 0081 loss_train: 1.3500 loss_val: 1.3806
Run:02 Epoch: 0091 loss_train: 1.3492 loss_val: 1.3807
Run:02 Epoch: 0101 loss_train: 1.3482 loss_val: 1.3804
Run:02 Epoch: 0111 loss_train: 1.3484 loss_val: 1.3800
Run:02 Epoch: 0121 loss_train: 1.3471 loss_val: 1.3799
Run:02 Epoch: 0131 loss_train: 1.3475 loss_val: 1.3800
Run:02 Epoch: 0141 loss_train: 1.3484 loss_val: 1.3799
Run:02 Epoch: 0151 loss_train: 1.3481 loss_val: 1.3797
Run:02 Epoch: 0161 loss_train: 1.3470 loss_val: 1.3795
Run:02 Epoch: 0171 loss_train: 1.3470 loss_val: 1.3795
Run:02 Epoch: 0181 loss_train: 1.3478 loss_val: 1.3795
Run:02 Epoch: 0191 loss_train: 1.3469 loss_val: 1.3791
Run:02 Epoch: 0201 loss_train: 1.3467 loss_val: 1.3791
Run:02 Epoch: 0211 loss_train: 1.3476 loss_val: 1.3787
Run:02 Epoch: 0221 loss_train: 1.3479 loss_val: 1.3787
Run:02 Epoch: 0231 loss_train: 1.3465 loss_val: 1.3782
Run:02 Epoch: 0241 loss_train: 1.3468 loss_val: 1.3777
Run:02 Epoch: 0251 loss_train: 1.3463 loss_val: 1.3778
Run:02 Epoch: 0261 loss_train: 1.3477 loss_val: 1.3778
Run:02 Epoch: 0271 loss_train: 1.3462 loss_val: 1.3775
Run:02 Epoch: 0281 loss_train: 1.3451 loss_val: 1.3774
Run:02 Epoch: 0291 loss_train: 1.3440 loss_val: 1.3772
Run:02 Epoch: 0301 loss_train: 1.3441 loss_val: 1.3773
Run:02 Epoch: 0311 loss_train: 1.3454 loss_val: 1.3771
Run:02 Epoch: 0321 loss_train: 1.3421 loss_val: 1.3769
Run:02 Epoch: 0331 loss_train: 1.3426 loss_val: 1.3763
Run:02 Epoch: 0341 loss_train: 1.3439 loss_val: 1.3764
Run:02 Epoch: 0351 loss_train: 1.3450 loss_val: 1.3765
Run:02 Epoch: 0361 loss_train: 1.3444 loss_val: 1.3766
Run:02 Epoch: 0371 loss_train: 1.3406 loss_val: 1.3760
Run:02 Epoch: 0381 loss_train: 1.3418 loss_val: 1.3760
Run:02 Epoch: 0391 loss_train: 1.3422 loss_val: 1.3760
Run:02 Epoch: 0401 loss_train: 1.3424 loss_val: 1.3761
Run:02 Epoch: 0411 loss_train: 1.3427 loss_val: 1.3761
Run:02 Epoch: 0421 loss_train: 1.3428 loss_val: 1.3757
Run:02 Epoch: 0431 loss_train: 1.3413 loss_val: 1.3755
Run:02 Epoch: 0441 loss_train: 1.3432 loss_val: 1.3755
Run:02 Epoch: 0451 loss_train: 1.3414 loss_val: 1.3751
Run:02 Epoch: 0461 loss_train: 1.3434 loss_val: 1.3755
Run:02 Epoch: 0471 loss_train: 1.3414 loss_val: 1.3751
Run:02 Epoch: 0481 loss_train: 1.3413 loss_val: 1.3752
Run:02 Epoch: 0491 loss_train: 1.3406 loss_val: 1.3751
Run:02 Epoch: 0501 loss_train: 1.3401 loss_val: 1.3750
Run:02 Epoch: 0511 loss_train: 1.3423 loss_val: 1.3748
Run:02 Epoch: 0521 loss_train: 1.3411 loss_val: 1.3747
Run:02 Epoch: 0531 loss_train: 1.3390 loss_val: 1.3747
Run:02 Epoch: 0541 loss_train: 1.3405 loss_val: 1.3743
Run:02 Epoch: 0551 loss_train: 1.3411 loss_val: 1.3743
Run:02 Epoch: 0561 loss_train: 1.3396 loss_val: 1.3743
Run:02 Epoch: 0571 loss_train: 1.3395 loss_val: 1.3738
Run:02 Epoch: 0581 loss_train: 1.3395 loss_val: 1.3739
Run:02 Epoch: 0591 loss_train: 1.3405 loss_val: 1.3739
Run:02 Epoch: 0601 loss_train: 1.3408 loss_val: 1.3742
Run:02 Epoch: 0611 loss_train: 1.3408 loss_val: 1.3740
Run:02 Epoch: 0621 loss_train: 1.3424 loss_val: 1.3738
Run:02 Epoch: 0631 loss_train: 1.3388 loss_val: 1.3734
Run:02 Epoch: 0641 loss_train: 1.3387 loss_val: 1.3735
Run:02 Epoch: 0651 loss_train: 1.3404 loss_val: 1.3737
Run:02 Epoch: 0661 loss_train: 1.3399 loss_val: 1.3735
Run:02 Epoch: 0671 loss_train: 1.3387 loss_val: 1.3734
Run:02 Epoch: 0681 loss_train: 1.3395 loss_val: 1.3735
Run:02 Epoch: 0691 loss_train: 1.3402 loss_val: 1.3734
Run:02 Epoch: 0701 loss_train: 1.3388 loss_val: 1.3737
Run:02 Epoch: 0711 loss_train: 1.3372 loss_val: 1.3729
Run:02 Epoch: 0721 loss_train: 1.3388 loss_val: 1.3728
Run:02 Epoch: 0731 loss_train: 1.3385 loss_val: 1.3732
Run:02 Epoch: 0741 loss_train: 1.3385 loss_val: 1.3731
Run:02 Epoch: 0751 loss_train: 1.3385 loss_val: 1.3732
Run:02 Epoch: 0761 loss_train: 1.3377 loss_val: 1.3728
Run:02 Epoch: 0771 loss_train: 1.3367 loss_val: 1.3728
Run:02 Epoch: 0781 loss_train: 1.3397 loss_val: 1.3726
Run:02 Epoch: 0791 loss_train: 1.3376 loss_val: 1.3728
Run:02 Epoch: 0801 loss_train: 1.3380 loss_val: 1.3727
Run:02 Epoch: 0811 loss_train: 1.3373 loss_val: 1.3727
Run:02 Epoch: 0821 loss_train: 1.3365 loss_val: 1.3722
Run:02 Epoch: 0831 loss_train: 1.3380 loss_val: 1.3727
Run:02 Epoch: 0841 loss_train: 1.3401 loss_val: 1.3724
Run:02 Epoch: 0851 loss_train: 1.3358 loss_val: 1.3723
Run:02 Epoch: 0861 loss_train: 1.3361 loss_val: 1.3724
Run:02 Epoch: 0871 loss_train: 1.3371 loss_val: 1.3724
Run:02 Epoch: 0881 loss_train: 1.3397 loss_val: 1.3724
Run:02 Epoch: 0891 loss_train: 1.3352 loss_val: 1.3720
Run:02 Epoch: 0901 loss_train: 1.3370 loss_val: 1.3722
Run:02 Epoch: 0911 loss_train: 1.3345 loss_val: 1.3719
Run:02 Epoch: 0921 loss_train: 1.3358 loss_val: 1.3719
Run:02 Epoch: 0931 loss_train: 1.3363 loss_val: 1.3719
Run:02 Epoch: 0941 loss_train: 1.3354 loss_val: 1.3720
Run:02 Epoch: 0951 loss_train: 1.3377 loss_val: 1.3720
Run:02 Epoch: 0961 loss_train: 1.3359 loss_val: 1.3717
Run:02 Epoch: 0971 loss_train: 1.3362 loss_val: 1.3720
Run:02 Epoch: 0981 loss_train: 1.3371 loss_val: 1.3718
Run:02 Epoch: 0991 loss_train: 1.3344 loss_val: 1.3717
Run:02 Epoch: 1001 loss_train: 1.3371 loss_val: 1.3714
Run:02 Epoch: 1011 loss_train: 1.3373 loss_val: 1.3716
Run:02 Epoch: 1021 loss_train: 1.3356 loss_val: 1.3718
Run:02 Epoch: 1031 loss_train: 1.3343 loss_val: 1.3718
Run:02 Epoch: 1041 loss_train: 1.3358 loss_val: 1.3718
Run:02 Epoch: 1051 loss_train: 1.3353 loss_val: 1.3716
Run:02 Epoch: 1061 loss_train: 1.3349 loss_val: 1.3714
Run:02 Epoch: 1071 loss_train: 1.3360 loss_val: 1.3716
Run:02 Epoch: 1081 loss_train: 1.3367 loss_val: 1.3717
Run:02 Epoch: 1091 loss_train: 1.3355 loss_val: 1.3715
Run:02 Epoch: 1101 loss_train: 1.3339 loss_val: 1.3714
Run:02 Epoch: 1111 loss_train: 1.3341 loss_val: 1.3713
Run:02 Epoch: 1121 loss_train: 1.3359 loss_val: 1.3712
Run:02 Epoch: 1131 loss_train: 1.3372 loss_val: 1.3717
Run:02 Epoch: 1141 loss_train: 1.3360 loss_val: 1.3713
Run:02 Epoch: 1151 loss_train: 1.3344 loss_val: 1.3714
Run:02 Epoch: 1161 loss_train: 1.3343 loss_val: 1.3716
Run:02 Epoch: 1171 loss_train: 1.3358 loss_val: 1.3713
Run:02 Epoch: 1181 loss_train: 1.3370 loss_val: 1.3713
Run:02 Epoch: 1191 loss_train: 1.3348 loss_val: 1.3711
Run:02 Epoch: 1201 loss_train: 1.3342 loss_val: 1.3711
Run:02 Epoch: 1211 loss_train: 1.3349 loss_val: 1.3712
Run:02 Epoch: 1221 loss_train: 1.3335 loss_val: 1.3711
Run:02 Epoch: 1231 loss_train: 1.3358 loss_val: 1.3707
Run:02 Epoch: 1241 loss_train: 1.3356 loss_val: 1.3712
Run:02 Epoch: 1251 loss_train: 1.3359 loss_val: 1.3709
Run:02 Epoch: 1261 loss_train: 1.3355 loss_val: 1.3710
Run:02 Epoch: 1271 loss_train: 1.3364 loss_val: 1.3710
Run:02 Epoch: 1281 loss_train: 1.3340 loss_val: 1.3707
Run:02 Epoch: 1291 loss_train: 1.3338 loss_val: 1.3706
Run:02 Epoch: 1301 loss_train: 1.3321 loss_val: 1.3709
Run:02 Epoch: 1311 loss_train: 1.3355 loss_val: 1.3709
Run:02 Epoch: 1321 loss_train: 1.3341 loss_val: 1.3708
Run:02 Epoch: 1331 loss_train: 1.3342 loss_val: 1.3706
Run:02 Epoch: 1341 loss_train: 1.3344 loss_val: 1.3706
Run:02 Epoch: 1351 loss_train: 1.3356 loss_val: 1.3708
Run:02 Epoch: 1361 loss_train: 1.3336 loss_val: 1.3706
Run:02 Epoch: 1371 loss_train: 1.3356 loss_val: 1.3708
Run:02 Epoch: 1381 loss_train: 1.3366 loss_val: 1.3707
Run:02 Epoch: 1391 loss_train: 1.3348 loss_val: 1.3710
Run:02 Epoch: 1401 loss_train: 1.3334 loss_val: 1.3710
Run:02 Epoch: 1411 loss_train: 1.3321 loss_val: 1.3709
Run:02 Epoch: 1421 loss_train: 1.3329 loss_val: 1.3705
Run:02 Epoch: 1431 loss_train: 1.3345 loss_val: 1.3704
Run:02 Epoch: 1441 loss_train: 1.3332 loss_val: 1.3707
Run:02 Epoch: 1451 loss_train: 1.3330 loss_val: 1.3705
Run:02 Epoch: 1461 loss_train: 1.3350 loss_val: 1.3703
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [1:02:11<00:00, 2089.80s/it]Run Train: 100%|██████████| 2/2 [1:02:11<00:00, 1865.86s/it]
/users/Min/miniconda/envs/hy/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_train: 1.3344 loss_val: 1.3706
Run:02 Epoch: 1481 loss_train: 1.3342 loss_val: 1.3706
Run:02 Epoch: 1491 loss_train: 1.3348 loss_val: 1.3705
test acc: 0.4384057971014493 test acc std 0.0036231884057971175


test micro f1: 0.4384057971014493 test macro f1 0.3792758458772645
Run Train:   0%|          | 0/2 [00:00<?, ?it/s]Run:01 Epoch: 0001 loss_train: 1.7904 loss_val: 1.8437
Run:01 Epoch: 0011 loss_train: 1.7647 loss_val: 1.7596
Run:01 Epoch: 0021 loss_train: 1.6449 loss_val: 1.6385
Run:01 Epoch: 0031 loss_train: 1.5255 loss_val: 1.5098
Run:01 Epoch: 0041 loss_train: 1.4553 loss_val: 1.4396
Run:01 Epoch: 0051 loss_train: 1.4233 loss_val: 1.4135
Run:01 Epoch: 0061 loss_train: 1.4168 loss_val: 1.4082
Run:01 Epoch: 0071 loss_train: 1.4148 loss_val: 1.4003
Run:01 Epoch: 0081 loss_train: 1.4124 loss_val: 1.3988
Run:01 Epoch: 0091 loss_train: 1.4197 loss_val: 1.4021
Run:01 Epoch: 0101 loss_train: 1.4168 loss_val: 1.4012
Run:01 Epoch: 0111 loss_train: 1.4170 loss_val: 1.3998
Run:01 Epoch: 0121 loss_train: 1.4096 loss_val: 1.3945
Run:01 Epoch: 0131 loss_train: 1.3975 loss_val: 1.3918
Run:01 Epoch: 0141 loss_train: 1.3960 loss_val: 1.3911
Run:01 Epoch: 0151 loss_train: 1.3978 loss_val: 1.3965
Run:01 Epoch: 0161 loss_train: 1.4040 loss_val: 1.3952
Run:01 Epoch: 0171 loss_train: 1.3964 loss_val: 1.3911
Run:01 Epoch: 0181 loss_train: 1.3962 loss_val: 1.3898
Run:01 Epoch: 0191 loss_train: 1.4027 loss_val: 1.3907
Run:01 Epoch: 0201 loss_train: 1.4001 loss_val: 1.3927
Run:01 Epoch: 0211 loss_train: 1.3982 loss_val: 1.3963
Run:01 Epoch: 0221 loss_train: 1.4040 loss_val: 1.3932
Run:01 Epoch: 0231 loss_train: 1.3986 loss_val: 1.3916
Run:01 Epoch: 0241 loss_train: 1.4018 loss_val: 1.3950
Run:01 Epoch: 0251 loss_train: 1.4015 loss_val: 1.3915
Run:01 Epoch: 0261 loss_train: 1.4012 loss_val: 1.3922
Run:01 Epoch: 0271 loss_train: 1.3999 loss_val: 1.3956
Run:01 Epoch: 0281 loss_train: 1.3987 loss_val: 1.3938
Run:01 Epoch: 0291 loss_train: 1.3974 loss_val: 1.3927
Run:01 Epoch: 0301 loss_train: 1.3996 loss_val: 1.3949
Run:01 Epoch: 0311 loss_train: 1.4034 loss_val: 1.3947
Run:01 Epoch: 0321 loss_train: 1.4008 loss_val: 1.3938
Run:01 Epoch: 0331 loss_train: 1.4052 loss_val: 1.3918
Run:01 Epoch: 0341 loss_train: 1.3995 loss_val: 1.3950
Run:01 Epoch: 0351 loss_train: 1.4009 loss_val: 1.3902
Run:01 Epoch: 0361 loss_train: 1.3987 loss_val: 1.3930
Run:01 Epoch: 0371 loss_train: 1.4011 loss_val: 1.3980
Run:01 Epoch: 0381 loss_train: 1.4011 loss_val: 1.3906
Run:01 Epoch: 0391 loss_train: 1.4024 loss_val: 1.3920
Run:01 Epoch: 0401 loss_train: 1.4000 loss_val: 1.3934
Run:01 Epoch: 0411 loss_train: 1.4043 loss_val: 1.3891
Run:01 Epoch: 0421 loss_train: 1.3970 loss_val: 1.3944
Run:01 Epoch: 0431 loss_train: 1.4008 loss_val: 1.3895
Run:01 Epoch: 0441 loss_train: 1.3964 loss_val: 1.3899
Run:01 Epoch: 0451 loss_train: 1.3990 loss_val: 1.3887
Run:01 Epoch: 0461 loss_train: 1.4020 loss_val: 1.3936
Run:01 Epoch: 0471 loss_train: 1.4001 loss_val: 1.3945
Run:01 Epoch: 0481 loss_train: 1.4022 loss_val: 1.3932
Run:01 Epoch: 0491 loss_train: 1.3963 loss_val: 1.3950
Run:01 Epoch: 0501 loss_train: 1.4071 loss_val: 1.3904
Run:01 Epoch: 0511 loss_train: 1.3946 loss_val: 1.3890
Run:01 Epoch: 0521 loss_train: 1.4001 loss_val: 1.3899
Run:01 Epoch: 0531 loss_train: 1.4065 loss_val: 1.3958
Run:01 Epoch: 0541 loss_train: 1.4002 loss_val: 1.3900
Run:01 Epoch: 0551 loss_train: 1.3993 loss_val: 1.3935
Run:01 Epoch: 0561 loss_train: 1.4017 loss_val: 1.3904
Run:01 Epoch: 0571 loss_train: 1.4012 loss_val: 1.3975
Run:01 Epoch: 0581 loss_train: 1.3998 loss_val: 1.3914
Run:01 Epoch: 0591 loss_train: 1.3965 loss_val: 1.3910
Run:01 Epoch: 0601 loss_train: 1.3977 loss_val: 1.3915
Run:01 Epoch: 0611 loss_train: 1.3987 loss_val: 1.3935
Run:01 Epoch: 0621 loss_train: 1.4044 loss_val: 1.3915
Run:01 Epoch: 0631 loss_train: 1.3975 loss_val: 1.3902
Run:01 Epoch: 0641 loss_train: 1.3924 loss_val: 1.3964
Run:01 Epoch: 0651 loss_train: 1.3998 loss_val: 1.3928
Run:01 Epoch: 0661 loss_train: 1.4002 loss_val: 1.3928
Run:01 Epoch: 0671 loss_train: 1.3966 loss_val: 1.3928
Run:01 Epoch: 0681 loss_train: 1.4006 loss_val: 1.3925
Run:01 Epoch: 0691 loss_train: 1.4038 loss_val: 1.3929
Run:01 Epoch: 0701 loss_train: 1.3924 loss_val: 1.3935
Run:01 Epoch: 0711 loss_train: 1.4024 loss_val: 1.3935
Run:01 Epoch: 0721 loss_train: 1.3930 loss_val: 1.3930
Run:01 Epoch: 0731 loss_train: 1.3989 loss_val: 1.3936
Run:01 Epoch: 0741 loss_train: 1.3993 loss_val: 1.3943
Run:01 Epoch: 0751 loss_train: 1.3982 loss_val: 1.3903
Run:01 Epoch: 0761 loss_train: 1.3996 loss_val: 1.3893
Run:01 Epoch: 0771 loss_train: 1.3970 loss_val: 1.3948
Run:01 Epoch: 0781 loss_train: 1.3982 loss_val: 1.3951
Run:01 Epoch: 0791 loss_train: 1.3918 loss_val: 1.3983
Run:01 Epoch: 0801 loss_train: 1.3903 loss_val: 1.3938
Run:01 Epoch: 0811 loss_train: 1.3970 loss_val: 1.3909
Run:01 Epoch: 0821 loss_train: 1.3968 loss_val: 1.3919
Run:01 Epoch: 0831 loss_train: 1.3989 loss_val: 1.3862
Run:01 Epoch: 0841 loss_train: 1.3971 loss_val: 1.3936
Run:01 Epoch: 0851 loss_train: 1.3970 loss_val: 1.3922
Run:01 Epoch: 0861 loss_train: 1.3907 loss_val: 1.3859
Run:01 Epoch: 0871 loss_train: 1.3870 loss_val: 1.3887
Run:01 Epoch: 0881 loss_train: 1.3880 loss_val: 1.3951
Run:01 Epoch: 0891 loss_train: 1.3868 loss_val: 1.3902
Run:01 Epoch: 0901 loss_train: 1.3913 loss_val: 1.3904
Run:01 Epoch: 0911 loss_train: 1.3989 loss_val: 1.3911
Run:01 Epoch: 0921 loss_train: 1.3961 loss_val: 1.3857
Run:01 Epoch: 0931 loss_train: 1.3893 loss_val: 1.3882
Run:01 Epoch: 0941 loss_train: 1.3881 loss_val: 1.3876
Run:01 Epoch: 0951 loss_train: 1.3902 loss_val: 1.3877
Run:01 Epoch: 0961 loss_train: 1.3847 loss_val: 1.3847
Run:01 Epoch: 0971 loss_train: 1.3838 loss_val: 1.3860
Run:01 Epoch: 0981 loss_train: 1.3852 loss_val: 1.3956
Run:01 Epoch: 0991 loss_train: 1.3919 loss_val: 1.3894
Run:01 Epoch: 1001 loss_train: 1.3836 loss_val: 1.3875
Run:01 Epoch: 1011 loss_train: 1.3809 loss_val: 1.3846
Run:01 Epoch: 1021 loss_train: 1.3835 loss_val: 1.3916
Run:01 Epoch: 1031 loss_train: 1.3865 loss_val: 1.3887
Run:01 Epoch: 1041 loss_train: 1.3822 loss_val: 1.3863
Run:01 Epoch: 1051 loss_train: 1.3809 loss_val: 1.3858
Run:01 Epoch: 1061 loss_train: 1.3838 loss_val: 1.3839
Run:01 Epoch: 1071 loss_train: 1.3807 loss_val: 1.3875
Run:01 Epoch: 1081 loss_train: 1.3840 loss_val: 1.3878
Run:01 Epoch: 1091 loss_train: 1.3886 loss_val: 1.3932
Run:01 Epoch: 1101 loss_train: 1.3763 loss_val: 1.3899
Run:01 Epoch: 1111 loss_train: 1.3844 loss_val: 1.3904
Run:01 Epoch: 1121 loss_train: 1.3810 loss_val: 1.3872
Run:01 Epoch: 1131 loss_train: 1.3902 loss_val: 1.3940
Run:01 Epoch: 1141 loss_train: 1.3851 loss_val: 1.3866
Run:01 Epoch: 1151 loss_train: 1.3833 loss_val: 1.3858
Run:01 Epoch: 1161 loss_train: 1.3751 loss_val: 1.3873
Run:01 Epoch: 1171 loss_train: 1.3837 loss_val: 1.3867
Run:01 Epoch: 1181 loss_train: 1.3765 loss_val: 1.3837
Run:01 Epoch: 1191 loss_train: 1.3781 loss_val: 1.3852
Run:01 Epoch: 1201 loss_train: 1.3737 loss_val: 1.3799
Run:01 Epoch: 1211 loss_train: 1.3787 loss_val: 1.3851
Run:01 Epoch: 1221 loss_train: 1.3697 loss_val: 1.3891
Run:01 Epoch: 1231 loss_train: 1.3779 loss_val: 1.3807
Run:01 Epoch: 1241 loss_train: 1.3803 loss_val: 1.3865
Run:01 Epoch: 1251 loss_train: 1.3797 loss_val: 1.3809
Run:01 Epoch: 1261 loss_train: 1.3704 loss_val: 1.3794
Run:01 Epoch: 1271 loss_train: 1.3728 loss_val: 1.3931
Run:01 Epoch: 1281 loss_train: 1.3756 loss_val: 1.3833
Run:01 Epoch: 1291 loss_train: 1.3674 loss_val: 1.3805
Run:01 Epoch: 1301 loss_train: 1.3727 loss_val: 1.3908
Run:01 Epoch: 1311 loss_train: 1.3755 loss_val: 1.3851
Run:01 Epoch: 1321 loss_train: 1.3736 loss_val: 1.3846
Run:01 Epoch: 1331 loss_train: 1.3763 loss_val: 1.3867
Run:01 Epoch: 1341 loss_train: 1.3713 loss_val: 1.3828
Run:01 Epoch: 1351 loss_train: 1.3763 loss_val: 1.3846
Run:01 Epoch: 1361 loss_train: 1.3792 loss_val: 1.3871
Run:01 Epoch: 1371 loss_train: 1.3731 loss_val: 1.3822
Run:01 Epoch: 1381 loss_train: 1.3729 loss_val: 1.3798
Run:01 Epoch: 1391 loss_train: 1.3751 loss_val: 1.3837
Run:01 Epoch: 1401 loss_train: 1.3744 loss_val: 1.3880
Run:01 Epoch: 1411 loss_train: 1.3742 loss_val: 1.3829
Run:01 Epoch: 1421 loss_train: 1.3715 loss_val: 1.3811
Run:01 Epoch: 1431 loss_train: 1.3722 loss_val: 1.3823
Run:01 Epoch: 1441 loss_train: 1.3711 loss_val: 1.3791
Run:01 Epoch: 1451 loss_train: 1.3690 loss_val: 1.3824
Run:01 Epoch: 1461 loss_train: 1.3691 loss_val: 1.3826
Run:01 Epoch: 1471 loss_train: 1.3713 loss_val: 1.3842
Run:01 Epoch: 1481 loss_train: 1.3665 Run Train:  50%|█████     | 1/2 [07:00<07:00, 420.45s/it]loss_val: 1.3819
Run:01 Epoch: 1491 loss_train: 1.3758 loss_val: 1.3836
Run:02 Epoch: 0001 loss_train: 1.3719 loss_val: 1.3800
Run:02 Epoch: 0011 loss_train: 1.3686 loss_val: 1.3807
Run:02 Epoch: 0021 loss_train: 1.3714 loss_val: 1.3833
Run:02 Epoch: 0031 loss_train: 1.3814 loss_val: 1.3924
Run:02 Epoch: 0041 loss_train: 1.3760 loss_val: 1.3859
Run:02 Epoch: 0051 loss_train: 1.3703 loss_val: 1.3813
Run:02 Epoch: 0061 loss_train: 1.3726 loss_val: 1.3785
Run:02 Epoch: 0071 loss_train: 1.3750 loss_val: 1.3850
Run:02 Epoch: 0081 loss_train: 1.3698 loss_val: 1.3810
Run:02 Epoch: 0091 loss_train: 1.3729 loss_val: 1.3826
Run:02 Epoch: 0101 loss_train: 1.3722 loss_val: 1.3800
Run:02 Epoch: 0111 loss_train: 1.3721 loss_val: 1.3821
Run:02 Epoch: 0121 loss_train: 1.3683 loss_val: 1.3803
Run:02 Epoch: 0131 loss_train: 1.3731 loss_val: 1.3847
Run:02 Epoch: 0141 loss_train: 1.3699 loss_val: 1.3817
Run:02 Epoch: 0151 loss_train: 1.3739 loss_val: 1.3817
Run:02 Epoch: 0161 loss_train: 1.3729 loss_val: 1.3815
Run:02 Epoch: 0171 loss_train: 1.3738 loss_val: 1.3782
Run:02 Epoch: 0181 loss_train: 1.3730 loss_val: 1.3785
Run:02 Epoch: 0191 loss_train: 1.3694 loss_val: 1.3779
Run:02 Epoch: 0201 loss_train: 1.3716 loss_val: 1.3876
Run:02 Epoch: 0211 loss_train: 1.3722 loss_val: 1.3802
Run:02 Epoch: 0221 loss_train: 1.3780 loss_val: 1.3813
Run:02 Epoch: 0231 loss_train: 1.3759 loss_val: 1.3832
Run:02 Epoch: 0241 loss_train: 1.3696 loss_val: 1.3811
Run:02 Epoch: 0251 loss_train: 1.3686 loss_val: 1.3796
Run:02 Epoch: 0261 loss_train: 1.3731 loss_val: 1.3799
Run:02 Epoch: 0271 loss_train: 1.3695 loss_val: 1.3783
Run:02 Epoch: 0281 loss_train: 1.3682 loss_val: 1.3809
Run:02 Epoch: 0291 loss_train: 1.3693 loss_val: 1.3805
Run:02 Epoch: 0301 loss_train: 1.3687 loss_val: 1.3805
Run:02 Epoch: 0311 loss_train: 1.3704 loss_val: 1.3889
Run:02 Epoch: 0321 loss_train: 1.3641 loss_val: 1.3799
Run:02 Epoch: 0331 loss_train: 1.3687 loss_val: 1.3809
Run:02 Epoch: 0341 loss_train: 1.3680 loss_val: 1.3805
Run:02 Epoch: 0351 loss_train: 1.3693 loss_val: 1.3826
Run:02 Epoch: 0361 loss_train: 1.3654 loss_val: 1.3804
Run:02 Epoch: 0371 loss_train: 1.3658 loss_val: 1.3828
Run:02 Epoch: 0381 loss_train: 1.3657 loss_val: 1.3797
Run:02 Epoch: 0391 loss_train: 1.3678 loss_val: 1.3798
Run:02 Epoch: 0401 loss_train: 1.3687 loss_val: 1.3800
Run:02 Epoch: 0411 loss_train: 1.3640 loss_val: 1.3794
Run:02 Epoch: 0421 loss_train: 1.3700 loss_val: 1.3783
Run:02 Epoch: 0431 loss_train: 1.3674 loss_val: 1.3787
Run:02 Epoch: 0441 loss_train: 1.3728 loss_val: 1.3812
Run:02 Epoch: 0451 loss_train: 1.3711 loss_val: 1.3789
Run:02 Epoch: 0461 loss_train: 1.3700 loss_val: 1.3816
Run:02 Epoch: 0471 loss_train: 1.3687 loss_val: 1.3791
Run:02 Epoch: 0481 loss_train: 1.3717 loss_val: 1.3806
Run:02 Epoch: 0491 loss_train: 1.3694 loss_val: 1.3835
Run:02 Epoch: 0501 loss_train: 1.3700 loss_val: 1.3817
Run:02 Epoch: 0511 loss_train: 1.3687 loss_val: 1.3851
Run:02 Epoch: 0521 loss_train: 1.3708 loss_val: 1.3778
Run:02 Epoch: 0531 loss_train: 1.3703 loss_val: 1.3804
Run:02 Epoch: 0541 loss_train: 1.3677 loss_val: 1.3827
Run:02 Epoch: 0551 loss_train: 1.3683 loss_val: 1.3803
Run:02 Epoch: 0561 loss_train: 1.3728 loss_val: 1.3840
Run:02 Epoch: 0571 loss_train: 1.3730 loss_val: 1.3817
Run:02 Epoch: 0581 loss_train: 1.3733 loss_val: 1.3865
Run:02 Epoch: 0591 loss_train: 1.3666 loss_val: 1.3819
Run:02 Epoch: 0601 loss_train: 1.3653 loss_val: 1.3804
Run:02 Epoch: 0611 loss_train: 1.3654 loss_val: 1.3801
Run:02 Epoch: 0621 loss_train: 1.3730 loss_val: 1.3801
Run:02 Epoch: 0631 loss_train: 1.3693 loss_val: 1.3793
Run:02 Epoch: 0641 loss_train: 1.3670 loss_val: 1.3825
Run:02 Epoch: 0651 loss_train: 1.3719 loss_val: 1.3786
Run:02 Epoch: 0661 loss_train: 1.3708 loss_val: 1.3833
Run:02 Epoch: 0671 loss_train: 1.3710 loss_val: 1.3843
Run:02 Epoch: 0681 loss_train: 1.3709 loss_val: 1.3821
Run:02 Epoch: 0691 loss_train: 1.3774 loss_val: 1.3859
Run:02 Epoch: 0701 loss_train: 1.3696 loss_val: 1.3850
Run:02 Epoch: 0711 loss_train: 1.3686 loss_val: 1.3826
Run:02 Epoch: 0721 loss_train: 1.3646 loss_val: 1.3801
Run:02 Epoch: 0731 loss_train: 1.3701 loss_val: 1.3799
Run:02 Epoch: 0741 loss_train: 1.3666 loss_val: 1.3837
Run:02 Epoch: 0751 loss_train: 1.3653 loss_val: 1.3818
Run:02 Epoch: 0761 loss_train: 1.3706 loss_val: 1.3765
Run:02 Epoch: 0771 loss_train: 1.3666 loss_val: 1.3828
Run:02 Epoch: 0781 loss_train: 1.3729 loss_val: 1.3808
Run:02 Epoch: 0791 loss_train: 1.3699 loss_val: 1.3806
Run:02 Epoch: 0801 loss_train: 1.3737 loss_val: 1.3845
Run:02 Epoch: 0811 loss_train: 1.3667 loss_val: 1.3781
Run:02 Epoch: 0821 loss_train: 1.3678 loss_val: 1.3808
Run:02 Epoch: 0831 loss_train: 1.3717 loss_val: 1.3802
Run:02 Epoch: 0841 loss_train: 1.3688 loss_val: 1.3855
Run:02 Epoch: 0851 loss_train: 1.3683 loss_val: 1.3830
Run:02 Epoch: 0861 loss_train: 1.3665 loss_val: 1.3836
Run:02 Epoch: 0871 loss_train: 1.3632 loss_val: 1.3809
Run:02 Epoch: 0881 loss_train: 1.3698 loss_val: 1.3798
Run:02 Epoch: 0891 loss_train: 1.3639 loss_val: 1.3789
Run:02 Epoch: 0901 loss_train: 1.3694 loss_val: 1.3808
Run:02 Epoch: 0911 loss_train: 1.3667 loss_val: 1.3803
Run:02 Epoch: 0921 loss_train: 1.3676 loss_val: 1.3779
Run:02 Epoch: 0931 loss_train: 1.3665 loss_val: 1.3795
Run:02 Epoch: 0941 loss_train: 1.3656 loss_val: 1.3831
Run:02 Epoch: 0951 loss_train: 1.3689 loss_val: 1.3828
Run:02 Epoch: 0961 loss_train: 1.3673 loss_val: 1.3802
Run:02 Epoch: 0971 loss_train: 1.3707 loss_val: 1.3798
Run:02 Epoch: 0981 loss_train: 1.3703 loss_val: 1.3803
Run:02 Epoch: 0991 loss_train: 1.3650 loss_val: 1.3783
Run:02 Epoch: 1001 loss_train: 1.3676 loss_val: 1.3814
Run:02 Epoch: 1011 loss_train: 1.3657 loss_val: 1.3813
Run:02 Epoch: 1021 loss_train: 1.3716 loss_val: 1.3800
Run:02 Epoch: 1031 loss_train: 1.3678 loss_val: 1.3792
Run:02 Epoch: 1041 loss_train: 1.3679 loss_val: 1.3808
Run:02 Epoch: 1051 loss_train: 1.3671 loss_val: 1.3792
Run:02 Epoch: 1061 loss_train: 1.3671 loss_val: 1.3790
Run:02 Epoch: 1071 loss_train: 1.3696 loss_val: 1.3820
Run:02 Epoch: 1081 loss_train: 1.3666 loss_val: 1.3840
Run:02 Epoch: 1091 loss_train: 1.3698 loss_val: 1.3777
Run:02 Epoch: 1101 loss_train: 1.3690 loss_val: 1.3783
Run:02 Epoch: 1111 loss_train: 1.3710 loss_val: 1.3781
Run:02 Epoch: 1121 loss_train: 1.3646 loss_val: 1.3805
Run:02 Epoch: 1131 loss_train: 1.3635 loss_val: 1.3828
Run:02 Epoch: 1141 loss_train: 1.3711 loss_val: 1.3868
Run:02 Epoch: 1151 loss_train: 1.3726 loss_val: 1.3829
Run:02 Epoch: 1161 loss_train: 1.3635 loss_val: 1.3826
Run:02 Epoch: 1171 loss_train: 1.3645 loss_val: 1.3809
Run:02 Epoch: 1181 loss_train: 1.3678 loss_val: 1.3809
Run:02 Epoch: 1191 loss_train: 1.3642 loss_val: 1.3818
Run:02 Epoch: 1201 loss_train: 1.3648 loss_val: 1.3827
Run:02 Epoch: 1211 loss_train: 1.3648 loss_val: 1.3801
Run:02 Epoch: 1221 loss_train: 1.3683 loss_val: 1.3813
Run:02 Epoch: 1231 loss_train: 1.3665 loss_val: 1.3852
Run:02 Epoch: 1241 loss_train: 1.3667 loss_val: 1.3791
Run:02 Epoch: 1251 loss_train: 1.3689 loss_val: 1.3801
Run:02 Epoch: 1261 loss_train: 1.3675 loss_val: 1.3813
Run:02 Epoch: 1271 loss_train: 1.3679 loss_val: 1.3786
Run:02 Epoch: 1281 loss_train: 1.3677 loss_val: 1.3830
Run:02 Epoch: 1291 loss_train: 1.3659 loss_val: 1.3802
Run:02 Epoch: 1301 loss_train: 1.3689 loss_val: 1.3851
Run:02 Epoch: 1311 loss_train: 1.3666 loss_val: 1.3798
Run:02 Epoch: 1321 loss_train: 1.3683 loss_val: 1.3809
Run:02 Epoch: 1331 loss_train: 1.3627 loss_val: 1.3779
Run:02 Epoch: 1341 loss_train: 1.3682 loss_val: 1.3820
Run:02 Epoch: 1351 loss_train: 1.3725 loss_val: 1.3795
Run:02 Epoch: 1361 loss_train: 1.3651 loss_val: 1.3793
Run:02 Epoch: 1371 loss_train: 1.3742 loss_val: 1.3795
Run:02 Epoch: 1381 loss_train: 1.3636 loss_val: 1.3789
Run:02 Epoch: 1391 loss_train: 1.3684 loss_val: 1.3797
Run:02 Epoch: 1401 loss_train: 1.3673 loss_val: 1.3856
Run:02 Epoch: 1411 loss_train: 1.3695 loss_val: 1.3812
Run:02 Epoch: 1421 loss_train: 1.3639 loss_val: 1.3819
Run:02 Epoch: 1431 loss_train: 1.3682 loss_val: 1.3789
Run:02 Epoch: 1441 loss_train: 1.3685 loss_val: 1.3788
Run:02 Epoch: 1451 loss_train: 1.3648 loss_val: 1.3814
Run:02 Epoch: 1461 loss_train: 1.3678 loss_val: 1.3804
Run:02 Epoch: 1471 Run Train: 100%|██████████| 2/2 [35:35<00:00, 1181.86s/it]Run Train: 100%|██████████| 2/2 [35:35<00:00, 1067.65s/it]
loss_train: 1.3700 loss_val: 1.3796
Run:02 Epoch: 1481 loss_train: 1.3618 loss_val: 1.3809
Run:02 Epoch: 1491 loss_train: 1.3686 loss_val: 1.3829
test acc: 0.4353864734299517 test acc std 0.0006038647342995196


test micro f1: 0.4353864734299517 test macro f1 0.37686167354776046
